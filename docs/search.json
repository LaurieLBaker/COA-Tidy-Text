[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Text Mining with Tidy Data Principles",
    "section": "",
    "text": "These are the materials for workshops on text analysis by Julia Silge. Text data is increasingly important in many domains, and tidy data principles and tidy tools can make text mining easier and more effective. In this workshop, learn how to manipulate, summarize, and visualize the characteristics of text using these methods and R packages from the tidy tool ecosystem. These tools are highly effective for many analytical questions and allow analysts to integrate natural language processing into effective workflows already in wide use. Explore how to implement approaches such as sentiment analysis of texts, measuring tf-idf, network analysis of words, and building both supervised and unsupervised text models."
  },
  {
    "objectID": "index.html#is-this-workshop-for-me",
    "href": "index.html#is-this-workshop-for-me",
    "title": "Text Mining with Tidy Data Principles",
    "section": "Is this workshop for me?",
    "text": "Is this workshop for me?\nThis course will be appropriate for you if you answer yes to these questions:\n\nHave you ever encountered text data and suspected there was useful insight latent within it but felt frustrated about how to find that insight?\nAre you familiar with dplyr and ggplot2, and ready to learn how unstructured text data can be analyzed within the tidyverse ecosystem?\nDo you need a flexible framework for handling text data that allows you to engage in tasks from exploratory data analysis to supervised predictive modeling?"
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "Text Mining with Tidy Data Principles",
    "section": "Learning objectives",
    "text": "Learning objectives\nAt the end of this workshop, participants will understand how to:\n\nPerform exploratory data analyses of text datasets, including summarization and data visualization\nUnderstand and implement both sentiment analysis and tf-idf\nUse unsupervised models to gain insight into text data\nBuild supervised classification models for text using tidy data principles"
  },
  {
    "objectID": "index.html#preparation",
    "href": "index.html#preparation",
    "title": "Text Mining with Tidy Data Principles",
    "section": "Preparation",
    "text": "Preparation\nPlease tune into the workshop with a computer that has the following installed (all available for free):\n\nA recent version of R, available at https://cran.r-project.org/\nA recent version of RStudio Desktop (RStudio Desktop Open Source License), available at https://posit.co/download/rstudio-desktop/\nThe following R packages, which you can install by connecting to the internet, opening RStudio, and running at the command line:\n\n\ninstall.packages(c(\"tidyverse\", \"tidytext\", \n                   \"gutenbergr\", \"widyr\",\n                   \"stopwords\", \"stm\",\n                   \"tidygraph\", \"ggraph\",\n                   \"tidymodels\", \"glmnet\", \n                   \"vip\", \"textrecipes\"))"
  },
  {
    "objectID": "index.html#slides",
    "href": "index.html#slides",
    "title": "Text Mining with Tidy Data Principles",
    "section": "Slides",
    "text": "Slides\n\n00: Intro\n01: Text as tidy data\n02: More advanced EDA\n03: Topic modeling\n04: Supervised text models"
  },
  {
    "objectID": "index.html#code",
    "href": "index.html#code",
    "title": "Text Mining with Tidy Data Principles",
    "section": "Code",
    "text": "Code\nQuarto files for working along are available on GitHub."
  },
  {
    "objectID": "index.html#past-workshops",
    "href": "index.html#past-workshops",
    "title": "Text Mining with Tidy Data Principles",
    "section": "Past workshops",
    "text": "Past workshops\n\n16 October 2017 for Portland R-Ladies and Portland R User Group\n18 April 2018 for R-Ladies RTP\n22 May 2018 for III International Seminar on Statistics with R\n29 May 2019 for ASA Symposium on Data Science and Statistics\n27-28 January 2020 at rstudio::conf()\n10 February 2021 for National Institute of Statistical Sciences\n10 February 2021 for National Institute of Statistical Sciences\n9-11 January 2022 for Faculty of Psychology, University of Basel"
  },
  {
    "objectID": "index.html#instructor-bio",
    "href": "index.html#instructor-bio",
    "title": "Text Mining with Tidy Data Principles",
    "section": "Instructor bio",
    "text": "Instructor bio\nJulia Silge is a data scientist and software engineer at Posit PBC (formerly RStudio) where she works on open source modeling and MLOps tools. She is an author, an international keynote speaker, and a real-world practitioner focusing on data analysis and machine learning. Julia loves text analysis, making beautiful charts, and communicating about technical topics with diverse audiences."
  },
  {
    "objectID": "slides/00-intro.html#text-in-the-real-world",
    "href": "slides/00-intro.html#text-in-the-real-world",
    "title": "Text Mining",
    "section": "Text in the real world",
    "text": "Text in the real world\n\n\nText data is increasingly important 📚\n\n\n\n\nNLP training is scarce on the ground 😱"
  },
  {
    "objectID": "slides/00-intro.html#section-1",
    "href": "slides/00-intro.html#section-1",
    "title": "Text Mining",
    "section": "",
    "text": "https://github.com/juliasilge/tidytext"
  },
  {
    "objectID": "slides/00-intro.html#section-2",
    "href": "slides/00-intro.html#section-2",
    "title": "Text Mining",
    "section": "",
    "text": "https://tidytextmining.com/"
  },
  {
    "objectID": "slides/00-intro.html#plan-for-this-workshop",
    "href": "slides/00-intro.html#plan-for-this-workshop",
    "title": "Text Mining",
    "section": "Plan for this workshop",
    "text": "Plan for this workshop\n\n\nEDA for text\n\n\n\n\nModeling for text"
  },
  {
    "objectID": "slides/01-tidytext.html#lets-install-some-packages",
    "href": "slides/01-tidytext.html#lets-install-some-packages",
    "title": "Text Mining",
    "section": "Let’s install some packages",
    "text": "Let’s install some packages\n\ninstall.packages(c(\"tidyverse\", \n                   \"tidytext\",\n                   \"stopwords\",\n                   \"gutenbergr\"))"
  },
  {
    "objectID": "slides/01-tidytext.html#what-do-we-mean-by-tidy-text",
    "href": "slides/01-tidytext.html#what-do-we-mean-by-tidy-text",
    "title": "Text Mining",
    "section": "What do we mean by tidy text?",
    "text": "What do we mean by tidy text?\n\n\ntext <- c(\"Tell all the truth but tell it slant —\",\n          \"Success in Circuit lies\",\n          \"Too bright for our infirm Delight\",\n          \"The Truth's superb surprise\",\n          \"As Lightning to the Children eased\",\n          \"With explanation kind\",\n          \"The Truth must dazzle gradually\",\n          \"Or every man be blind —\")\n\ntext\n#> [1] \"Tell all the truth but tell it slant —\"\n#> [2] \"Success in Circuit lies\"               \n#> [3] \"Too bright for our infirm Delight\"     \n#> [4] \"The Truth's superb surprise\"           \n#> [5] \"As Lightning to the Children eased\"    \n#> [6] \"With explanation kind\"                 \n#> [7] \"The Truth must dazzle gradually\"       \n#> [8] \"Or every man be blind —\""
  },
  {
    "objectID": "slides/01-tidytext.html#what-do-we-mean-by-tidy-text-1",
    "href": "slides/01-tidytext.html#what-do-we-mean-by-tidy-text-1",
    "title": "Text Mining",
    "section": "What do we mean by tidy text?",
    "text": "What do we mean by tidy text?\n\n\nlibrary(tidyverse)\n\ntext_df <- tibble(line = 1:8, text = text)\n\ntext_df\n#> # A tibble: 8 × 2\n#>    line text                                  \n#>   <int> <chr>                                 \n#> 1     1 Tell all the truth but tell it slant —\n#> 2     2 Success in Circuit lies               \n#> 3     3 Too bright for our infirm Delight     \n#> 4     4 The Truth's superb surprise           \n#> 5     5 As Lightning to the Children eased    \n#> 6     6 With explanation kind                 \n#> 7     7 The Truth must dazzle gradually       \n#> 8     8 Or every man be blind —"
  },
  {
    "objectID": "slides/01-tidytext.html#what-do-we-mean-by-tidy-text-2",
    "href": "slides/01-tidytext.html#what-do-we-mean-by-tidy-text-2",
    "title": "Text Mining",
    "section": "What do we mean by tidy text?",
    "text": "What do we mean by tidy text?\n\n\nlibrary(tidytext)\n\ntext_df %>%\n    unnest_tokens(word, text)\n#> # A tibble: 41 × 2\n#>     line word   \n#>    <int> <chr>  \n#>  1     1 tell   \n#>  2     1 all    \n#>  3     1 the    \n#>  4     1 truth  \n#>  5     1 but    \n#>  6     1 tell   \n#>  7     1 it     \n#>  8     1 slant  \n#>  9     2 success\n#> 10     2 in     \n#> # ℹ 31 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#jane-wants-to-know",
    "href": "slides/01-tidytext.html#jane-wants-to-know",
    "title": "Text Mining",
    "section": "Jane wants to know…",
    "text": "Jane wants to know…\n\nA tidy text dataset typically has\n\nmore\nfewer\n\nrows than the original, non-tidy text dataset."
  },
  {
    "objectID": "slides/01-tidytext.html#gathering-more-data",
    "href": "slides/01-tidytext.html#gathering-more-data",
    "title": "Text Mining",
    "section": "Gathering more data",
    "text": "Gathering more data\nYou can access the full text of many public domain works from Project Gutenberg using the gutenbergr package.\n\nlibrary(gutenbergr)\n\nfull_text <- gutenberg_download(1342, mirror = my_mirror)\n\n\n\n\nhttps://docs.ropensci.org/gutenbergr/"
  },
  {
    "objectID": "slides/01-tidytext.html#time-to-tidy-your-text",
    "href": "slides/01-tidytext.html#time-to-tidy-your-text",
    "title": "Text Mining",
    "section": "Time to tidy your text!",
    "text": "Time to tidy your text!\n\ntidy_book <- full_text %>%\n    mutate(line = row_number()) %>%\n    unnest_tokens(word, text)         \n\nglimpse(tidy_book)\n#> Rows: 127,996\n#> Columns: 3\n#> $ gutenberg_id <int> 1342, 1342, 1342, 1342, 1342, 1342, 1342, 1342, 1342, 134…\n#> $ line         <int> 1, 3, 3, 4, 6, 6, 6, 6, 7, 9, 9, 12, 14, 14, 14, 14, 14, …\n#> $ word         <chr> \"illustration\", \"george\", \"allen\", \"publisher\", \"156\", \"c…"
  },
  {
    "objectID": "slides/01-tidytext.html#what-are-the-most-common-words",
    "href": "slides/01-tidytext.html#what-are-the-most-common-words",
    "title": "Text Mining",
    "section": "What are the most common words?",
    "text": "What are the most common words?\nWhat do you predict will happen if we run the following code? 🤔\n\ntidy_book %>%\n    count(word, sort = TRUE)"
  },
  {
    "objectID": "slides/01-tidytext.html#what-are-the-most-common-words-1",
    "href": "slides/01-tidytext.html#what-are-the-most-common-words-1",
    "title": "Text Mining",
    "section": "What are the most common words?",
    "text": "What are the most common words?\nWhat do you predict will happen if we run the following code? 🤔\n\ntidy_book %>%\n    count(word, sort = TRUE)\n#> # A tibble: 7,118 × 2\n#>    word      n\n#>    <chr> <int>\n#>  1 the    4656\n#>  2 to     4323\n#>  3 of     3838\n#>  4 and    3763\n#>  5 her    2260\n#>  6 i      2095\n#>  7 a      2036\n#>  8 in     1991\n#>  9 was    1871\n#> 10 she    1732\n#> # ℹ 7,108 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#stop-words",
    "href": "slides/01-tidytext.html#stop-words",
    "title": "Text Mining",
    "section": "Stop words",
    "text": "Stop words\n\nget_stopwords()\n#> # A tibble: 175 × 2\n#>    word      lexicon \n#>    <chr>     <chr>   \n#>  1 i         snowball\n#>  2 me        snowball\n#>  3 my        snowball\n#>  4 myself    snowball\n#>  5 we        snowball\n#>  6 our       snowball\n#>  7 ours      snowball\n#>  8 ourselves snowball\n#>  9 you       snowball\n#> 10 your      snowball\n#> # ℹ 165 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#stop-words-1",
    "href": "slides/01-tidytext.html#stop-words-1",
    "title": "Text Mining",
    "section": "Stop words",
    "text": "Stop words\n\nget_stopwords(language = \"es\")\n#> # A tibble: 308 × 2\n#>    word  lexicon \n#>    <chr> <chr>   \n#>  1 de    snowball\n#>  2 la    snowball\n#>  3 que   snowball\n#>  4 el    snowball\n#>  5 en    snowball\n#>  6 y     snowball\n#>  7 a     snowball\n#>  8 los   snowball\n#>  9 del   snowball\n#> 10 se    snowball\n#> # ℹ 298 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#stop-words-2",
    "href": "slides/01-tidytext.html#stop-words-2",
    "title": "Text Mining",
    "section": "Stop words",
    "text": "Stop words\n\nget_stopwords(language = \"fr\")\n#> # A tibble: 164 × 2\n#>    word  lexicon \n#>    <chr> <chr>   \n#>  1 au    snowball\n#>  2 aux   snowball\n#>  3 avec  snowball\n#>  4 ce    snowball\n#>  5 ces   snowball\n#>  6 dans  snowball\n#>  7 de    snowball\n#>  8 des   snowball\n#>  9 du    snowball\n#> 10 elle  snowball\n#> # ℹ 154 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#stop-words-3",
    "href": "slides/01-tidytext.html#stop-words-3",
    "title": "Text Mining",
    "section": "Stop words",
    "text": "Stop words\n\nget_stopwords(source = \"smart\")\n#> # A tibble: 571 × 2\n#>    word        lexicon\n#>    <chr>       <chr>  \n#>  1 a           smart  \n#>  2 a's         smart  \n#>  3 able        smart  \n#>  4 about       smart  \n#>  5 above       smart  \n#>  6 according   smart  \n#>  7 accordingly smart  \n#>  8 across      smart  \n#>  9 actually    smart  \n#> 10 after       smart  \n#> # ℹ 561 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#stop-words-4",
    "href": "slides/01-tidytext.html#stop-words-4",
    "title": "Text Mining",
    "section": "Stop words",
    "text": "Stop words\n\nget_stopwords(source = \"smart\")\n#&gt; # A tibble: 571 x 2\n#&gt;    word        lexicon\n#&gt;    &lt;chr&gt;       &lt;chr&gt;  \n#&gt;  1 a           smart  \n#&gt;  2 a's         smart  \n#&gt;  3 able        smart  \n#&gt;  4 about       smart  \n#&gt;  5 above       smart  \n#&gt;  6 according   smart  \n#&gt;  7 accordingly smart  \n#&gt;  8 across      smart  \n#&gt;  9 actually    smart  \n#&gt; 10 after       smart  \n#&gt; # ... with 561 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#what-are-the-most-common-words-2",
    "href": "slides/01-tidytext.html#what-are-the-most-common-words-2",
    "title": "Text Mining",
    "section": "What are the most common words?",
    "text": "What are the most common words?\nU N S C R A M B L E\nanti_join(get_stopwords(source = “smart”)) %>%\ntidy_book %>%\ncount(word, sort = TRUE) %>%\ngeom_col() +\nslice_max(n, n = 20) %>%\nggplot(aes(n, fct_reorder(word, n))) +"
  },
  {
    "objectID": "slides/01-tidytext.html#what-are-the-most-common-words-3",
    "href": "slides/01-tidytext.html#what-are-the-most-common-words-3",
    "title": "Text Mining",
    "section": "What are the most common words?",
    "text": "What are the most common words?\n\ntidy_book %>%\n    anti_join(get_stopwords(source = \"smart\")) %>%\n    count(word, sort = TRUE) %>%\n    slice_max(n, n = 20) %>%\n    ggplot(aes(n, fct_reorder(word, n))) +  \n    geom_col()"
  },
  {
    "objectID": "slides/01-tidytext.html#sentiment-lexicons",
    "href": "slides/01-tidytext.html#sentiment-lexicons",
    "title": "Text Mining",
    "section": "Sentiment lexicons",
    "text": "Sentiment lexicons\n\n\n\n\nget_sentiments(\"afinn\")\n#> # A tibble: 2,477 × 2\n#>    word       value\n#>    <chr>      <dbl>\n#>  1 abandon       -2\n#>  2 abandoned     -2\n#>  3 abandons      -2\n#>  4 abducted      -2\n#>  5 abduction     -2\n#>  6 abductions    -2\n#>  7 abhor         -3\n#>  8 abhorred      -3\n#>  9 abhorrent     -3\n#> 10 abhors        -3\n#> # ℹ 2,467 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#sentiment-lexicons-1",
    "href": "slides/01-tidytext.html#sentiment-lexicons-1",
    "title": "Text Mining",
    "section": "Sentiment lexicons",
    "text": "Sentiment lexicons\n\nget_sentiments(\"bing\")\n#> # A tibble: 6,786 × 2\n#>    word        sentiment\n#>    <chr>       <chr>    \n#>  1 2-faces     negative \n#>  2 abnormal    negative \n#>  3 abolish     negative \n#>  4 abominable  negative \n#>  5 abominably  negative \n#>  6 abominate   negative \n#>  7 abomination negative \n#>  8 abort       negative \n#>  9 aborted     negative \n#> 10 aborts      negative \n#> # ℹ 6,776 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#sentiment-lexicons-2",
    "href": "slides/01-tidytext.html#sentiment-lexicons-2",
    "title": "Text Mining",
    "section": "Sentiment lexicons",
    "text": "Sentiment lexicons\n\nget_sentiments(\"nrc\")\n#> # A tibble: 13,872 × 2\n#>    word        sentiment\n#>    <chr>       <chr>    \n#>  1 abacus      trust    \n#>  2 abandon     fear     \n#>  3 abandon     negative \n#>  4 abandon     sadness  \n#>  5 abandoned   anger    \n#>  6 abandoned   fear     \n#>  7 abandoned   negative \n#>  8 abandoned   sadness  \n#>  9 abandonment anger    \n#> 10 abandonment fear     \n#> # ℹ 13,862 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#sentiment-lexicons-3",
    "href": "slides/01-tidytext.html#sentiment-lexicons-3",
    "title": "Text Mining",
    "section": "Sentiment lexicons",
    "text": "Sentiment lexicons\n\nget_sentiments(\"loughran\")\n#> # A tibble: 4,150 × 2\n#>    word         sentiment\n#>    <chr>        <chr>    \n#>  1 abandon      negative \n#>  2 abandoned    negative \n#>  3 abandoning   negative \n#>  4 abandonment  negative \n#>  5 abandonments negative \n#>  6 abandons     negative \n#>  7 abdicated    negative \n#>  8 abdicates    negative \n#>  9 abdicating   negative \n#> 10 abdication   negative \n#> # ℹ 4,140 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#implementing-sentiment-analysis",
    "href": "slides/01-tidytext.html#implementing-sentiment-analysis",
    "title": "Text Mining",
    "section": "Implementing sentiment analysis",
    "text": "Implementing sentiment analysis\n\ntidy_book %>%\n    inner_join(get_sentiments(\"bing\")) %>% \n    count(sentiment, sort = TRUE)\n#> # A tibble: 2 × 2\n#>   sentiment     n\n#>   <chr>     <int>\n#> 1 positive   5306\n#> 2 negative   3864"
  },
  {
    "objectID": "slides/01-tidytext.html#jane-wants-to-know-1",
    "href": "slides/01-tidytext.html#jane-wants-to-know-1",
    "title": "Text Mining",
    "section": "Jane wants to know…",
    "text": "Jane wants to know…\n\nWhat kind of join is appropriate for sentiment analysis?\n\nanti_join()\nfull_join()\nouter_join()\ninner_join()"
  },
  {
    "objectID": "slides/01-tidytext.html#implementing-sentiment-analysis-1",
    "href": "slides/01-tidytext.html#implementing-sentiment-analysis-1",
    "title": "Text Mining",
    "section": "Implementing sentiment analysis",
    "text": "Implementing sentiment analysis\nWhat do you predict will happen if we run the following code? 🤔\n\ntidy_book %>%\n    inner_join(get_sentiments(\"bing\")) %>%            \n    count(sentiment, word, sort = TRUE)"
  },
  {
    "objectID": "slides/01-tidytext.html#implementing-sentiment-analysis-2",
    "href": "slides/01-tidytext.html#implementing-sentiment-analysis-2",
    "title": "Text Mining",
    "section": "Implementing sentiment analysis",
    "text": "Implementing sentiment analysis\nWhat do you predict will happen if we run the following code? 🤔\n\ntidy_book %>%\n    inner_join(get_sentiments(\"bing\")) %>%            \n    count(sentiment, word, sort = TRUE)   \n#> # A tibble: 1,503 × 3\n#>    sentiment word         n\n#>    <chr>     <chr>    <int>\n#>  1 negative  miss       315\n#>  2 positive  well       230\n#>  3 positive  good       208\n#>  4 positive  great      148\n#>  5 positive  enough     111\n#>  6 positive  love       102\n#>  7 positive  better      98\n#>  8 positive  pleasure    94\n#>  9 positive  like        89\n#> 10 positive  happy       83\n#> # ℹ 1,493 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#implementing-sentiment-analysis-3",
    "href": "slides/01-tidytext.html#implementing-sentiment-analysis-3",
    "title": "Text Mining",
    "section": "Implementing sentiment analysis",
    "text": "Implementing sentiment analysis\n\ntidy_book %>%\n    inner_join(get_sentiments(\"bing\")) %>%\n    count(sentiment, word, sort = TRUE) %>%\n    group_by(sentiment) %>%\n    slice_max(n, n = 10) %>%\n    ungroup() %>%\n    ggplot(aes(n, fct_reorder(word, n), fill = sentiment)) +\n    geom_col() +\n    facet_wrap(vars(sentiment), scales = \"free\")"
  },
  {
    "objectID": "slides/02-more-eda.html#lets-install-some-packages",
    "href": "slides/02-more-eda.html#lets-install-some-packages",
    "title": "Text Mining",
    "section": "Let’s install some packages",
    "text": "Let’s install some packages\n\ninstall.packages(c(\"tidyverse\", \n                   \"tidytext\",\n                   \"stopwords\",\n                   \"gutenbergr\",\n                   \"widyr\",\n                   \"tidygraph\",\n                   \"tidylo\",\n                   \"ggraph\"))"
  },
  {
    "objectID": "slides/02-more-eda.html#what-is-a-document-about-1",
    "href": "slides/02-more-eda.html#what-is-a-document-about-1",
    "title": "Text Mining",
    "section": "What is a document about?",
    "text": "What is a document about?\n\nTerm frequency\nInverse document frequency\n\n\n\\[idf(\\text{term}) = \\ln{\\left(\\frac{n_{\\text{documents}}}{n_{\\text{documents containing term}}}\\right)}\\]\n\n\ntf-idf is about comparing documents within a collection."
  },
  {
    "objectID": "slides/02-more-eda.html#understanding-tf-idf",
    "href": "slides/02-more-eda.html#understanding-tf-idf",
    "title": "Text Mining",
    "section": "Understanding tf-idf",
    "text": "Understanding tf-idf\nMake a collection (corpus) for yourself! 💅\n\nlibrary(gutenbergr)\nfull_collection <- gutenberg_download(c(141, 158, 161, 1342),\n                                      meta_fields = \"title\",\n                                      mirror = my_mirror)"
  },
  {
    "objectID": "slides/02-more-eda.html#understanding-tf-idf-1",
    "href": "slides/02-more-eda.html#understanding-tf-idf-1",
    "title": "Text Mining",
    "section": "Understanding tf-idf",
    "text": "Understanding tf-idf\nMake a collection (corpus) for yourself! 💅\n\nfull_collection\n#> # A tibble: 59,360 × 3\n#>    gutenberg_id text             title         \n#>           <int> <chr>            <chr>         \n#>  1          141 \"MANSFIELD PARK\" Mansfield Park\n#>  2          141 \"\"               Mansfield Park\n#>  3          141 \"(1814)\"         Mansfield Park\n#>  4          141 \"\"               Mansfield Park\n#>  5          141 \"By Jane Austen\" Mansfield Park\n#>  6          141 \"\"               Mansfield Park\n#>  7          141 \"\"               Mansfield Park\n#>  8          141 \"Contents\"       Mansfield Park\n#>  9          141 \"\"               Mansfield Park\n#> 10          141 \"   CHAPTER I\"   Mansfield Park\n#> # … with 59,350 more rows"
  },
  {
    "objectID": "slides/02-more-eda.html#counting-word-frequencies",
    "href": "slides/02-more-eda.html#counting-word-frequencies",
    "title": "Text Mining",
    "section": "Counting word frequencies",
    "text": "Counting word frequencies\n\nlibrary(tidyverse)\nlibrary(tidytext)\n\nbook_words <- full_collection %>%\n    unnest_tokens(word, text) %>%\n    count(title, word, sort = TRUE)\n\nWhat do the columns of book_words tell us?"
  },
  {
    "objectID": "slides/02-more-eda.html#calculating-tf-idf",
    "href": "slides/02-more-eda.html#calculating-tf-idf",
    "title": "Text Mining",
    "section": "Calculating tf-idf",
    "text": "Calculating tf-idf\n\nbook_tf_idf <- book_words %>%\n    bind_tf_idf(word, title, n)"
  },
  {
    "objectID": "slides/02-more-eda.html#calculating-tf-idf-1",
    "href": "slides/02-more-eda.html#calculating-tf-idf-1",
    "title": "Text Mining",
    "section": "Calculating tf-idf",
    "text": "Calculating tf-idf\n\nbook_tf_idf\n#> # A tibble: 29,055 × 6\n#>    title               word      n     tf   idf tf_idf\n#>    <chr>               <chr> <int>  <dbl> <dbl>  <dbl>\n#>  1 Mansfield Park      the    6207 0.0387     0      0\n#>  2 Mansfield Park      to     5473 0.0341     0      0\n#>  3 Mansfield Park      and    5437 0.0339     0      0\n#>  4 Emma                to     5238 0.0325     0      0\n#>  5 Emma                the    5201 0.0323     0      0\n#>  6 Emma                and    4896 0.0304     0      0\n#>  7 Mansfield Park      of     4777 0.0298     0      0\n#>  8 Pride and Prejudice the    4656 0.0364     0      0\n#>  9 Pride and Prejudice to     4323 0.0338     0      0\n#> 10 Emma                of     4291 0.0266     0      0\n#> # … with 29,045 more rows\n\n\nThat’s… super exciting???"
  },
  {
    "objectID": "slides/02-more-eda.html#calculating-tf-idf-2",
    "href": "slides/02-more-eda.html#calculating-tf-idf-2",
    "title": "Text Mining",
    "section": "Calculating tf-idf",
    "text": "Calculating tf-idf\nWhat do you predict will happen if we run the following code? 🤔\n\nbook_tf_idf %>%\n    arrange(-tf_idf)"
  },
  {
    "objectID": "slides/02-more-eda.html#calculating-tf-idf-3",
    "href": "slides/02-more-eda.html#calculating-tf-idf-3",
    "title": "Text Mining",
    "section": "Calculating tf-idf",
    "text": "Calculating tf-idf\nWhat do you predict will happen if we run the following code? 🤔\n\nbook_tf_idf %>%\n    arrange(-tf_idf)\n#> # A tibble: 29,055 × 6\n#>    title                 word          n      tf   idf  tf_idf\n#>    <chr>                 <chr>     <int>   <dbl> <dbl>   <dbl>\n#>  1 Sense and Sensibility elinor      622 0.00518 1.39  0.00718\n#>  2 Sense and Sensibility marianne    492 0.00410 1.39  0.00568\n#>  3 Pride and Prejudice   darcy       383 0.00299 1.39  0.00415\n#>  4 Emma                  emma        786 0.00488 0.693 0.00338\n#>  5 Pride and Prejudice   bennet      309 0.00241 1.39  0.00335\n#>  6 Emma                  weston      388 0.00241 1.39  0.00334\n#>  7 Pride and Prejudice   elizabeth   605 0.00473 0.693 0.00328\n#>  8 Emma                  knightley   356 0.00221 1.39  0.00306\n#>  9 Pride and Prejudice   bingley     262 0.00205 1.39  0.00284\n#> 10 Emma                  elton       319 0.00198 1.39  0.00274\n#> # … with 29,045 more rows"
  },
  {
    "objectID": "slides/02-more-eda.html#calculating-tf-idf-4",
    "href": "slides/02-more-eda.html#calculating-tf-idf-4",
    "title": "Text Mining",
    "section": "Calculating tf-idf",
    "text": "Calculating tf-idf\nU N S C R A M B L E\ngroup_by(title) %>%\nbook_tf_idf %>%\nslice_max(tf_idf, n = 10) %>%\nggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = title)) +\nfacet_wrap(vars(title), scales = “free”)\ngeom_col(show.legend = FALSE) +"
  },
  {
    "objectID": "slides/02-more-eda.html#calculating-tf-idf-5",
    "href": "slides/02-more-eda.html#calculating-tf-idf-5",
    "title": "Text Mining",
    "section": "Calculating tf-idf",
    "text": "Calculating tf-idf\n\nbook_tf_idf %>%\n    group_by(title) %>%\n    slice_max(tf_idf, n = 10) %>%\n    ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = title)) +\n    geom_col(show.legend = FALSE) +\n    facet_wrap(vars(title), scales = \"free\")"
  },
  {
    "objectID": "slides/02-more-eda.html#what-is-a-document-about-3",
    "href": "slides/02-more-eda.html#what-is-a-document-about-3",
    "title": "Text Mining",
    "section": "What is a document about?",
    "text": "What is a document about?\n\nTerm frequency\nInverse document frequency\n\n\nWeighted log odds ⚖️\n\nLog odds ratio expresses probabilities\nWeighting helps deal with power law distribution"
  },
  {
    "objectID": "slides/02-more-eda.html#weighted-log-odds-1",
    "href": "slides/02-more-eda.html#weighted-log-odds-1",
    "title": "Text Mining",
    "section": "Weighted log odds ⚖️",
    "text": "Weighted log odds ⚖️\n\nlibrary(tidylo)\nbook_words %>%\n    bind_log_odds(title, word, n) %>%\n    arrange(-log_odds_weighted)\n#> # A tibble: 29,055 × 4\n#>    title                 word          n log_odds_weighted\n#>    <chr>                 <chr>     <int>             <dbl>\n#>  1 Sense and Sensibility elinor      622              35.6\n#>  2 Sense and Sensibility marianne    492              31.6\n#>  3 Emma                  emma        786              29.3\n#>  4 Pride and Prejudice   darcy       383              27.5\n#>  5 Pride and Prejudice   elizabeth   605              26.9\n#>  6 Emma                  weston      388              26.8\n#>  7 Emma                  knightley   356              25.7\n#>  8 Pride and Prejudice   bennet      309              24.7\n#>  9 Emma                  elton       319              24.3\n#> 10 Mansfield Park        crawford    493              23.2\n#> # … with 29,045 more rows\n\n\nWeighted log odds can distinguish between words that are used in all texts."
  },
  {
    "objectID": "slides/02-more-eda.html#n-grams-and-beyond-1",
    "href": "slides/02-more-eda.html#n-grams-and-beyond-1",
    "title": "Text Mining",
    "section": "N-grams… and beyond! 🚀",
    "text": "N-grams… and beyond! 🚀\n\nfull_text <- gutenberg_download(158, mirror = my_mirror)\n\ntidy_ngram <- full_text %>%\n    unnest_tokens(bigram, text, token = \"ngrams\", n = 2) %>% \n    filter(!is.na(bigram))"
  },
  {
    "objectID": "slides/02-more-eda.html#n-grams-and-beyond-2",
    "href": "slides/02-more-eda.html#n-grams-and-beyond-2",
    "title": "Text Mining",
    "section": "N-grams… and beyond! 🚀",
    "text": "N-grams… and beyond! 🚀\n\ntidy_ngram\n#> # A tibble: 147,256 × 2\n#>    gutenberg_id bigram     \n#>           <int> <chr>      \n#>  1          158 by jane    \n#>  2          158 jane austen\n#>  3          158 volume i   \n#>  4          158 chapter i  \n#>  5          158 chapter ii \n#>  6          158 chapter iii\n#>  7          158 chapter iv \n#>  8          158 chapter v  \n#>  9          158 chapter vi \n#> 10          158 chapter vii\n#> # … with 147,246 more rows"
  },
  {
    "objectID": "slides/02-more-eda.html#n-grams-and-beyond-3",
    "href": "slides/02-more-eda.html#n-grams-and-beyond-3",
    "title": "Text Mining",
    "section": "N-grams… and beyond! 🚀",
    "text": "N-grams… and beyond! 🚀\n\ntidy_ngram %>%\n    count(bigram, sort = TRUE)\n#> # A tibble: 61,242 × 2\n#>    bigram       n\n#>    <chr>    <int>\n#>  1 to be      583\n#>  2 of the     523\n#>  3 it was     425\n#>  4 in the     421\n#>  5 i am       381\n#>  6 she had    316\n#>  7 she was    310\n#>  8 it is      290\n#>  9 had been   284\n#> 10 i have     265\n#> # … with 61,232 more rows"
  },
  {
    "objectID": "slides/02-more-eda.html#jane-wants-to-know",
    "href": "slides/02-more-eda.html#jane-wants-to-know",
    "title": "Text Mining",
    "section": "Jane wants to know…",
    "text": "Jane wants to know…\n\nCan we use an anti_join() now to remove stop words?\n\nYes! ✅\nNo ☹️"
  },
  {
    "objectID": "slides/02-more-eda.html#n-grams-and-beyond-4",
    "href": "slides/02-more-eda.html#n-grams-and-beyond-4",
    "title": "Text Mining",
    "section": "N-grams… and beyond! 🚀",
    "text": "N-grams… and beyond! 🚀\n\nbigram_counts <- tidy_ngram %>%\n    separate(bigram, c(\"word1\", \"word2\"), sep = \" \") %>%\n    filter(!word1 %in% stop_words$word,\n           !word2 %in% stop_words$word) %>%\n    count(word1, word2, sort = TRUE)"
  },
  {
    "objectID": "slides/02-more-eda.html#n-grams-and-beyond-5",
    "href": "slides/02-more-eda.html#n-grams-and-beyond-5",
    "title": "Text Mining",
    "section": "N-grams… and beyond! 🚀",
    "text": "N-grams… and beyond! 🚀\n\nbigram_counts\n#> # A tibble: 6,526 × 3\n#>    word1 word2         n\n#>    <chr> <chr>     <int>\n#>  1 miss  woodhouse   136\n#>  2 frank churchill   110\n#>  3 miss  fairfax     101\n#>  4 miss  bates        95\n#>  5 jane  fairfax      90\n#>  6 john  knightley    47\n#>  7 miss  smith        45\n#>  8 miss  taylor       39\n#>  9 dear  emma         30\n#> 10 maple grove        28\n#> # … with 6,516 more rows"
  },
  {
    "objectID": "slides/02-more-eda.html#what-can-you-do-with-n-grams",
    "href": "slides/02-more-eda.html#what-can-you-do-with-n-grams",
    "title": "Text Mining",
    "section": "What can you do with n-grams?",
    "text": "What can you do with n-grams?\n\n\ntf-idf of n-grams\nweighted log odds of n-grams\nnetwork analysis\nnegation"
  },
  {
    "objectID": "slides/02-more-eda.html#section-3",
    "href": "slides/02-more-eda.html#section-3",
    "title": "Text Mining",
    "section": "",
    "text": "https://pudding.cool/2017/08/screen-direction/"
  },
  {
    "objectID": "slides/02-more-eda.html#network-analysis",
    "href": "slides/02-more-eda.html#network-analysis",
    "title": "Text Mining",
    "section": "Network analysis",
    "text": "Network analysis\n\nlibrary(widyr)\nlibrary(ggraph)\nlibrary(tidygraph)\n\nbigram_graph <- bigram_counts %>%\n    filter(n > 5) %>%\n    as_tbl_graph()"
  },
  {
    "objectID": "slides/02-more-eda.html#network-analysis-1",
    "href": "slides/02-more-eda.html#network-analysis-1",
    "title": "Text Mining",
    "section": "Network analysis",
    "text": "Network analysis\n\nbigram_graph\n#> # A tbl_graph: 81 nodes and 68 edges\n#> #\n#> # A directed acyclic simple graph with 19 components\n#> #\n#> # Node Data: 81 × 1 (active)\n#>   name \n#>   <chr>\n#> 1 miss \n#> 2 frank\n#> 3 jane \n#> 4 john \n#> 5 dear \n#> 6 maple\n#> # … with 75 more rows\n#> #\n#> # Edge Data: 68 × 3\n#>    from    to     n\n#>   <int> <int> <int>\n#> 1     1    30   136\n#> 2     2    31   110\n#> 3     1    32   101\n#> # … with 65 more rows"
  },
  {
    "objectID": "slides/02-more-eda.html#jane-wants-to-know-1",
    "href": "slides/02-more-eda.html#jane-wants-to-know-1",
    "title": "Text Mining",
    "section": "Jane wants to know…",
    "text": "Jane wants to know…\n\nIs bigram_graph a tidy dataset?\n\nYes ☑️\nNo 🚫"
  },
  {
    "objectID": "slides/02-more-eda.html#network-analysis-2",
    "href": "slides/02-more-eda.html#network-analysis-2",
    "title": "Text Mining",
    "section": "Network analysis",
    "text": "Network analysis\n\nbigram_graph %>%\n    ggraph(layout = \"kk\") +\n    geom_edge_link(aes(edge_alpha = n)) + \n    geom_node_text(aes(label = name)) +  \n    theme_graph()"
  },
  {
    "objectID": "slides/02-more-eda.html#network-analysis-3",
    "href": "slides/02-more-eda.html#network-analysis-3",
    "title": "Text Mining",
    "section": "Network analysis",
    "text": "Network analysis\n\nbigram_graph %>%\n    ggraph(layout = \"kk\") +\n    geom_edge_link(aes(edge_alpha = n), \n                   show.legend = FALSE, \n                   arrow = arrow(length = unit(1.5, 'mm')), \n                   start_cap = circle(3, 'mm'),\n                   end_cap = circle(3, 'mm')) +\n    geom_node_text(aes(label = name)) + \n    theme_graph()"
  },
  {
    "objectID": "slides/03-topic-models.html#lets-install-some-packages",
    "href": "slides/03-topic-models.html#lets-install-some-packages",
    "title": "Text Mining",
    "section": "Let’s install some packages",
    "text": "Let’s install some packages\n\ninstall.packages(c(\"tidyverse\", \n                   \"tidytext\",\n                   \"stopwords\",\n                   \"gutenbergr\",\n                   \"stm\"))"
  },
  {
    "objectID": "slides/03-topic-models.html#workflow-for-text-miningmodeling",
    "href": "slides/03-topic-models.html#workflow-for-text-miningmodeling",
    "title": "Text Mining",
    "section": "Workflow for text mining/modeling",
    "text": "Workflow for text mining/modeling"
  },
  {
    "objectID": "slides/03-topic-models.html#download-your-text-data",
    "href": "slides/03-topic-models.html#download-your-text-data",
    "title": "Text Mining",
    "section": "Download your text data",
    "text": "Download your text data\n\nlibrary(tidyverse)\nlibrary(gutenbergr)\n\nbooks <- gutenberg_download(c(36, 158, 164, 345),\n                            meta_fields = \"title\",\n                            mirror = my_mirror)\nbooks %>%\n    count(title)\n#> # A tibble: 4 × 2\n#>   title                                     n\n#>   <chr>                                 <int>\n#> 1 Dracula                               15480\n#> 2 Emma                                  16488\n#> 3 The War of the Worlds                  6372\n#> 4 Twenty Thousand Leagues under the Sea 12426"
  },
  {
    "objectID": "slides/03-topic-models.html#someone-has-torn-up-your-books",
    "href": "slides/03-topic-models.html#someone-has-torn-up-your-books",
    "title": "Text Mining",
    "section": "Someone has torn up your books! 😭",
    "text": "Someone has torn up your books! 😭\nWhat do you predict will happen if we run the following code? 🤔\n\nbooks_by_document <- books %>%\n    group_by(title) %>%\n    mutate(document = row_number() %/% 500) %>%\n    ungroup() %>%\n    unite(document, title, document)\n\nglimpse(books_by_document)"
  },
  {
    "objectID": "slides/03-topic-models.html#someone-has-torn-up-your-books-1",
    "href": "slides/03-topic-models.html#someone-has-torn-up-your-books-1",
    "title": "Text Mining",
    "section": "Someone has torn up your books! 😭",
    "text": "Someone has torn up your books! 😭\nWhat do you predict will happen if we run the following code? 🤔\n\nbooks_by_document <- books %>%\n    group_by(title) %>%\n    mutate(document = row_number() %/% 500) %>%\n    ungroup() %>%\n    unite(document, title, document)\n\nglimpse(books_by_document)\n#> Rows: 50,766\n#> Columns: 3\n#> $ gutenberg_id <int> 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 3…\n#> $ text         <chr> \"cover \", \"\", \"\", \"\", \"\", \"The War of the Worlds\", \"\", \"b…\n#> $ document     <chr> \"The War of the Worlds_0\", \"The War of the Worlds_0\", \"Th…"
  },
  {
    "objectID": "slides/03-topic-models.html#can-we-put-them-back-together",
    "href": "slides/03-topic-models.html#can-we-put-them-back-together",
    "title": "Text Mining",
    "section": "Can we put them back together?",
    "text": "Can we put them back together?\n\nlibrary(tidytext)\nword_counts <- books_by_document %>%\n    unnest_tokens(word, text) %>% \n    anti_join(get_stopwords(source = \"smart\")) %>%\n    count(document, word, sort = TRUE)\n\nglimpse(word_counts)\n#> Rows: 100,572\n#> Columns: 3\n#> $ document <chr> \"Emma_0\", \"Emma_7\", \"Emma_2\", \"Emma_8\", \"Emma_11\", \"Emma_6\", …\n#> $ word     <chr> \"chapter\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"chapter\", \"mr…\n#> $ n        <int> 57, 56, 54, 52, 51, 50, 49, 49, 48, 44, 44, 43, 43, 42, 42, 4…"
  },
  {
    "objectID": "slides/03-topic-models.html#jane-wants-to-know",
    "href": "slides/03-topic-models.html#jane-wants-to-know",
    "title": "Text Mining",
    "section": "Jane wants to know…",
    "text": "Jane wants to know…\n\nThe dataset word_counts contains\n\nthe counts of words per book\nthe counts of words per “chunk” (500 lines)\nthe counts of words per line"
  },
  {
    "objectID": "slides/03-topic-models.html#can-we-put-them-back-together-1",
    "href": "slides/03-topic-models.html#can-we-put-them-back-together-1",
    "title": "Text Mining",
    "section": "Can we put them back together?",
    "text": "Can we put them back together?\n\nwords_sparse <- word_counts %>%\n    cast_sparse(document, word, n)\n\nclass(words_sparse)\n#> [1] \"dgCMatrix\"\n#> attr(,\"package\")\n#> [1] \"Matrix\"\ndim(words_sparse)\n#> [1]   102 18370"
  },
  {
    "objectID": "slides/03-topic-models.html#jane-wants-to-know-1",
    "href": "slides/03-topic-models.html#jane-wants-to-know-1",
    "title": "Text Mining",
    "section": "Jane wants to know…",
    "text": "Jane wants to know…\n\nIs words_sparse a tidy dataset?\n\nYes ✔️\nNo 🚫"
  },
  {
    "objectID": "slides/03-topic-models.html#train-a-topic-model",
    "href": "slides/03-topic-models.html#train-a-topic-model",
    "title": "Text Mining",
    "section": "Train a topic model",
    "text": "Train a topic model\nUse a sparse matrix or a quanteda::dfm object as input\n\nlibrary(stm)\ntopic_model <- stm(words_sparse, K = 4, \n                   verbose = FALSE, \n                   init.type = \"Spectral\")"
  },
  {
    "objectID": "slides/03-topic-models.html#train-a-topic-model-1",
    "href": "slides/03-topic-models.html#train-a-topic-model-1",
    "title": "Text Mining",
    "section": "Train a topic model",
    "text": "Train a topic model\nUse a sparse matrix or a quanteda::dfm object as input\n\nsummary(topic_model)\n#> A topic model with 4 topics, 102 documents and a 18370 word dictionary.\n#> Topic 1 Top Words:\n#>       Highest Prob: mr, emma, harriet, good, miss, thing, man \n#>       FREX: charade, taylor, papa, isabella, martin, children, marry \n#>       Lift: charade, monarch, hannah, hating, humours, militia, widower \n#>       Score: emma, harriet, knightley, elton, weston, hartfield, martin \n#> Topic 2 Top Words:\n#>       Highest Prob: captain, _nautilus_, sea, nemo, ned, conseil, land \n#>       FREX: _nautilus_, nemo, ned, conseil, ocean, canadian, submarine \n#>       Lift: natives, astrolabe, canoes, galleons, gallons, morses, dillon \n#>       Score: _nautilus_, nemo, ned, conseil, captain, canadian, ocean \n#> Topic 3 Top Words:\n#>       Highest Prob: mr, mrs, emma, miss, weston, thing, jane \n#>       FREX: campbell, dixon, grove, maple, fairfax’s, engagement, jane \n#>       Lift: ford, larkins, patty, ford’s, sucklings, coxes, hodges \n#>       Score: emma, weston, jane, knightley, harriet, elton, mrs \n#> Topic 4 Top Words:\n#>       Highest Prob: time, night, man, back, van, helsing, day \n#>       FREX: helsing, lucy, mina, jonathan, martians, harker, diary \n#>       Lift: scullery, boxes, skinsky, wolves, ogilvy, renfield, galatz \n#>       Score: helsing, martians, lucy, mina, van, jonathan, diary"
  },
  {
    "objectID": "slides/03-topic-models.html#explore-the-topic-model-output",
    "href": "slides/03-topic-models.html#explore-the-topic-model-output",
    "title": "Text Mining",
    "section": "Explore the topic model output",
    "text": "Explore the topic model output\n\nchapter_topics <- tidy(topic_model, matrix = \"beta\")\nchapter_topics\n#> # A tibble: 73,480 × 3\n#>    topic term        beta\n#>    <int> <chr>      <dbl>\n#>  1     1 chapter 5.88e- 3\n#>  2     2 chapter 2.11e- 3\n#>  3     3 chapter 8.87e- 4\n#>  4     4 chapter 6.80e- 4\n#>  5     1 mr      2.82e- 2\n#>  6     2 mr      2.23e- 4\n#>  7     3 mr      1.96e- 2\n#>  8     4 mr      9.58e- 4\n#>  9     1 mrs     5.17e- 3\n#> 10     2 mrs     3.90e-42\n#> # … with 73,470 more rows"
  },
  {
    "objectID": "slides/03-topic-models.html#explore-the-topic-model-output-1",
    "href": "slides/03-topic-models.html#explore-the-topic-model-output-1",
    "title": "Text Mining",
    "section": "Explore the topic model output",
    "text": "Explore the topic model output\nU N S C R A M B L E\ntop_terms <- chapter_topics %>%\nungroup() %>%\ngroup_by(topic) %>%\narrange(topic, -beta)\nslice_max(beta, n = 10) %>%"
  },
  {
    "objectID": "slides/03-topic-models.html#explore-the-topic-model-output-2",
    "href": "slides/03-topic-models.html#explore-the-topic-model-output-2",
    "title": "Text Mining",
    "section": "Explore the topic model output",
    "text": "Explore the topic model output\n\ntop_terms <- chapter_topics %>%\n    group_by(topic) %>%\n    slice_max(beta, n = 10) %>%\n    ungroup() %>%\n    arrange(topic, -beta)"
  },
  {
    "objectID": "slides/03-topic-models.html#explore-the-topic-model-output-3",
    "href": "slides/03-topic-models.html#explore-the-topic-model-output-3",
    "title": "Text Mining",
    "section": "Explore the topic model output",
    "text": "Explore the topic model output\n\ntop_terms\n#> # A tibble: 40 × 3\n#>    topic term         beta\n#>    <int> <chr>       <dbl>\n#>  1     1 mr        0.0282 \n#>  2     1 emma      0.0125 \n#>  3     1 harriet   0.0115 \n#>  4     1 good      0.0105 \n#>  5     1 miss      0.00914\n#>  6     1 thing     0.00787\n#>  7     1 man       0.00764\n#>  8     1 knightley 0.00696\n#>  9     1 elton     0.00680\n#> 10     1 dear      0.00633\n#> # … with 30 more rows"
  },
  {
    "objectID": "slides/03-topic-models.html#explore-the-topic-model-output-4",
    "href": "slides/03-topic-models.html#explore-the-topic-model-output-4",
    "title": "Text Mining",
    "section": "Explore the topic model output",
    "text": "Explore the topic model output\n\ntop_terms %>%\n    mutate(term = fct_reorder(term, beta)) %>%\n    ggplot(aes(beta, term, fill = factor(topic))) + \n    geom_col(show.legend = FALSE) +\n    facet_wrap(vars(topic), scales = \"free\")"
  },
  {
    "objectID": "slides/03-topic-models.html#how-are-documents-classified",
    "href": "slides/03-topic-models.html#how-are-documents-classified",
    "title": "Text Mining",
    "section": "How are documents classified?",
    "text": "How are documents classified?\n\nchapters_gamma <- tidy(topic_model, matrix = \"gamma\",\n                       document_names = rownames(words_sparse))\nchapters_gamma\n#> # A tibble: 408 × 3\n#>    document                                topic    gamma\n#>    <chr>                                   <int>    <dbl>\n#>  1 Emma_0                                      1 0.999   \n#>  2 Emma_7                                      1 0.239   \n#>  3 Emma_2                                      1 0.999   \n#>  4 Emma_8                                      1 0.233   \n#>  5 Emma_11                                     1 0.00103 \n#>  6 Emma_6                                      1 0.999   \n#>  7 Emma_21                                     1 0.000715\n#>  8 Twenty Thousand Leagues under the Sea_0     1 0.000146\n#>  9 Emma_20                                     1 0.000937\n#> 10 Emma_19                                     1 0.000977\n#> # … with 398 more rows"
  },
  {
    "objectID": "slides/03-topic-models.html#how-are-documents-classified-1",
    "href": "slides/03-topic-models.html#how-are-documents-classified-1",
    "title": "Text Mining",
    "section": "How are documents classified?",
    "text": "How are documents classified?\nWhat do you predict will happen if we run the following code? 🤔\n\nchapters_parsed <- chapters_gamma %>%\n    separate(document, c(\"title\", \"chapter\"), \n             sep = \"_\", convert = TRUE)\n\nglimpse(chapters_parsed)"
  },
  {
    "objectID": "slides/03-topic-models.html#how-are-documents-classified-2",
    "href": "slides/03-topic-models.html#how-are-documents-classified-2",
    "title": "Text Mining",
    "section": "How are documents classified?",
    "text": "How are documents classified?\nWhat do you predict will happen if we run the following code? 🤔\n\nchapters_parsed <- chapters_gamma %>%\n    separate(document, c(\"title\", \"chapter\"), \n             sep = \"_\", convert = TRUE)\n\nglimpse(chapters_parsed)\n#> Rows: 408\n#> Columns: 4\n#> $ title   <chr> \"Emma\", \"Emma\", \"Emma\", \"Emma\", \"Emma\", \"Emma\", \"Emma\", \"Twent…\n#> $ chapter <int> 0, 7, 2, 8, 11, 6, 21, 0, 20, 19, 4, 9, 15, 21, 23, 27, 19, 14…\n#> $ topic   <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#> $ gamma   <dbl> 9.986350e-01, 2.387502e-01, 9.988524e-01, 2.325374e-01, 1.0326…"
  },
  {
    "objectID": "slides/03-topic-models.html#how-are-documents-classified-3",
    "href": "slides/03-topic-models.html#how-are-documents-classified-3",
    "title": "Text Mining",
    "section": "How are documents classified?",
    "text": "How are documents classified?\nU N S C R A M B L E\nchapters_parsed %>%\nggplot(aes(factor(topic), gamma)) +\nfacet_wrap(vars(title))\nmutate(title = fct_reorder(title, gamma * topic)) %>%\ngeom_boxplot() +"
  },
  {
    "objectID": "slides/03-topic-models.html#how-are-documents-classified-4",
    "href": "slides/03-topic-models.html#how-are-documents-classified-4",
    "title": "Text Mining",
    "section": "How are documents classified?",
    "text": "How are documents classified?\n\nchapters_parsed %>%\n    mutate(title = fct_reorder(title, gamma * topic)) %>%\n    ggplot(aes(factor(topic), gamma)) +\n    geom_boxplot() +\n    facet_wrap(vars(title))"
  },
  {
    "objectID": "slides/03-topic-models.html#tidying-model-output",
    "href": "slides/03-topic-models.html#tidying-model-output",
    "title": "Text Mining",
    "section": "Tidying model output",
    "text": "Tidying model output\nWhich words in each document are assigned to which topics?\n\naugment()\nAdd information to each observation in the original data"
  },
  {
    "objectID": "slides/03-topic-models.html#using-stm",
    "href": "slides/03-topic-models.html#using-stm",
    "title": "Text Mining",
    "section": "Using stm",
    "text": "Using stm\n\nDocument-level covariates\n\n\ntopic_model <- stm(words_sparse, \n                   K = 0, init.type = \"Spectral\",\n                   prevalence = ~s(Year),\n                   data = covariates,\n                   verbose = FALSE)\n\n\nUse functions for semanticCoherence(), checkResiduals(), exclusivity(), and more!\nCheck out http://www.structuraltopicmodel.com/"
  },
  {
    "objectID": "slides/03-topic-models.html#train-many-topic-models",
    "href": "slides/03-topic-models.html#train-many-topic-models",
    "title": "Text Mining",
    "section": "Train many topic models",
    "text": "Train many topic models\n\nlibrary(furrr)\nplan(multicore)\n\nmany_models <- tibble(K = c(3, 4, 6, 8, 10)) %>% \n    mutate(topic_model = future_map(\n        K, ~stm(words_sparse, K = ., verbose = FALSE))\n    )\n\nmany_models\n#> # A tibble: 5 × 2\n#>       K topic_model\n#>   <dbl> <list>     \n#> 1     3 <STM>      \n#> 2     4 <STM>      \n#> 3     6 <STM>      \n#> 4     8 <STM>      \n#> 5    10 <STM>"
  },
  {
    "objectID": "slides/03-topic-models.html#train-many-topic-models-1",
    "href": "slides/03-topic-models.html#train-many-topic-models-1",
    "title": "Text Mining",
    "section": "Train many topic models",
    "text": "Train many topic models\n\nheldout <- make.heldout(words_sparse)\n\nk_result <- many_models %>%\n    mutate(exclusivity        = map(topic_model, exclusivity),\n           semantic_coherence = map(topic_model, semanticCoherence, words_sparse),\n           eval_heldout       = map(topic_model, eval.heldout, heldout$missing),\n           residual           = map(topic_model, checkResiduals, words_sparse),\n           bound              = map_dbl(topic_model, function(x) max(x$convergence$bound)),\n           lfact              = map_dbl(topic_model, function(x) lfactorial(x$settings$dim$K)),\n           lbound             = bound + lfact,\n           iterations         = map_dbl(topic_model, function(x) length(x$convergence$bound)))"
  },
  {
    "objectID": "slides/03-topic-models.html#train-many-topic-models-2",
    "href": "slides/03-topic-models.html#train-many-topic-models-2",
    "title": "Text Mining",
    "section": "Train many topic models",
    "text": "Train many topic models\n\nk_result\n#> # A tibble: 5 × 10\n#>       K topic_…¹ exclu…² seman…³ eval_heldout residual       bound lfact  lbound\n#>   <dbl> <list>   <list>  <list>  <list>       <list>         <dbl> <dbl>   <dbl>\n#> 1     3 <STM>    <dbl>   <dbl>   <named list> <named list> -1.40e6  1.79 -1.40e6\n#> 2     4 <STM>    <dbl>   <dbl>   <named list> <named list> -1.39e6  3.18 -1.39e6\n#> 3     6 <STM>    <dbl>   <dbl>   <named list> <named list> -1.37e6  6.58 -1.37e6\n#> 4     8 <STM>    <dbl>   <dbl>   <named list> <named list> -1.35e6 10.6  -1.35e6\n#> 5    10 <STM>    <dbl>   <dbl>   <named list> <named list> -1.34e6 15.1  -1.34e6\n#> # … with 1 more variable: iterations <dbl>, and abbreviated variable names\n#> #   ¹​topic_model, ²​exclusivity, ³​semantic_coherence"
  },
  {
    "objectID": "slides/03-topic-models.html#train-many-topic-models-3",
    "href": "slides/03-topic-models.html#train-many-topic-models-3",
    "title": "Text Mining",
    "section": "Train many topic models",
    "text": "Train many topic models\n\nk_result %>%\n    transmute(K,\n              `Lower bound`         = lbound,\n              Residuals             = map_dbl(residual, \"dispersion\"), \n              `Semantic coherence`  = map_dbl(semantic_coherence, mean), \n              `Held-out likelihood` = map_dbl(eval_heldout, \"expected.heldout\")) %>% \n    gather(Metric, Value, -K) %>%\n    ggplot(aes(K, Value, color = Metric)) +\n    geom_line() +\n    facet_wrap(~Metric, scales = \"free_y\")"
  },
  {
    "objectID": "slides/03-topic-models.html#what-is-semantic-coherence",
    "href": "slides/03-topic-models.html#what-is-semantic-coherence",
    "title": "Text Mining",
    "section": "What is semantic coherence?",
    "text": "What is semantic coherence?\n\n\nSemantic coherence is maximized when the most probable words in a given topic frequently co-occur together\nCorrelates well with human judgment of topic quality 😃\nHaving high semantic coherence is relatively easy, though, if you only have a few topics dominated by very common words 😩\nMeasure semantic coherence and exclusivity"
  },
  {
    "objectID": "slides/03-topic-models.html#train-many-topic-models-4",
    "href": "slides/03-topic-models.html#train-many-topic-models-4",
    "title": "Text Mining",
    "section": "Train many topic models",
    "text": "Train many topic models\n\nk_result %>%\n    select(K, exclusivity, semantic_coherence) %>%\n    filter(K %in% c(3, 6, 10)) %>%\n    unnest(cols = c(exclusivity, semantic_coherence)) %>%\n    ggplot(aes(semantic_coherence, exclusivity, \n               color = factor(K))) +\n    geom_point()"
  },
  {
    "objectID": "slides/03-topic-models.html#jane-wants-to-know-2",
    "href": "slides/03-topic-models.html#jane-wants-to-know-2",
    "title": "Text Mining",
    "section": "Jane wants to know…",
    "text": "Jane wants to know…\n\nTopic modeling is an example of…\n\nsupervised machine learning\nunsupervised machine learning\n\n\nhttps://juliasilge.com/blog/evaluating-stm/"
  },
  {
    "objectID": "slides/03-topic-models.html#workflow-for-text-miningmodeling-1",
    "href": "slides/03-topic-models.html#workflow-for-text-miningmodeling-1",
    "title": "Text Mining",
    "section": "Workflow for text mining/modeling",
    "text": "Workflow for text mining/modeling"
  },
  {
    "objectID": "slides/03-topic-models.html#go-explore-real-world-text",
    "href": "slides/03-topic-models.html#go-explore-real-world-text",
    "title": "Text Mining",
    "section": "Go explore real-world text!",
    "text": "Go explore real-world text!"
  },
  {
    "objectID": "slides/04-sml-text.html#lets-install-some-packages",
    "href": "slides/04-sml-text.html#lets-install-some-packages",
    "title": "Text Mining",
    "section": "Let’s install some packages",
    "text": "Let’s install some packages\n\ninstall.packages(c(\"glmnet\", \n                   \"tidyverse\", \n                   \"tidymodels\",\n                   \"textrecipes\",\n                   \"stopwords\",\n                   \"vip\"))"
  },
  {
    "objectID": "slides/04-sml-text.html#section-1",
    "href": "slides/04-sml-text.html#section-1",
    "title": "Text Mining",
    "section": "",
    "text": "library(tidymodels)\n#> ── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n#> ✔ broom        1.0.2     ✔ rsample      1.1.1\n#> ✔ dials        1.1.0     ✔ tune         1.0.1\n#> ✔ infer        1.0.4     ✔ workflows    1.1.2\n#> ✔ modeldata    1.0.1     ✔ workflowsets 1.0.0\n#> ✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n#> ✔ recipes      1.0.3\n#> ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n#> ✖ scales::discard() masks purrr::discard()\n#> ✖ dplyr::filter()   masks stats::filter()\n#> ✖ recipes::fixed()  masks stringr::fixed()\n#> ✖ dplyr::lag()      masks stats::lag()\n#> ✖ yardstick::spec() masks readr::spec()\n#> ✖ recipes::step()   masks stats::step()\n#> • Use tidymodels_prefer() to resolve common conflicts."
  },
  {
    "objectID": "slides/04-sml-text.html#learn-more",
    "href": "slides/04-sml-text.html#learn-more",
    "title": "Text Mining",
    "section": "Learn more",
    "text": "Learn more\n\n\nhttps://www.tidymodels.org/\nTidy Modeling with R\nSupervised Machine Learning for Text Analysis in R"
  },
  {
    "objectID": "slides/04-sml-text.html#download-your-text-data",
    "href": "slides/04-sml-text.html#download-your-text-data",
    "title": "Text Mining",
    "section": "Download your text data",
    "text": "Download your text data\n\nlibrary(tidyverse)\nlibrary(gutenbergr)\n\ntitles <- c(\"The War of the Worlds\",\n            \"Pride and Prejudice\")\n\nbooks <- gutenberg_works(title %in% titles) %>%\n    gutenberg_download(meta_fields = \"title\", mirror = my_mirror) %>%\n    mutate(title = str_replace_all(title, \" \", \"_\")) %>%\n    filter(nchar(text) > 3) %>%\n    mutate(document = row_number())"
  },
  {
    "objectID": "slides/04-sml-text.html#download-your-text-data-1",
    "href": "slides/04-sml-text.html#download-your-text-data-1",
    "title": "Text Mining",
    "section": "Download your text data",
    "text": "Download your text data\n\nbooks\n#> # A tibble: 16,846 × 4\n#>    gutenberg_id text                                               title docum…¹\n#>           <int> <chr>                                              <chr>   <int>\n#>  1           36 \"cover \"                                           The_…       1\n#>  2           36 \"The War of the Worlds\"                            The_…       2\n#>  3           36 \"by H. G. Wells\"                                   The_…       3\n#>  4           36 \"   ‘But who shall dwell in these worlds if they … The_…       4\n#>  5           36 \"    . . . Are we or they Lords of the World? . .… The_…       5\n#>  6           36 \"    how are all things made for man?’\"            The_…       6\n#>  7           36 \"                    KEPLER (quoted in _The Anato… The_…       7\n#>  8           36 \"Contents\"                                         The_…       8\n#>  9           36 \" BOOK ONE.—THE COMING OF THE MARTIANS\"            The_…       9\n#> 10           36 \" I. THE EVE OF THE WAR.\"                          The_…      10\n#> # … with 16,836 more rows, and abbreviated variable name ¹​document"
  },
  {
    "objectID": "slides/04-sml-text.html#spend-your-data-budget-1",
    "href": "slides/04-sml-text.html#spend-your-data-budget-1",
    "title": "Text Mining",
    "section": "Spend your data budget",
    "text": "Spend your data budget\n\nset.seed(123)\nbook_split <- initial_split(books, strata = title)\nbook_split\n#> <Training/Testing/Total>\n#> <12633/4213/16846>"
  },
  {
    "objectID": "slides/04-sml-text.html#spend-your-data-budget-2",
    "href": "slides/04-sml-text.html#spend-your-data-budget-2",
    "title": "Text Mining",
    "section": "Spend your data budget",
    "text": "Spend your data budget\n\nbook_train <- training(book_split)\nbook_train\n#> # A tibble: 12,633 × 4\n#>    gutenberg_id text                                               title docum…¹\n#>           <int> <chr>                                              <chr>   <int>\n#>  1         1342 \"                            [Illustration:\"       Prid…    5310\n#>  2         1342 \"                             GEORGE ALLEN\"        Prid…    5311\n#>  3         1342 \"                               PUBLISHER\"         Prid…    5312\n#>  4         1342 \"                                LONDON\"           Prid…    5314\n#>  5         1342 \"                             RUSKIN HOUSE\"        Prid…    5315\n#>  6         1342 \"                                   ]\"             Prid…    5316\n#>  7         1342 \"               _Reading Jane’s Letters._      _C… Prid…    5318\n#>  8         1342 \"                                PRIDE.\"           Prid…    5320\n#>  9         1342 \"                                  and\"            Prid…    5321\n#> 10         1342 \"                               PREJUDICE\"         Prid…    5322\n#> # … with 12,623 more rows, and abbreviated variable name ¹​document"
  },
  {
    "objectID": "slides/04-sml-text.html#spend-your-data-budget-3",
    "href": "slides/04-sml-text.html#spend-your-data-budget-3",
    "title": "Text Mining",
    "section": "Spend your data budget",
    "text": "Spend your data budget\n\nbook_test <- testing(book_split)\nbook_test\n#> # A tibble: 4,213 × 4\n#>    gutenberg_id text                                               title docum…¹\n#>           <int> <chr>                                              <chr>   <int>\n#>  1           36 \"    how are all things made for man?’\"            The_…       6\n#>  2           36 \"Contents\"                                         The_…       8\n#>  3           36 \" III. ON HORSELL COMMON.\"                         The_…      12\n#>  4           36 \" VI. THE HEAT-RAY IN THE CHOBHAM ROAD.\"           The_…      15\n#>  5           36 \" XV. WHAT HAD HAPPENED IN SURREY.\"                The_…      24\n#>  6           36 \" XVII. THE “THUNDER CHILD”.\"                      The_…      26\n#>  7           36 \" I. UNDER FOOT.\"                                  The_…      28\n#>  8           36 \" IX. WRECKAGE.\"                                   The_…      36\n#>  9           36 \"THE EVE OF THE WAR.\"                              The_…      40\n#> 10           36 \"the mental habits of those departed days. At mos… The_…      53\n#> # … with 4,203 more rows, and abbreviated variable name ¹​document"
  },
  {
    "objectID": "slides/04-sml-text.html#spend-your-data-budget-4",
    "href": "slides/04-sml-text.html#spend-your-data-budget-4",
    "title": "Text Mining",
    "section": "Spend your data budget",
    "text": "Spend your data budget\n\nset.seed(123)\nbook_split <- initial_split(books, strata = title)\nbook_train <- training(book_split) \nnrow(book_train)\n#> [1] 12633\nbook_test <- testing(book_split)\nnrow(book_test)\n#> [1] 4213"
  },
  {
    "objectID": "slides/04-sml-text.html#jane-wants-to-know",
    "href": "slides/04-sml-text.html#jane-wants-to-know",
    "title": "Text Mining",
    "section": "Jane wants to know…",
    "text": "Jane wants to know…\n\nIs the book_split object a tidy dataset?\n\nYes ✅\nNo 🚫"
  },
  {
    "objectID": "slides/04-sml-text.html#spend-your-data-budget-5",
    "href": "slides/04-sml-text.html#spend-your-data-budget-5",
    "title": "Text Mining",
    "section": "Spend your data budget",
    "text": "Spend your data budget\n\nset.seed(234)\nbook_folds <- vfold_cv(book_train, strata = title)\nbook_folds\n#> #  10-fold cross-validation using stratification \n#> # A tibble: 10 × 2\n#>    splits               id    \n#>    <list>               <chr> \n#>  1 <split [11368/1265]> Fold01\n#>  2 <split [11369/1264]> Fold02\n#>  3 <split [11370/1263]> Fold03\n#>  4 <split [11370/1263]> Fold04\n#>  5 <split [11370/1263]> Fold05\n#>  6 <split [11370/1263]> Fold06\n#>  7 <split [11370/1263]> Fold07\n#>  8 <split [11370/1263]> Fold08\n#>  9 <split [11370/1263]> Fold09\n#> 10 <split [11370/1263]> Fold10"
  },
  {
    "objectID": "slides/04-sml-text.html#specify-a-model",
    "href": "slides/04-sml-text.html#specify-a-model",
    "title": "Text Mining",
    "section": "Specify a model",
    "text": "Specify a model\n\n\nPick a model\nSet the mode (if needed)\nSet the engine\n\n\n\nAll available models are listed at https://tidymodels.org/find/parsnip"
  },
  {
    "objectID": "slides/04-sml-text.html#specify-a-model-1",
    "href": "slides/04-sml-text.html#specify-a-model-1",
    "title": "Text Mining",
    "section": "Specify a model",
    "text": "Specify a model\n\nlogistic_reg()\n#> Logistic Regression Model Specification (classification)\n#> \n#> Computational engine: glm"
  },
  {
    "objectID": "slides/04-sml-text.html#specify-a-model-2",
    "href": "slides/04-sml-text.html#specify-a-model-2",
    "title": "Text Mining",
    "section": "Specify a model",
    "text": "Specify a model\nWhat do you predict will happen if we run the following code? 🤔\n\nlogistic_reg() %>%\n    set_engine(\"glmnet\")"
  },
  {
    "objectID": "slides/04-sml-text.html#specify-a-model-3",
    "href": "slides/04-sml-text.html#specify-a-model-3",
    "title": "Text Mining",
    "section": "Specify a model",
    "text": "Specify a model\nWhat do you predict will happen if we run the following code? 🤔\n\nlogistic_reg() %>%\n    set_engine(\"glmnet\")\n#> Logistic Regression Model Specification (classification)\n#> \n#> Computational engine: glmnet"
  },
  {
    "objectID": "slides/04-sml-text.html#specify-a-model-4",
    "href": "slides/04-sml-text.html#specify-a-model-4",
    "title": "Text Mining",
    "section": "Specify a model",
    "text": "Specify a model\nWhat do you predict will happen if we run the following code? 🤔\n\nlogistic_reg(penalty = tune(), mixture = 1) %>%\n    set_engine(\"glmnet\")"
  },
  {
    "objectID": "slides/04-sml-text.html#specify-a-model-5",
    "href": "slides/04-sml-text.html#specify-a-model-5",
    "title": "Text Mining",
    "section": "Specify a model",
    "text": "Specify a model\nWhat do you predict will happen if we run the following code? 🤔\n\nlogistic_reg(penalty = tune(), mixture = 1) %>%\n    set_engine(\"glmnet\")\n#> Logistic Regression Model Specification (classification)\n#> \n#> Main Arguments:\n#>   penalty = tune()\n#>   mixture = 1\n#> \n#> Computational engine: glmnet"
  },
  {
    "objectID": "slides/04-sml-text.html#specify-a-model-6",
    "href": "slides/04-sml-text.html#specify-a-model-6",
    "title": "Text Mining",
    "section": "Specify a model",
    "text": "Specify a model\n\nlasso_spec <- logistic_reg(penalty = tune(), mixture = 1) %>% \n    set_engine(\"glmnet\")\n\nlasso_spec\n#> Logistic Regression Model Specification (classification)\n#> \n#> Main Arguments:\n#>   penalty = tune()\n#>   mixture = 1\n#> \n#> Computational engine: glmnet"
  },
  {
    "objectID": "slides/04-sml-text.html#jane-wants-to-know-1",
    "href": "slides/04-sml-text.html#jane-wants-to-know-1",
    "title": "Text Mining",
    "section": "Jane wants to know…",
    "text": "Jane wants to know…\n\nHave we fit the lasso_spec model to our data yet?\n\nYep 💃\nNot yet 🙅‍♀️"
  },
  {
    "objectID": "slides/04-sml-text.html#section-4",
    "href": "slides/04-sml-text.html#section-4",
    "title": "Text Mining",
    "section": "",
    "text": "Illustration by Allison Horst"
  },
  {
    "objectID": "slides/04-sml-text.html#specify-a-recipe",
    "href": "slides/04-sml-text.html#specify-a-recipe",
    "title": "Text Mining",
    "section": "Specify a recipe",
    "text": "Specify a recipe\n\n\nStart the recipe()\nDefine the variables\nDescribe preprocessing step-by-step\n\n\n\nAll available recipe steps are listed at https://www.tidymodels.org/find/recipes/"
  },
  {
    "objectID": "slides/04-sml-text.html#estimate-using-training-data",
    "href": "slides/04-sml-text.html#estimate-using-training-data",
    "title": "Text Mining",
    "section": "Estimate using training data",
    "text": "Estimate using training data\n\nlibrary(textrecipes)\nrecipe(title ~ text, data = book_train)\n#> Recipe\n#> \n#> Inputs:\n#> \n#>       role #variables\n#>    outcome          1\n#>  predictor          1"
  },
  {
    "objectID": "slides/04-sml-text.html#estimate-using-training-data-1",
    "href": "slides/04-sml-text.html#estimate-using-training-data-1",
    "title": "Text Mining",
    "section": "Estimate using training data",
    "text": "Estimate using training data\nWhat do you predict will happen if we run the following code? 🤔\n\nrecipe(title ~ text, data = book_train) %>%\n    step_tokenize(text)"
  },
  {
    "objectID": "slides/04-sml-text.html#estimate-using-training-data-2",
    "href": "slides/04-sml-text.html#estimate-using-training-data-2",
    "title": "Text Mining",
    "section": "Estimate using training data",
    "text": "Estimate using training data\nWhat do you predict will happen if we run the following code? 🤔\n\nrecipe(title ~ text, data = book_train) %>%\n    step_tokenize(text)  %>%\n    step_stopwords(text)"
  },
  {
    "objectID": "slides/04-sml-text.html#estimate-using-training-data-3",
    "href": "slides/04-sml-text.html#estimate-using-training-data-3",
    "title": "Text Mining",
    "section": "Estimate using training data",
    "text": "Estimate using training data\nWhat do you predict will happen if we run the following code? 🤔\n\nrecipe(title ~ text, data = book_train) %>%\n    step_tokenize(text)  %>%\n    step_stopwords(text)\n#> Recipe\n#> \n#> Inputs:\n#> \n#>       role #variables\n#>    outcome          1\n#>  predictor          1\n#> \n#> Operations:\n#> \n#> Tokenization for text\n#> Stop word removal for text"
  },
  {
    "objectID": "slides/04-sml-text.html#estimate-using-training-data-4",
    "href": "slides/04-sml-text.html#estimate-using-training-data-4",
    "title": "Text Mining",
    "section": "Estimate using training data",
    "text": "Estimate using training data\n\nbook_rec <- recipe(title ~ text, data = book_train) %>%\n    step_tokenize(text)  %>% \n    step_stopwords(text) %>%  \n    step_tokenfilter(text, max_tokens = 500) %>%\n    step_tfidf(text)"
  },
  {
    "objectID": "slides/04-sml-text.html#estimate-using-training-data-5",
    "href": "slides/04-sml-text.html#estimate-using-training-data-5",
    "title": "Text Mining",
    "section": "Estimate using training data",
    "text": "Estimate using training data\n\nbook_rec\n#> Recipe\n#> \n#> Inputs:\n#> \n#>       role #variables\n#>    outcome          1\n#>  predictor          1\n#> \n#> Operations:\n#> \n#> Tokenization for text\n#> Stop word removal for text\n#> Text filtering for text\n#> Term frequency-inverse document frequency with text"
  },
  {
    "objectID": "slides/04-sml-text.html#combine-recipe-and-model",
    "href": "slides/04-sml-text.html#combine-recipe-and-model",
    "title": "Text Mining",
    "section": "Combine recipe and model",
    "text": "Combine recipe and model\n\nbook_wf <- workflow(book_rec, lasso_spec) \nbook_wf\n#> ══ Workflow ════════════════════════════════════════════════════════════════════\n#> Preprocessor: Recipe\n#> Model: logistic_reg()\n#> \n#> ── Preprocessor ────────────────────────────────────────────────────────────────\n#> 4 Recipe Steps\n#> \n#> • step_tokenize()\n#> • step_stopwords()\n#> • step_tokenfilter()\n#> • step_tfidf()\n#> \n#> ── Model ───────────────────────────────────────────────────────────────────────\n#> Logistic Regression Model Specification (classification)\n#> \n#> Main Arguments:\n#>   penalty = tune()\n#>   mixture = 1\n#> \n#> Computational engine: glmnet"
  },
  {
    "objectID": "slides/04-sml-text.html#tune-model-with-resampled-data",
    "href": "slides/04-sml-text.html#tune-model-with-resampled-data",
    "title": "Text Mining",
    "section": "Tune model with resampled data",
    "text": "Tune model with resampled data\n\nnarrower_penalty <- penalty(range = c(-5, 0))\n\nset.seed(2021)\nlasso_grid <- tune_grid(\n    book_wf, \n    resamples = book_folds,\n    param_info = parameters(narrower_penalty),\n    grid = 20\n)"
  },
  {
    "objectID": "slides/04-sml-text.html#tune-model-with-resampled-data-1",
    "href": "slides/04-sml-text.html#tune-model-with-resampled-data-1",
    "title": "Text Mining",
    "section": "Tune model with resampled data",
    "text": "Tune model with resampled data\n\nlasso_grid\n#> # Tuning results\n#> # 10-fold cross-validation using stratification \n#> # A tibble: 10 × 4\n#>    splits               id     .metrics          .notes          \n#>    <list>               <chr>  <list>            <list>          \n#>  1 <split [11368/1265]> Fold01 <tibble [40 × 5]> <tibble [0 × 3]>\n#>  2 <split [11369/1264]> Fold02 <tibble [40 × 5]> <tibble [0 × 3]>\n#>  3 <split [11370/1263]> Fold03 <tibble [40 × 5]> <tibble [0 × 3]>\n#>  4 <split [11370/1263]> Fold04 <tibble [40 × 5]> <tibble [0 × 3]>\n#>  5 <split [11370/1263]> Fold05 <tibble [40 × 5]> <tibble [0 × 3]>\n#>  6 <split [11370/1263]> Fold06 <tibble [40 × 5]> <tibble [0 × 3]>\n#>  7 <split [11370/1263]> Fold07 <tibble [40 × 5]> <tibble [0 × 3]>\n#>  8 <split [11370/1263]> Fold08 <tibble [40 × 5]> <tibble [0 × 3]>\n#>  9 <split [11370/1263]> Fold09 <tibble [40 × 5]> <tibble [0 × 3]>\n#> 10 <split [11370/1263]> Fold10 <tibble [40 × 5]> <tibble [0 × 3]>"
  },
  {
    "objectID": "slides/04-sml-text.html#evaluate-models",
    "href": "slides/04-sml-text.html#evaluate-models",
    "title": "Text Mining",
    "section": "Evaluate models",
    "text": "Evaluate models\n\nshow_best(lasso_grid)\n#> # A tibble: 5 × 7\n#>     penalty .metric .estimator  mean     n std_err .config              \n#>       <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n#> 1 0.0000166 roc_auc binary     0.913    10 0.00229 Preprocessor1_Model01\n#> 2 0.0000255 roc_auc binary     0.913    10 0.00229 Preprocessor1_Model02\n#> 3 0.0000529 roc_auc binary     0.913    10 0.00231 Preprocessor1_Model03\n#> 4 0.000700  roc_auc binary     0.913    10 0.00236 Preprocessor1_Model08\n#> 5 0.0000921 roc_auc binary     0.913    10 0.00232 Preprocessor1_Model04"
  },
  {
    "objectID": "slides/04-sml-text.html#evaluate-models-1",
    "href": "slides/04-sml-text.html#evaluate-models-1",
    "title": "Text Mining",
    "section": "Evaluate models",
    "text": "Evaluate models\n\nautoplot(lasso_grid)"
  },
  {
    "objectID": "slides/04-sml-text.html#finalize-and-fit-workflow",
    "href": "slides/04-sml-text.html#finalize-and-fit-workflow",
    "title": "Text Mining",
    "section": "Finalize and fit workflow",
    "text": "Finalize and fit workflow\n\nsimple_lasso <- select_by_one_std_err(\n    lasso_grid, \n    -penalty, \n    metric = \"roc_auc\"\n)\n\nsimple_lasso\n#> # A tibble: 1 × 9\n#>   penalty .metric .estimator  mean     n std_err .config            .best .bound\n#>     <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>              <dbl>  <dbl>\n#> 1 0.00228 roc_auc binary     0.911    10 0.00229 Preprocessor1_Mod… 0.913  0.911"
  },
  {
    "objectID": "slides/04-sml-text.html#finalize-and-fit-workflow-1",
    "href": "slides/04-sml-text.html#finalize-and-fit-workflow-1",
    "title": "Text Mining",
    "section": "Finalize and fit workflow",
    "text": "Finalize and fit workflow\n\nbook_final <- book_wf %>%\n    finalize_workflow(simple_lasso) %>% \n    last_fit(book_split) \n\ncollect_metrics(book_final)\n#> # A tibble: 2 × 4\n#>   .metric  .estimator .estimate .config             \n#>   <chr>    <chr>          <dbl> <chr>               \n#> 1 accuracy binary         0.838 Preprocessor1_Model1\n#> 2 roc_auc  binary         0.910 Preprocessor1_Model1"
  },
  {
    "objectID": "slides/04-sml-text.html#evaluate-final-model",
    "href": "slides/04-sml-text.html#evaluate-final-model",
    "title": "Text Mining",
    "section": "Evaluate final model",
    "text": "Evaluate final model\n\ncollect_predictions(book_final)\n#> # A tibble: 4,213 × 7\n#>    id               .pred_Pride_and_Prejud…¹ .pred…²  .row .pred…³ title .config\n#>    <chr>                               <dbl>   <dbl> <int> <fct>   <fct> <chr>  \n#>  1 train/test split                   0.269    0.731     6 The_Wa… The_… Prepro…\n#>  2 train/test split                   0.657    0.343     8 Pride_… The_… Prepro…\n#>  3 train/test split                   0.111    0.889    12 The_Wa… The_… Prepro…\n#>  4 train/test split                   0.0112   0.989    15 The_Wa… The_… Prepro…\n#>  5 train/test split                   0.607    0.393    24 Pride_… The_… Prepro…\n#>  6 train/test split                   0.657    0.343    26 Pride_… The_… Prepro…\n#>  7 train/test split                   0.657    0.343    28 Pride_… The_… Prepro…\n#>  8 train/test split                   0.657    0.343    36 Pride_… The_… Prepro…\n#>  9 train/test split                   0.657    0.343    40 Pride_… The_… Prepro…\n#> 10 train/test split                   0.0752   0.925    53 The_Wa… The_… Prepro…\n#> # … with 4,203 more rows, and abbreviated variable names\n#> #   ¹​.pred_Pride_and_Prejudice, ²​.pred_The_War_of_the_Worlds, ³​.pred_class"
  },
  {
    "objectID": "slides/04-sml-text.html#evaluate-final-model-1",
    "href": "slides/04-sml-text.html#evaluate-final-model-1",
    "title": "Text Mining",
    "section": "Evaluate final model",
    "text": "Evaluate final model\n\ncollect_predictions(book_final) %>%\n    conf_mat(title, .pred_class)\n#>                        Truth\n#> Prediction              Pride_and_Prejudice The_War_of_the_Worlds\n#>   Pride_and_Prejudice                  2712                   509\n#>   The_War_of_the_Worlds                 173                   819"
  },
  {
    "objectID": "slides/04-sml-text.html#evaluate-final-model-2",
    "href": "slides/04-sml-text.html#evaluate-final-model-2",
    "title": "Text Mining",
    "section": "Evaluate final model",
    "text": "Evaluate final model\n\ncollect_predictions(book_final) %>%\n    roc_curve(title, .pred_Pride_and_Prejudice) %>% \n    autoplot()"
  },
  {
    "objectID": "slides/04-sml-text.html#jane-wants-to-know-2",
    "href": "slides/04-sml-text.html#jane-wants-to-know-2",
    "title": "Text Mining",
    "section": "Jane wants to know…",
    "text": "Jane wants to know…\n\nIs this the ROC curve for the training or testing data?\n\nTraining\nTesting"
  },
  {
    "objectID": "slides/04-sml-text.html#variable-importance",
    "href": "slides/04-sml-text.html#variable-importance",
    "title": "Text Mining",
    "section": "Variable importance",
    "text": "Variable importance\n\nlibrary(vip)\nbook_vip <- \n    extract_fit_engine(book_final) %>%\n    vi()\n\nbook_vip\n#> # A tibble: 500 × 3\n#>    Variable             Importance Sign \n#>    <chr>                     <dbl> <chr>\n#>  1 tfidf_text_elizabeth      10.2  NEG  \n#>  2 tfidf_text_mr              8.25 NEG  \n#>  3 tfidf_text_bennet          7.73 NEG  \n#>  4 tfidf_text_martians        7.45 POS  \n#>  5 tfidf_text_jane            7.01 NEG  \n#>  6 tfidf_text_bingley         6.92 NEG  \n#>  7 tfidf_text_darcy           6.89 NEG  \n#>  8 tfidf_text_wickham         6.44 NEG  \n#>  9 tfidf_text_father          6.00 NEG  \n#> 10 tfidf_text_longbourn       5.78 NEG  \n#> # … with 490 more rows"
  },
  {
    "objectID": "slides/04-sml-text.html#variable-importance-1",
    "href": "slides/04-sml-text.html#variable-importance-1",
    "title": "Text Mining",
    "section": "Variable importance",
    "text": "Variable importance\n\nbook_vip %>%\n    group_by(Sign) %>%\n    slice_max(abs(Importance), n = 15) %>%\n    ungroup() %>%\n    mutate(\n        Importance = abs(Importance),\n        Variable = fct_reorder(Variable, Importance)\n    ) %>%\n    ggplot(aes(Importance, Variable, fill = Sign)) + \n    geom_col() +\n    facet_wrap(vars(Sign))"
  },
  {
    "objectID": "slides/04-sml-text.html#jane-wants-to-know-3",
    "href": "slides/04-sml-text.html#jane-wants-to-know-3",
    "title": "Text Mining",
    "section": "Jane wants to know…",
    "text": "Jane wants to know…\n\nText classification is an example of…\n\nsupervised machine learning\nunsupervised machine learning"
  },
  {
    "objectID": "slides/04-sml-text.html#go-explore-real-world-text",
    "href": "slides/04-sml-text.html#go-explore-real-world-text",
    "title": "Text Mining",
    "section": "Go explore real-world text!",
    "text": "Go explore real-world text!"
  },
  {
    "objectID": "slides/03-topic-models.html#high-frex-words",
    "href": "slides/03-topic-models.html#high-frex-words",
    "title": "Text Mining",
    "section": "High FREX words",
    "text": "High FREX words\nHigh frequency and high exclusivity\n\ntidy(topic_model, matrix = \"frex\")\n#> # A tibble: 73,480 × 2\n#>    topic term    \n#>    <int> <chr>   \n#>  1     1 charade \n#>  2     1 taylor  \n#>  3     1 papa    \n#>  4     1 isabella\n#>  5     1 martin  \n#>  6     1 children\n#>  7     1 marry   \n#>  8     1 pretty  \n#>  9     1 likeness\n#> 10     1 marriage\n#> # … with 73,470 more rows"
  },
  {
    "objectID": "slides/03-topic-models.html#high-lift-words",
    "href": "slides/03-topic-models.html#high-lift-words",
    "title": "Text Mining",
    "section": "High lift words",
    "text": "High lift words\nTopic-word distribution divided by word count distribution\n\ntidy(topic_model, matrix = \"lift\")\n#> # A tibble: 73,480 × 2\n#>    topic term       \n#>    <int> <chr>      \n#>  1     1 charade    \n#>  2     1 monarch    \n#>  3     1 hannah     \n#>  4     1 hating     \n#>  5     1 humours    \n#>  6     1 militia    \n#>  7     1 widower    \n#>  8     1 likenesses \n#>  9     1 subjection \n#> 10     1 _courtship_\n#> # … with 73,470 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#currently-2.5-journals-transcribed-from-1871-1875",
    "href": "slides/01-tidytext.html#currently-2.5-journals-transcribed-from-1871-1875",
    "title": "Text Mining",
    "section": "Currently 2.5 journals transcribed from 1871-1875",
    "text": "Currently 2.5 journals transcribed from 1871-1875\n\n\nlibrary(readxl)\njournal &lt;- read_excel(\"data/journal_year_1871_1872.xlsx\")\n\njournal %&gt;%\n    select(date_mdy, month, journal_entry) %&gt;%\n    head()\n#&gt; # A tibble: 6 x 3\n#&gt;   date_mdy   month    journal_entry                                             \n#&gt;   &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;                                                     \n#&gt; 1 12/23/1871 December Was married at home in evening by William Rand Esqr.      \n#&gt; 2 12/24/1871 December Went to meeting.                                          \n#&gt; 3 12/25/1871 December Shooting match all day in the evening to Christmas tree a~\n#&gt; 4 12/26/1871 December About home at work fobbing.                               \n#&gt; 5 12/27/1871 December Work about home reed letter from N. H. Higgins Ins agt.   \n#&gt; 6 12/28/1871 December Work about home."
  },
  {
    "objectID": "slides/01-tidytext.html#section-6",
    "href": "slides/01-tidytext.html#section-6",
    "title": "Text Mining",
    "section": "1871-1872",
    "text": "1871-1872\n\n\n(tidy_journal &lt;- journal %&gt;%\n    select(date_mdy, month, journal_entry) %&gt;%\n    unnest_tokens(word, journal_entry))\n#&gt; # A tibble: 3,576 x 3\n#&gt;    date_mdy   month    word   \n#&gt;    &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;  \n#&gt;  1 12/23/1871 December was    \n#&gt;  2 12/23/1871 December married\n#&gt;  3 12/23/1871 December at     \n#&gt;  4 12/23/1871 December home   \n#&gt;  5 12/23/1871 December in     \n#&gt;  6 12/23/1871 December evening\n#&gt;  7 12/23/1871 December by     \n#&gt;  8 12/23/1871 December william\n#&gt;  9 12/23/1871 December rand   \n#&gt; 10 12/23/1871 December esqr   \n#&gt; # ... with 3,566 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#currently-2.5-journals-transcribed-from-1871-1874",
    "href": "slides/01-tidytext.html#currently-2.5-journals-transcribed-from-1871-1874",
    "title": "Text Mining",
    "section": "Currently 2.5 journals transcribed from 1871-1874",
    "text": "Currently 2.5 journals transcribed from 1871-1874\n\n\nlibrary(readxl)\njournal_1871_1872 &lt;- read_excel(\"data/journal_year_1871_1872.xlsx\")\n\njournal_1871_1872 %&gt;%\n    select(date_mdy, month, journal_entry) %&gt;%\n    head()\n#&gt; # A tibble: 6 x 3\n#&gt;   date_mdy   month    journal_entry                                             \n#&gt;   &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;                                                     \n#&gt; 1 12/23/1871 December Was married at home in evening by William Rand Esqr.      \n#&gt; 2 12/24/1871 December Went to meeting.                                          \n#&gt; 3 12/25/1871 December Shooting match all day in the evening to Christmas tree a~\n#&gt; 4 12/26/1871 December About home at work fobbing.                               \n#&gt; 5 12/27/1871 December Work about home reed letter from N. H. Higgins Ins agt.   \n#&gt; 6 12/28/1871 December Work about home."
  },
  {
    "objectID": "slides/01-tidytext.html#currently-2.5-journals-transcribed-from-1871-1874-1",
    "href": "slides/01-tidytext.html#currently-2.5-journals-transcribed-from-1871-1874-1",
    "title": "Text Mining",
    "section": "Currently 2.5 journals transcribed from 1871-1874",
    "text": "Currently 2.5 journals transcribed from 1871-1874\n\n\njournal %&gt;%\n    select(date_mdy, month, journal_entry) %&gt;%\n    unnest_tokens(word, journal_entry)\n#&gt; # A tibble: 3,576 x 3\n#&gt;    date_mdy   month    word   \n#&gt;    &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;  \n#&gt;  1 12/23/1871 December was    \n#&gt;  2 12/23/1871 December married\n#&gt;  3 12/23/1871 December at     \n#&gt;  4 12/23/1871 December home   \n#&gt;  5 12/23/1871 December in     \n#&gt;  6 12/23/1871 December evening\n#&gt;  7 12/23/1871 December by     \n#&gt;  8 12/23/1871 December william\n#&gt;  9 12/23/1871 December rand   \n#&gt; 10 12/23/1871 December esqr   \n#&gt; # ... with 3,566 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#most-common-words",
    "href": "slides/01-tidytext.html#most-common-words",
    "title": "Text Mining",
    "section": "Most common words",
    "text": "Most common words\n\ntidy_journal %>%\n    count(word, sort = TRUE)\n#> # A tibble: 4,109 × 2\n#>    word            n\n#>    <chr>       <int>\n#>  1 the          5116\n#>  2 wind         3052\n#>  3 and          2301\n#>  4 in           2181\n#>  5 to           1959\n#>  6 at           1422\n#>  7 thermometer  1071\n#>  8 of            948\n#>  9 west          933\n#> 10 went          909\n#> # ℹ 4,099 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#removing-stop-words",
    "href": "slides/01-tidytext.html#removing-stop-words",
    "title": "Text Mining",
    "section": "Removing stop words",
    "text": "Removing stop words\n\ntidy_journal %>%\n    anti_join(get_stopwords(source = \"smart\")) %>%\n    count(word, sort = TRUE) %>%\n    slice_max(n, n = 20) %>%\n    ggplot(aes(n, fct_reorder(word, n))) +  \n    geom_col()"
  },
  {
    "objectID": "slides/01-tidytext.html#removing-stop-words-1",
    "href": "slides/01-tidytext.html#removing-stop-words-1",
    "title": "Text Mining",
    "section": "Removing stop words",
    "text": "Removing stop words"
  },
  {
    "objectID": "slides/01-tidytext.html#any-stopwords-we-should-add",
    "href": "slides/01-tidytext.html#any-stopwords-we-should-add",
    "title": "Text Mining",
    "section": "Any stopwords we should add?",
    "text": "Any stopwords we should add?\n\njournals %&gt;%\n    filter(str_detect(journal_entry, pattern = \"cc\")) %&gt;%\n    select(journal_entry) %&gt;%\n    head(1)\n#&gt; # A tibble: 1 x 1\n#&gt;   journal_entry                                                                 \n#&gt;   &lt;chr&gt;                                                                         \n#&gt; 1 acknowledged deed for C Stevens and deeded all my right of the Estate to Jami~"
  },
  {
    "objectID": "slides/01-tidytext.html#after-removing-stop-words",
    "href": "slides/01-tidytext.html#after-removing-stop-words",
    "title": "Text Mining",
    "section": "After removing stop words 🦞 🍳 🥗",
    "text": "After removing stop words 🦞 🍳 🥗"
  },
  {
    "objectID": "slides/01-tidytext.html#work-boats-meals-and-goods",
    "href": "slides/01-tidytext.html#work-boats-meals-and-goods",
    "title": "Text Mining",
    "section": "Work, Boats, Meals, and Goods 🍳 ⛵🦞 🪵",
    "text": "Work, Boats, Meals, and Goods 🍳 ⛵🦞 🪵"
  },
  {
    "objectID": "slides/01-tidytext.html#work-boats-meals-goods",
    "href": "slides/01-tidytext.html#work-boats-meals-goods",
    "title": "Text Mining",
    "section": "Work, Boats, Meals, Goods 🍳 ⛵🦞 🪵",
    "text": "Work, Boats, Meals, Goods 🍳 ⛵🦞 🪵"
  },
  {
    "objectID": "slides/01-tidytext.html#all-journals",
    "href": "slides/01-tidytext.html#all-journals",
    "title": "Text Mining",
    "section": "All Journals",
    "text": "All Journals\n\n\njournal_1873 <- read_excel(\"data/journal_1873.xlsx\")\njournal_1874 <- read_excel(\"data/journal_1874.xlsx\")\njournal_1875 <- read_excel(\"data/journal_1875.xlsx\")\njournal_1876 <- read_excel(\"data/journal_1876.xlsx\")\njournal_1877 <- read_excel(\"data/journal_1877.xlsx\")\njournal_1878 <- read_excel(\"data/journal_1878.xlsx\")\njournal_1879 <- read_excel(\"data/journal_1879.xlsx\")\njournal_1880 <- read_excel(\"data/journal_1880.xlsx\")"
  },
  {
    "objectID": "slides/01-tidytext.html#tidy-journals",
    "href": "slides/01-tidytext.html#tidy-journals",
    "title": "Text Mining",
    "section": "Tidy Journals",
    "text": "Tidy Journals\n\nlibrary(lubridate)\n(tidy_journal <- journals %>%\n    select(date_mdy, month, journal_entry, journal) %>%\n    mutate(date_mdy = mdy(date_mdy)) %>%\n    mutate(year = year(date_mdy)) %>%\n    unnest_tokens(word, journal_entry)  %>%\n    mutate(word = case_when(word %in% c(\"reed\", \"read\") ~ \"received\",\n                            TRUE ~ word)))\n#> # A tibble: 65,118 × 5\n#>    date_mdy   month    journal  year word   \n#>    <date>     <chr>      <dbl> <dbl> <chr>  \n#>  1 1871-12-23 December       1  1871 was    \n#>  2 1871-12-23 December       1  1871 married\n#>  3 1871-12-23 December       1  1871 at     \n#>  4 1871-12-23 December       1  1871 home   \n#>  5 1871-12-23 December       1  1871 in     \n#>  6 1871-12-23 December       1  1871 evening\n#>  7 1871-12-23 December       1  1871 by     \n#>  8 1871-12-23 December       1  1871 william\n#>  9 1871-12-23 December       1  1871 rand   \n#> 10 1871-12-23 December       1  1871 esqr   \n#> # ℹ 65,108 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#journal-1-work-boats-meals-goods",
    "href": "slides/01-tidytext.html#journal-1-work-boats-meals-goods",
    "title": "Text Mining",
    "section": "Journal 1: Work, Boats, Meals, Goods 🍳 ⛵🦞 🪵",
    "text": "Journal 1: Work, Boats, Meals, Goods 🍳 ⛵🦞 🪵"
  },
  {
    "objectID": "slides/01-tidytext.html#journal-1-boats-meals-goods",
    "href": "slides/01-tidytext.html#journal-1-boats-meals-goods",
    "title": "Text Mining",
    "section": "Journal 1: Boats, Meals, Goods 🍳 ⛵🦞 🪵",
    "text": "Journal 1: Boats, Meals, Goods 🍳 ⛵🦞 🪵"
  },
  {
    "objectID": "slides/01-tidytext.html#journal-2-boats-meals-goods",
    "href": "slides/01-tidytext.html#journal-2-boats-meals-goods",
    "title": "Text Mining",
    "section": "Journal 2: Boats, Meals, Goods 🍳 ⛵🦞 🪵",
    "text": "Journal 2: Boats, Meals, Goods 🍳 ⛵🦞 🪵"
  },
  {
    "objectID": "slides/01-tidytext.html#journal-2-boats-meals-goods-nesw",
    "href": "slides/01-tidytext.html#journal-2-boats-meals-goods-nesw",
    "title": "Text Mining",
    "section": "Journal 2: Boats, Meals, Goods ⛵NESW",
    "text": "Journal 2: Boats, Meals, Goods ⛵NESW"
  },
  {
    "objectID": "slides/01-tidytext.html#journal-2-boats-wind-direction-nesw",
    "href": "slides/01-tidytext.html#journal-2-boats-wind-direction-nesw",
    "title": "Text Mining",
    "section": "Journal 2: Boats, Wind Direction ⛵NESW",
    "text": "Journal 2: Boats, Wind Direction ⛵NESW"
  },
  {
    "objectID": "slides/01-tidytext.html#journal-2-wind-and-weather-nesw",
    "href": "slides/01-tidytext.html#journal-2-wind-and-weather-nesw",
    "title": "Text Mining",
    "section": "Journal 2: Wind and Weather ☁︎ NESW",
    "text": "Journal 2: Wind and Weather ☁︎ NESW"
  },
  {
    "objectID": "slides/01-tidytext.html#your-turn-what-were-the-most-common-words-in-journal-3-and-4",
    "href": "slides/01-tidytext.html#your-turn-what-were-the-most-common-words-in-journal-3-and-4",
    "title": "Text Mining",
    "section": "Your Turn: What were the most common words in Journal 3 and 4?",
    "text": "Your Turn: What were the most common words in Journal 3 and 4?"
  },
  {
    "objectID": "slides/01-tidytext.html#implementing-sentiment-analysis-4",
    "href": "slides/01-tidytext.html#implementing-sentiment-analysis-4",
    "title": "Text Mining",
    "section": "Implementing sentiment analysis",
    "text": "Implementing sentiment analysis\n\ntidy_journal %>%\n    inner_join(get_sentiments(\"bing\")) %>%            \n    count(sentiment, word, sort = TRUE)   \n#> # A tibble: 198 × 3\n#>    sentiment word         n\n#>    <chr>     <chr>    <int>\n#>  1 positive  work       802\n#>  2 positive  breeze     251\n#>  3 positive  fresh      199\n#>  4 positive  calm       177\n#>  5 positive  pleasant   119\n#>  6 positive  worked      97\n#>  7 positive  good        85\n#>  8 negative  cold        75\n#>  9 positive  ready       73\n#> 10 negative  dark        71\n#> # ℹ 188 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#implementing-sentiment-analysis-5",
    "href": "slides/01-tidytext.html#implementing-sentiment-analysis-5",
    "title": "Text Mining",
    "section": "Implementing sentiment analysis",
    "text": "Implementing sentiment analysis\n\ntidy_journal %>%\n    inner_join(get_sentiments(\"bing\")) %>%\n    count(sentiment, word, sort = TRUE) %>%\n    group_by(sentiment) %>%\n    slice_max(n, n = 10) %>%\n    ungroup() %>%\n    ggplot(aes(n, fct_reorder(word, n), fill = sentiment)) +\n    geom_col() +\n    facet_wrap(vars(sentiment), scales = \"free\")"
  },
  {
    "objectID": "slides/01-tidytext.html#n-grams-and-beyond",
    "href": "slides/01-tidytext.html#n-grams-and-beyond",
    "title": "Text Mining",
    "section": "N-grams… and beyond! 🚀",
    "text": "N-grams… and beyond! 🚀\n\ntidy_ngram %>%\n    count(bigram, sort = TRUE)\n#> # A tibble: 19,415 × 2\n#>    bigram             n\n#>    <chr>          <int>\n#>  1 the wind        2760\n#>  2 in the           735\n#>  3 wind north       572\n#>  4 went to          557\n#>  5 wind southerly   543\n#>  6 all day          483\n#>  7 north west       402\n#>  8 wind south       378\n#>  9 the afternoon    292\n#> 10 work in          273\n#> # ℹ 19,405 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#jane-wants-to-know-2",
    "href": "slides/01-tidytext.html#jane-wants-to-know-2",
    "title": "Text Mining",
    "section": "Jane wants to know…",
    "text": "Jane wants to know…\n\nCan we use an anti_join() now to remove stop words?\n\nYes! ✅\nNo ☹️"
  },
  {
    "objectID": "slides/01-tidytext.html#n-grams-and-beyond-1",
    "href": "slides/01-tidytext.html#n-grams-and-beyond-1",
    "title": "Text Mining",
    "section": "N-grams… and beyond! 🚀",
    "text": "N-grams… and beyond! 🚀\n\nbigram_counts <- tidy_ngram %>%\n    separate(bigram, c(\"word1\", \"word2\"), sep = \" \") %>%\n    filter(!word1 %in% stop_words$word,\n           !word2 %in% stop_words$word) %>%\n    count(word1, word2, sort = TRUE)"
  },
  {
    "objectID": "slides/01-tidytext.html#so-many-wind-directions",
    "href": "slides/01-tidytext.html#so-many-wind-directions",
    "title": "Text Mining",
    "section": "So many wind directions…! 🚀",
    "text": "So many wind directions…! 🚀\n\nbigram_counts\n#> # A tibble: 7,244 × 3\n#>    word1 word2           n\n#>    <chr> <chr>       <int>\n#>  1 wind  north         572\n#>  2 wind  southerly     543\n#>  3 north west          402\n#>  4 wind  south         378\n#>  5 south west          271\n#>  6 wrote letter        263\n#>  7 wind  easterly      243\n#>  8 west  thermometer   186\n#>  9 wind  westerly      182\n#> 10 fresh breeze        175\n#> # ℹ 7,234 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#lets-tidy-these-up",
    "href": "slides/01-tidytext.html#lets-tidy-these-up",
    "title": "Text Mining",
    "section": "Let’s tidy these up",
    "text": "Let’s tidy these up\n\nbigram_counts <- tidy_ngram %>%\n    separate(bigram, c(\"word1\", \"word2\"), sep = \" \") %>%\n    filter(!word1 %in% stop_words$word,\n           !word2 %in% stop_words$word) %>%\n    mutate(word1 = case_when(word1 == \"easterly\" ~ \"east\",\n                             word1 == \"southerly\" ~ \"south\",\n                             word1 == \"n.w\" ~ \"northwest\",\n                             word1 == \"northerly\" ~ \"north\",\n                             word1 == \"westerly\" ~ \"west\",\n           TRUE ~ word1)) %>%\n    mutate(word2 = case_when(word2 == \"easterly\" ~ \"east\",\n                             word2 == \"southerly\" ~ \"south\",\n                             word2 == \"n.w\" ~ \"northwest\",\n                             word2 == \"northerly\" ~ \"north\",\n                             word2 == \"westerly\" ~ \"west\",\n           TRUE ~ word2)) %>%\n    count(word1, word2, sort = TRUE)"
  },
  {
    "objectID": "slides/01-tidytext.html#removing-wind",
    "href": "slides/01-tidytext.html#removing-wind",
    "title": "Text Mining",
    "section": "Removing wind",
    "text": "Removing wind\n\nbigram_counts %>%\n    filter(word1 != \"wind\" & word1 != \"north\" & word1 != \"south\")\n#> # A tibble: 6,950 × 3\n#>    word1 word2           n\n#>    <chr> <chr>       <int>\n#>  1 wrote letter        263\n#>  2 west  thermometer   226\n#>  3 fresh breeze        175\n#>  4 west  gouldsboro    116\n#>  5 east  thermometer    97\n#>  6 reed  letter         96\n#>  7 recd  letter         84\n#>  8 heavy rain           82\n#>  9 wm    guptill        67\n#> 10 wrote letters        66\n#> # ℹ 6,940 more rows"
  },
  {
    "objectID": "slides/01-tidytext.html#currently-9-journals-transcribed-from-1871-1880",
    "href": "slides/01-tidytext.html#currently-9-journals-transcribed-from-1871-1880",
    "title": "Text Mining",
    "section": "Currently 9 journals transcribed from 1871-1880",
    "text": "Currently 9 journals transcribed from 1871-1880\n\n\nlibrary(readxl)\njournal_1871_1872 <- read_excel(\"data/journal_1871_1872.xlsx\")\njournal_1871_1872 %>%\n    select(date_mdy, month, journal_entry) %>%\n    head()\n#> # A tibble: 6 × 3\n#>   date_mdy   month    journal_entry                                             \n#>   <chr>      <chr>    <chr>                                                     \n#> 1 12/23/1871 December Was married at home in evening by William Rand Esqr.      \n#> 2 12/24/1871 December Went to meeting.                                          \n#> 3 12/25/1871 December Shooting match all day in the evening to Christmas tree a…\n#> 4 12/26/1871 December About home at work fobbing.                               \n#> 5 12/27/1871 December Work about home reed letter from N. H. Higgins Ins agt.   \n#> 6 12/28/1871 December Work about home."
  },
  {
    "objectID": "slides/01-tidytext.html#keeping-track",
    "href": "slides/01-tidytext.html#keeping-track",
    "title": "Text Mining",
    "section": "Keeping Track",
    "text": "Keeping Track\n\n\n\n\n# We want to keep track of the journals\n\njournal_1871_1872$journal <- 1\njournal_1873$journal <- 2\njournal_1874$journal <- 3\njournal_1875$journal <- 4\njournal_1876$journal <- 5\njournal_1877$journal <- 6\njournal_1878$journal <- 7\njournal_1879$journal <- 8\njournal_1880$journal <- 9\n\njournals <- dplyr::bind_rows(journal_1871_1872, journal_1873, journal_1874, \n                             journal_1875, journal_1876, journal_1877, \n                             journal_1878, journal_1879, journal_1880)"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#lets-install-some-packages",
    "href": "slides/01-fb-tidytext.html#lets-install-some-packages",
    "title": "Mining Historical Texts",
    "section": "Let’s install some packages",
    "text": "Let’s install some packages\n\ninstall.packages(c(\"tidyverse\", # data wrangling\n                   \"tidytext\", # text analysis\n                   \"stopwords\", # stop words\n                   \"lubridate\", # dates\n                   \"readxl\")) # reading data"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#what-do-we-mean-by-tidy-text",
    "href": "slides/01-fb-tidytext.html#what-do-we-mean-by-tidy-text",
    "title": "Mining Historical Texts",
    "section": "What do we mean by tidy text?",
    "text": "What do we mean by tidy text?\n\n\njournal_text <- c(\"Was married at home in evening by William Rand Esqr.\",\n          \"Went to meeting.\",\n          \"Shooting match all day in the evening to Christmas Tree at the Hall.\",\n          \"About home at work fobbing.\",\n          \"Work about home.\",\n          \"To work in shop.\",\n          \"To work in shop.\",\n          \"Went to meeting.\")\n\njournal_text\n#> [1] \"Was married at home in evening by William Rand Esqr.\"                \n#> [2] \"Went to meeting.\"                                                    \n#> [3] \"Shooting match all day in the evening to Christmas Tree at the Hall.\"\n#> [4] \"About home at work fobbing.\"                                         \n#> [5] \"Work about home.\"                                                    \n#> [6] \"To work in shop.\"                                                    \n#> [7] \"To work in shop.\"                                                    \n#> [8] \"Went to meeting.\""
  },
  {
    "objectID": "slides/01-fb-tidytext.html#what-do-we-mean-by-tidy-text-1",
    "href": "slides/01-fb-tidytext.html#what-do-we-mean-by-tidy-text-1",
    "title": "Mining Historical Texts",
    "section": "What do we mean by tidy text?",
    "text": "What do we mean by tidy text?\n\n\nlibrary(tidyverse)\n\njournal_df <- tibble(line = 1:8, text = journal_text)\n\njournal_df\n#> # A tibble: 8 × 2\n#>    line text                                                                \n#>   <int> <chr>                                                               \n#> 1     1 Was married at home in evening by William Rand Esqr.                \n#> 2     2 Went to meeting.                                                    \n#> 3     3 Shooting match all day in the evening to Christmas Tree at the Hall.\n#> 4     4 About home at work fobbing.                                         \n#> 5     5 Work about home.                                                    \n#> 6     6 To work in shop.                                                    \n#> 7     7 To work in shop.                                                    \n#> 8     8 Went to meeting."
  },
  {
    "objectID": "slides/01-fb-tidytext.html#what-do-we-mean-by-tidy-text-2",
    "href": "slides/01-fb-tidytext.html#what-do-we-mean-by-tidy-text-2",
    "title": "Mining Historical Texts",
    "section": "What do we mean by tidy text?",
    "text": "What do we mean by tidy text?\n\n\nlibrary(tidytext)\n\njournal_df %>%\n    unnest_tokens(word, text)\n#> # A tibble: 45 × 2\n#>     line word   \n#>    <int> <chr>  \n#>  1     1 was    \n#>  2     1 married\n#>  3     1 at     \n#>  4     1 home   \n#>  5     1 in     \n#>  6     1 evening\n#>  7     1 by     \n#>  8     1 william\n#>  9     1 rand   \n#> 10     1 esqr   \n#> # ℹ 35 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#jane-wants-to-know",
    "href": "slides/01-fb-tidytext.html#jane-wants-to-know",
    "title": "Text Mining",
    "section": "Jane wants to know…",
    "text": "Jane wants to know…\n\nCan we use an anti_join() now to remove stop words?\n\nYes! ✅\nNo ☹️"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#gathering-more-data",
    "href": "slides/01-fb-tidytext.html#gathering-more-data",
    "title": "Mining Texts",
    "section": "Gathering more data",
    "text": "Gathering more data\nYou can access the full text of many public domain works from Project Gutenberg using the gutenbergr package.\n\nlibrary(gutenbergr)\n\nfull_text <- gutenberg_download(1342, mirror = my_mirror)\n\n\n\n\nhttps://docs.ropensci.org/gutenbergr/"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#time-to-tidy-your-text",
    "href": "slides/01-fb-tidytext.html#time-to-tidy-your-text",
    "title": "Mining Texts",
    "section": "Time to tidy your text!",
    "text": "Time to tidy your text!\n\ntidy_book <- full_text %>%\n    mutate(line = row_number()) %>%\n    unnest_tokens(word, text)         \n\nglimpse(tidy_book)\n#> Rows: 127,996\n#> Columns: 3\n#> $ gutenberg_id <int> 1342, 1342, 1342, 1342, 1342, 1342, 1342, 1342, 1342, 134…\n#> $ line         <int> 1, 3, 3, 4, 6, 6, 6, 6, 7, 9, 9, 12, 14, 14, 14, 14, 14, …\n#> $ word         <chr> \"illustration\", \"george\", \"allen\", \"publisher\", \"156\", \"c…"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#what-are-the-most-common-words",
    "href": "slides/01-fb-tidytext.html#what-are-the-most-common-words",
    "title": "Mining Historical Texts",
    "section": "What are the most common words?",
    "text": "What are the most common words?\nWhat do you predict will happen if we run the following code? 🤔\n\ntidy_journal %>%\n    count(word, sort = TRUE)"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#what-are-the-most-common-words-1",
    "href": "slides/01-fb-tidytext.html#what-are-the-most-common-words-1",
    "title": "Mining Historical Texts",
    "section": "What are the most common words?",
    "text": "What are the most common words?\nWhat do you predict will happen if we run the following code? 🤔\n\ntidy_journal %>%\n    count(word, sort = TRUE)\n#> # A tibble: 4,108 × 2\n#>    word            n\n#>    <chr>       <int>\n#>  1 the          5116\n#>  2 wind         3052\n#>  3 and          2301\n#>  4 in           2181\n#>  5 to           1959\n#>  6 at           1422\n#>  7 thermometer  1071\n#>  8 of            948\n#>  9 west          933\n#> 10 went          909\n#> # ℹ 4,098 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#stop-words",
    "href": "slides/01-fb-tidytext.html#stop-words",
    "title": "Mining Historical Texts",
    "section": "Stop words",
    "text": "Stop words\n\nget_stopwords()\n#> # A tibble: 175 × 2\n#>    word      lexicon \n#>    <chr>     <chr>   \n#>  1 i         snowball\n#>  2 me        snowball\n#>  3 my        snowball\n#>  4 myself    snowball\n#>  5 we        snowball\n#>  6 our       snowball\n#>  7 ours      snowball\n#>  8 ourselves snowball\n#>  9 you       snowball\n#> 10 your      snowball\n#> # ℹ 165 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#stop-words-1",
    "href": "slides/01-fb-tidytext.html#stop-words-1",
    "title": "Mining Historical Texts",
    "section": "Stop words",
    "text": "Stop words\n\nget_stopwords(language = \"es\")\n#> # A tibble: 308 × 2\n#>    word  lexicon \n#>    <chr> <chr>   \n#>  1 de    snowball\n#>  2 la    snowball\n#>  3 que   snowball\n#>  4 el    snowball\n#>  5 en    snowball\n#>  6 y     snowball\n#>  7 a     snowball\n#>  8 los   snowball\n#>  9 del   snowball\n#> 10 se    snowball\n#> # ℹ 298 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#stop-words-2",
    "href": "slides/01-fb-tidytext.html#stop-words-2",
    "title": "Mining Historical Texts",
    "section": "Stop words",
    "text": "Stop words\n\nget_stopwords(language = \"de\")\n#> # A tibble: 231 × 2\n#>    word  lexicon \n#>    <chr> <chr>   \n#>  1 aber  snowball\n#>  2 alle  snowball\n#>  3 allem snowball\n#>  4 allen snowball\n#>  5 aller snowball\n#>  6 alles snowball\n#>  7 als   snowball\n#>  8 also  snowball\n#>  9 am    snowball\n#> 10 an    snowball\n#> # ℹ 221 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#stop-words-3",
    "href": "slides/01-fb-tidytext.html#stop-words-3",
    "title": "Mining Historical Texts",
    "section": "Stop words",
    "text": "Stop words\n\nget_stopwords(source = \"smart\")\n#> # A tibble: 571 × 2\n#>    word        lexicon\n#>    <chr>       <chr>  \n#>  1 a           smart  \n#>  2 a's         smart  \n#>  3 able        smart  \n#>  4 about       smart  \n#>  5 above       smart  \n#>  6 according   smart  \n#>  7 accordingly smart  \n#>  8 across      smart  \n#>  9 actually    smart  \n#> 10 after       smart  \n#> # ℹ 561 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#what-are-the-most-common-words-2",
    "href": "slides/01-fb-tidytext.html#what-are-the-most-common-words-2",
    "title": "Mining Historical Texts",
    "section": "What are the most common words?",
    "text": "What are the most common words?\nU N S C R A M B L E\nanti_join(get_stopwords(source = “smart”)) %>%\ntidy_journal %>%\ncount(word, sort = TRUE) %>%\ngeom_col() +\nslice_max(n, n = 20) %>%\nggplot(aes(n, fct_reorder(word, n))) +"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#what-are-the-most-common-words-3",
    "href": "slides/01-fb-tidytext.html#what-are-the-most-common-words-3",
    "title": "Mining Historical Texts",
    "section": "What are the most common words?",
    "text": "What are the most common words?\n\ntidy_journal %>%\n    anti_join(get_stopwords(source = \"smart\")) %>%\n    count(word, sort = TRUE) %>%\n    slice_max(n, n = 20) %>%\n    ggplot(aes(n, fct_reorder(word, n))) +  \n    geom_col()"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#currently-9-journals-transcribed-from-1871-1880",
    "href": "slides/01-fb-tidytext.html#currently-9-journals-transcribed-from-1871-1880",
    "title": "Mining Historical Texts",
    "section": "Currently 9 journals transcribed from 1871-1880",
    "text": "Currently 9 journals transcribed from 1871-1880\nReading in the data from excel.\n\n\nlibrary(readxl)\njournal_1871_1872 <- read_excel(\"data/journal_1871_1872.xlsx\")\njournal_1873 <- read_excel(\"data/journal_1873.xlsx\")\njournal_1874 <- read_excel(\"data/journal_1874.xlsx\")\njournal_1875 <- read_excel(\"data/journal_1875.xlsx\")\njournal_1876 <- read_excel(\"data/journal_1876.xlsx\")\njournal_1877 <- read_excel(\"data/journal_1877.xlsx\")\njournal_1878 <- read_excel(\"data/journal_1878.xlsx\")\njournal_1879 <- read_excel(\"data/journal_1879.xlsx\")\njournal_1880 <- read_excel(\"data/journal_1880.xlsx\")\n\nI will show you a method for reading in data from a pdf later this week."
  },
  {
    "objectID": "slides/01-fb-tidytext.html#all-journals",
    "href": "slides/01-fb-tidytext.html#all-journals",
    "title": "Mining Texts",
    "section": "All Journals",
    "text": "All Journals\n\n\njournal_1873 <- read_excel(\"data/journal_1873.xlsx\")\njournal_1874 <- read_excel(\"data/journal_1874.xlsx\")\njournal_1875 <- read_excel(\"data/journal_1875.xlsx\")\njournal_1876 <- read_excel(\"data/journal_1876.xlsx\")\njournal_1877 <- read_excel(\"data/journal_1877.xlsx\")\njournal_1878 <- read_excel(\"data/journal_1878.xlsx\")\njournal_1879 <- read_excel(\"data/journal_1879.xlsx\")\njournal_1880 <- read_excel(\"data/journal_1880.xlsx\")"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#keeping-track",
    "href": "slides/01-fb-tidytext.html#keeping-track",
    "title": "Mining Historical Texts",
    "section": "Keeping Track",
    "text": "Keeping Track\n\n\n\n\n# We want to keep track of the journals\n\njournal_1871_1872$journal <- 1\njournal_1873$journal <- 2\njournal_1874$journal <- 3\njournal_1875$journal <- 4\njournal_1876$journal <- 5\njournal_1877$journal <- 6\njournal_1878$journal <- 7\njournal_1879$journal <- 8\njournal_1880$journal <- 9\n\njournals <- dplyr::bind_rows(journal_1871_1872, journal_1873, journal_1874, \n                             journal_1875, journal_1876, journal_1877, \n                             journal_1878, journal_1879, journal_1880)"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#tidy-journals",
    "href": "slides/01-fb-tidytext.html#tidy-journals",
    "title": "Mining Historical Texts",
    "section": "Tidy Journals",
    "text": "Tidy Journals\n\nlibrary(lubridate)\n(tidy_journal <- journals %>%\n    select(date_mdy, month, journal_entry, journal) %>%\n    mutate(date_mdy = mdy(date_mdy)) %>%\n    mutate(year = year(date_mdy)) %>%\n    unnest_tokens(word, journal_entry)  %>%\n    mutate(word = case_when(word %in% c(\"reed\", \"read\") ~ \"received\",\n                            TRUE ~ word)))\n#> # A tibble: 65,118 × 5\n#>    date_mdy   month    journal  year word   \n#>    <date>     <chr>      <dbl> <dbl> <chr>  \n#>  1 1871-12-23 December       1  1871 was    \n#>  2 1871-12-23 December       1  1871 married\n#>  3 1871-12-23 December       1  1871 at     \n#>  4 1871-12-23 December       1  1871 home   \n#>  5 1871-12-23 December       1  1871 in     \n#>  6 1871-12-23 December       1  1871 evening\n#>  7 1871-12-23 December       1  1871 by     \n#>  8 1871-12-23 December       1  1871 william\n#>  9 1871-12-23 December       1  1871 rand   \n#> 10 1871-12-23 December       1  1871 esqr   \n#> # ℹ 65,108 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#most-common-words",
    "href": "slides/01-fb-tidytext.html#most-common-words",
    "title": "Mining Historical Texts",
    "section": "Most common words",
    "text": "Most common words\n\ntidy_journal %>%\n    count(word, sort = TRUE)\n#> # A tibble: 4,110 × 2\n#>    word            n\n#>    <chr>       <int>\n#>  1 the          5116\n#>  2 wind         3052\n#>  3 and          2301\n#>  4 in           2181\n#>  5 to           1959\n#>  6 at           1422\n#>  7 thermometer  1071\n#>  8 of            948\n#>  9 west          933\n#> 10 went          909\n#> # ℹ 4,100 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#removing-stop-words",
    "href": "slides/01-fb-tidytext.html#removing-stop-words",
    "title": "Mining Historical Texts",
    "section": "Removing stop words",
    "text": "Removing stop words\n\ntidy_journal %>%\n    anti_join(get_stopwords(source = \"smart\")) %>%\n    count(word, sort = TRUE) %>%\n    slice_max(n, n = 20) %>%\n    ggplot(aes(n, fct_reorder(word, n))) +  \n    geom_col()"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#journal-1-boats-meals-goods",
    "href": "slides/01-fb-tidytext.html#journal-1-boats-meals-goods",
    "title": "Mining Historical Texts",
    "section": "Journal 1: Boats, Meals, Goods 🍳 ⛵🦞 🪵",
    "text": "Journal 1: Boats, Meals, Goods 🍳 ⛵🦞 🪵"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#journal-2-wind-and-weather-nesw",
    "href": "slides/01-fb-tidytext.html#journal-2-wind-and-weather-nesw",
    "title": "Mining Historical Texts",
    "section": "Journal 2: Wind and Weather︎ NESW",
    "text": "Journal 2: Wind and Weather︎ NESW"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#your-turn-what-were-the-most-common-words-in-journal-3-and-4",
    "href": "slides/01-fb-tidytext.html#your-turn-what-were-the-most-common-words-in-journal-3-and-4",
    "title": "Mining Historical Texts",
    "section": "Your Turn: What were the most common words in Journal 3 and 4?",
    "text": "Your Turn: What were the most common words in Journal 3 and 4?"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#sentiment-lexicons",
    "href": "slides/01-fb-tidytext.html#sentiment-lexicons",
    "title": "Mining Historical Texts",
    "section": "Sentiment lexicons",
    "text": "Sentiment lexicons\n\n\n\n\nget_sentiments(\"afinn\")\n#> # A tibble: 2,477 × 2\n#>    word       value\n#>    <chr>      <dbl>\n#>  1 abandon       -2\n#>  2 abandoned     -2\n#>  3 abandons      -2\n#>  4 abducted      -2\n#>  5 abduction     -2\n#>  6 abductions    -2\n#>  7 abhor         -3\n#>  8 abhorred      -3\n#>  9 abhorrent     -3\n#> 10 abhors        -3\n#> # ℹ 2,467 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#sentiment-lexicons-1",
    "href": "slides/01-fb-tidytext.html#sentiment-lexicons-1",
    "title": "Mining Historical Texts",
    "section": "Sentiment lexicons",
    "text": "Sentiment lexicons\n\nget_sentiments(\"bing\")\n#> # A tibble: 6,786 × 2\n#>    word        sentiment\n#>    <chr>       <chr>    \n#>  1 2-faces     negative \n#>  2 abnormal    negative \n#>  3 abolish     negative \n#>  4 abominable  negative \n#>  5 abominably  negative \n#>  6 abominate   negative \n#>  7 abomination negative \n#>  8 abort       negative \n#>  9 aborted     negative \n#> 10 aborts      negative \n#> # ℹ 6,776 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#sentiment-lexicons-2",
    "href": "slides/01-fb-tidytext.html#sentiment-lexicons-2",
    "title": "Mining Historical Texts",
    "section": "Sentiment lexicons",
    "text": "Sentiment lexicons\n\nget_sentiments(\"nrc\")\n#> # A tibble: 13,872 × 2\n#>    word        sentiment\n#>    <chr>       <chr>    \n#>  1 abacus      trust    \n#>  2 abandon     fear     \n#>  3 abandon     negative \n#>  4 abandon     sadness  \n#>  5 abandoned   anger    \n#>  6 abandoned   fear     \n#>  7 abandoned   negative \n#>  8 abandoned   sadness  \n#>  9 abandonment anger    \n#> 10 abandonment fear     \n#> # ℹ 13,862 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#sentiment-lexicons-3",
    "href": "slides/01-fb-tidytext.html#sentiment-lexicons-3",
    "title": "Mining Historical Texts",
    "section": "Sentiment lexicons",
    "text": "Sentiment lexicons\n\nget_sentiments(\"loughran\")\n#> # A tibble: 4,150 × 2\n#>    word         sentiment\n#>    <chr>        <chr>    \n#>  1 abandon      negative \n#>  2 abandoned    negative \n#>  3 abandoning   negative \n#>  4 abandonment  negative \n#>  5 abandonments negative \n#>  6 abandons     negative \n#>  7 abdicated    negative \n#>  8 abdicates    negative \n#>  9 abdicating   negative \n#> 10 abdication   negative \n#> # ℹ 4,140 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#implementing-sentiment-analysis",
    "href": "slides/01-fb-tidytext.html#implementing-sentiment-analysis",
    "title": "Mining Historical Texts",
    "section": "Implementing sentiment analysis",
    "text": "Implementing sentiment analysis\n\ntidy_journal %>%\n    inner_join(get_sentiments(\"bing\")) %>% \n    count(sentiment, sort = TRUE)\n#> # A tibble: 2 × 2\n#>   sentiment     n\n#>   <chr>     <int>\n#> 1 positive   2349\n#> 2 negative    619"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#jane-wants-to-know-1",
    "href": "slides/01-fb-tidytext.html#jane-wants-to-know-1",
    "title": "Text Mining",
    "section": "Jane wants to know…",
    "text": "Jane wants to know…\n\nCan we use an anti_join() now to remove stop words?\n\nYes! ✅\nNo ☹️"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#implementing-sentiment-analysis-1",
    "href": "slides/01-fb-tidytext.html#implementing-sentiment-analysis-1",
    "title": "Mining Historical Texts",
    "section": "Implementing sentiment analysis",
    "text": "Implementing sentiment analysis\nWhat do you predict will happen if we run the following code? 🤔\n\ntidy_journal %>%\n    inner_join(get_sentiments(\"bing\")) %>%            \n    count(sentiment, word, sort = TRUE)"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#implementing-sentiment-analysis-2",
    "href": "slides/01-fb-tidytext.html#implementing-sentiment-analysis-2",
    "title": "Mining Historical Texts",
    "section": "Implementing sentiment analysis",
    "text": "Implementing sentiment analysis\nWhat do you predict will happen if we run the following code? 🤔\n\ntidy_journal %>%\n    inner_join(get_sentiments(\"bing\")) %>%            \n    count(sentiment, word, sort = TRUE)   \n#> # A tibble: 198 × 3\n#>    sentiment word         n\n#>    <chr>     <chr>    <int>\n#>  1 positive  work       802\n#>  2 positive  breeze     251\n#>  3 positive  fresh      199\n#>  4 positive  calm       177\n#>  5 positive  pleasant   119\n#>  6 positive  worked      97\n#>  7 positive  good        85\n#>  8 negative  cold        75\n#>  9 positive  ready       73\n#> 10 negative  dark        71\n#> # ℹ 188 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#implementing-sentiment-analysis-3",
    "href": "slides/01-fb-tidytext.html#implementing-sentiment-analysis-3",
    "title": "Mining Historical Texts",
    "section": "Implementing sentiment analysis",
    "text": "Implementing sentiment analysis\n\ntidy_journal %>%\n    inner_join(get_sentiments(\"bing\")) %>%\n    count(sentiment, word, sort = TRUE) %>%\n    group_by(sentiment) %>%\n    slice_max(n, n = 10) %>%\n    ungroup() %>%\n    ggplot(aes(n, fct_reorder(word, n), fill = sentiment)) +\n    geom_col() +\n    facet_wrap(vars(sentiment), scales = \"free\")"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#implementing-sentiment-analysis-4",
    "href": "slides/01-fb-tidytext.html#implementing-sentiment-analysis-4",
    "title": "Mining Historical Texts",
    "section": "Implementing sentiment analysis",
    "text": "Implementing sentiment analysis\n\ntidy_journal %>%\n    inner_join(get_sentiments(\"bing\")) %>%            \n    count(sentiment, word, sort = TRUE)   \n#> # A tibble: 198 × 3\n#>    sentiment word         n\n#>    <chr>     <chr>    <int>\n#>  1 positive  work       802\n#>  2 positive  breeze     251\n#>  3 positive  fresh      199\n#>  4 positive  calm       177\n#>  5 positive  pleasant   119\n#>  6 positive  worked      97\n#>  7 positive  good        85\n#>  8 negative  cold        75\n#>  9 positive  ready       73\n#> 10 negative  dark        71\n#> # ℹ 188 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#implementing-sentiment-analysis-5",
    "href": "slides/01-fb-tidytext.html#implementing-sentiment-analysis-5",
    "title": "Mining Historical Texts",
    "section": "Implementing sentiment analysis",
    "text": "Implementing sentiment analysis\n\ntidy_journal %>%\n    inner_join(get_sentiments(\"bing\")) %>%\n    count(sentiment, word, sort = TRUE) %>%\n    group_by(sentiment) %>%\n    slice_max(n, n = 10) %>%\n    ungroup() %>%\n    ggplot(aes(n, fct_reorder(word, n), fill = sentiment)) +\n    geom_col() +\n    facet_wrap(vars(sentiment), scales = \"free\")"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#n-grams-and-beyond",
    "href": "slides/01-fb-tidytext.html#n-grams-and-beyond",
    "title": "Mining Historical Texts",
    "section": "N-grams… and beyond! 🚀",
    "text": "N-grams… and beyond! 🚀\n\ntidy_ngram %>%\n    count(bigram, sort = TRUE)\n#> # A tibble: 19,411 × 2\n#>    bigram             n\n#>    <chr>          <int>\n#>  1 the wind        2760\n#>  2 in the           735\n#>  3 wind north       572\n#>  4 went to          557\n#>  5 wind southerly   543\n#>  6 all day          483\n#>  7 north west       402\n#>  8 wind south       381\n#>  9 the afternoon    292\n#> 10 south west       275\n#> # ℹ 19,401 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#jane-wants-to-know-2",
    "href": "slides/01-fb-tidytext.html#jane-wants-to-know-2",
    "title": "Text Mining",
    "section": "Jane wants to know…",
    "text": "Jane wants to know…\n\nCan we use an anti_join() now to remove stop words?\n\nYes! ✅\nNo ☹️"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#n-grams-and-beyond-1",
    "href": "slides/01-fb-tidytext.html#n-grams-and-beyond-1",
    "title": "Mining Historical Texts",
    "section": "N-grams… and beyond! 🚀",
    "text": "N-grams… and beyond! 🚀\n\nbigram_counts <- tidy_ngram %>%\n    separate(bigram, c(\"word1\", \"word2\"), sep = \" \") %>%\n    filter(!word1 %in% stop_words$word,\n           !word2 %in% stop_words$word) %>%\n    count(word1, word2, sort = TRUE)"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#so-many-wind-directions",
    "href": "slides/01-fb-tidytext.html#so-many-wind-directions",
    "title": "Mining Historical Texts",
    "section": "So many wind directions…! 🚀",
    "text": "So many wind directions…! 🚀\n\nbigram_counts\n#> # A tibble: 7,243 × 3\n#>    word1 word2           n\n#>    <chr> <chr>       <int>\n#>  1 wind  north         572\n#>  2 wind  southerly     543\n#>  3 north west          402\n#>  4 wind  south         381\n#>  5 south west          275\n#>  6 wrote letter        263\n#>  7 wind  easterly      243\n#>  8 west  thermometer   186\n#>  9 wind  westerly      182\n#> 10 fresh breeze        175\n#> # ℹ 7,233 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#lets-tidy-these-up",
    "href": "slides/01-fb-tidytext.html#lets-tidy-these-up",
    "title": "Mining Historical Texts",
    "section": "Let’s tidy these up",
    "text": "Let’s tidy these up\n\ntidy_ngram <- tidy_ngram %>%\n    separate(bigram, c(\"word1\", \"word2\"), sep = \" \") %>%\n    filter(!word1 %in% stop_words$word,\n           !word2 %in% stop_words$word) %>%\n    mutate(word1 = case_when(word1 %in% c(\"E\", \"easterly\", \"East\") ~ \"east\",\n                             word1 %in% c(\"S\", \"S.\", \"southerly\", \"South\") ~ \"south\",\n                             word1 %in% c(\"n.w\", \"N.W.\") ~ \"northwest\",\n                             word1 %in% c(\"northerly\", \"N\", \"n\", \"North\") ~ \"north\",\n                             word1 %in% c(\"westerly\", \"w\", \"W\", \"West\") ~ \"west\",\n           TRUE ~ word1)) %>%\n    mutate(word2 = case_when(word2 %in% c(\"E\", \"easterly\") ~ \"east\",\n                             word2 %in% c(\"S\", \"S.\", \"southerly\") ~ \"south\",\n                             word2 %in% \"n.w\" ~ \"northwest\",\n                             word2 %in% c(\"northerly\", \"N\", \"n\") ~ \"north\",\n                             word2 %in% c(\"westerly\", \"w\", \"W\") ~ \"west\",\n           TRUE ~ word2)) %>%\n    mutate(word1 = case_when(word1 %in% c(\"reed\", \"recd\") ~ \"received\",\n           TRUE ~ word1),\n           word2 = case_when(word2 %in% c(\"reed\", \"recd\") ~ \"received\",\n           TRUE ~ word2)) %>%\n    mutate(word1 = case_when(word1 %in% c(\"letters\") ~ \"letter\",\n           TRUE ~ word1),\n           word2 = case_when(word2 %in% c(\"letters\") ~ \"letter\",\n           TRUE ~ word2))\n\nnames(tidy_ngram)\n#> [1] \"journal\"  \"word1\"    \"word2\"    \"date_mdy\" \"location\""
  },
  {
    "objectID": "slides/01-fb-tidytext.html#removing-wind",
    "href": "slides/01-fb-tidytext.html#removing-wind",
    "title": "Mining Historical Texts",
    "section": "Removing wind",
    "text": "Removing wind\n\ntidy_ngram %>%\n    filter(!word1 %in% c(\"wind\") & !word2 %in% c(\"north\", \"south\", \"west\", \"east\")) %>%\n    filter(!word1 %in% c(\"south\", \"west\", \"east\", \"north\") & !word2 %in% c(\"thermometer\", \"Thermometer\"))  %>%\n    filter(str_detect(location, \"Winter Harbor|Winter harbor\")) %>%\n    unite(bigram, word1, word2, sep = \" \")  %>%\n    filter(!str_detect(bigram, \"letter|breeze|rain|thermometer|wrote|noon|1|degree|blow|home|harbor|[\\\\d+]\")) %>%\n    count(bigram, sort = TRUE) %>%\n    slice_max(n, n = 15)\n#> # A tibble: 17 × 2\n#>    bigram                n\n#>    <chr>             <int>\n#>  1 wm guptill           37\n#>  2 benj kittridge       30\n#>  3 thomas bunker        23\n#>  4 cutting wood         13\n#>  5 religious meeting    12\n#>  6 american office      11\n#>  7 iron bound           10\n#>  8 sea flower           10\n#>  9 stave island         10\n#> 10 capt thomas           9\n#> 11 cranberry isles       8\n#> 12 eldridge perry        8\n#> 13 thomas smallidge      8\n#> 14 cut wood              7\n#> 15 half day              7\n#> 16 postal card           7\n#> 17 snow storm            7"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#freeland-wants-to-know",
    "href": "slides/01-fb-tidytext.html#freeland-wants-to-know",
    "title": "Mining Historical Texts",
    "section": "Freeland wants to know…",
    "text": "Freeland wants to know…\n\nA tidy text dataset typically has\n\nmore\nfewer\n\nrows than the original, non-tidy text dataset."
  },
  {
    "objectID": "slides/01-fb-tidytext.html#freeland-wants-to-know-1",
    "href": "slides/01-fb-tidytext.html#freeland-wants-to-know-1",
    "title": "Mining Historical Texts",
    "section": "Freeland wants to know…",
    "text": "Freeland wants to know…\n\nCan we use an anti_join() now to remove stop words?\n\nYes! ✅\nNo ☹️"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#freeland-wants-to-know-2",
    "href": "slides/01-fb-tidytext.html#freeland-wants-to-know-2",
    "title": "Mining Historical Texts",
    "section": "Freeland wants to know…",
    "text": "Freeland wants to know…\n\nCan we use an anti_join() now to remove stop words?\n\nYes! ✅\nNo ☹️"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#original-text",
    "href": "slides/01-fb-tidytext.html#original-text",
    "title": "Mining Historical Texts",
    "section": "Original Text",
    "text": "Original Text"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#journal-date-and-text",
    "href": "slides/01-fb-tidytext.html#journal-date-and-text",
    "title": "Mining Historical Texts",
    "section": "Journal Date and Text",
    "text": "Journal Date and Text\n\njournals %>%\n    select(date_mdy, journal_entry, location, journal)\n#> # A tibble: 3,951 × 4\n#>    date_mdy   journal_entry                                     location journal\n#>    <chr>      <chr>                                             <chr>      <dbl>\n#>  1 12/23/1871 Was married at home in evening by William Rand E… home           1\n#>  2 12/24/1871 Went to meeting.                                  NA             1\n#>  3 12/25/1871 Shooting match all day in the evening to Christm… hall           1\n#>  4 12/26/1871 About home at work fobbing.                       home           1\n#>  5 12/27/1871 Work about home reed letter from N. H. Higgins I… home           1\n#>  6 12/28/1871 Work about home.                                  home           1\n#>  7 12/29/1871 To work in shop.                                  shop           1\n#>  8 12/30/1871 To work in shop.                                  shop           1\n#>  9 12/31/1871 Went to meeting.                                  NA             1\n#> 10 1/1/1872   Work in shop.                                     shop           1\n#> # ℹ 3,941 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#section",
    "href": "slides/01-fb-tidytext.html#section",
    "title": "Mining Historical Texts",
    "section": "",
    "text": "journal_1871_1872 %>% select(date_mdy, month, journal_entry) %>% head()"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#the-journals-1870-1906",
    "href": "slides/01-fb-tidytext.html#the-journals-1870-1906",
    "title": "Mining Historical Texts",
    "section": "The Journals (1870-1906)",
    "text": "The Journals (1870-1906)"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#currently-9-journals-transcribed",
    "href": "slides/01-fb-tidytext.html#currently-9-journals-transcribed",
    "title": "Mining Historical Texts",
    "section": "Currently 9 journals transcribed",
    "text": "Currently 9 journals transcribed\nReading in the data from excel.\n\n\nlibrary(readxl)\njournal_1871_1872 <- read_excel(\"data/journal_1871_1872.xlsx\")\njournal_1873 <- read_excel(\"data/journal_1873.xlsx\")\njournal_1874 <- read_excel(\"data/journal_1874.xlsx\")\njournal_1875 <- read_excel(\"data/journal_1875.xlsx\")\njournal_1876 <- read_excel(\"data/journal_1876.xlsx\")\njournal_1877 <- read_excel(\"data/journal_1877.xlsx\")\njournal_1878 <- read_excel(\"data/journal_1878.xlsx\")\njournal_1879 <- read_excel(\"data/journal_1879.xlsx\")\njournal_1880 <- read_excel(\"data/journal_1880.xlsx\")\n\nI will show you a method for reading in data from a pdf later this week."
  },
  {
    "objectID": "slides/01-fb-tidytext.html#currently-9-journals-1871-1880-transcribed",
    "href": "slides/01-fb-tidytext.html#currently-9-journals-1871-1880-transcribed",
    "title": "Mining Historical Texts",
    "section": "Currently 9 journals (1871-1880) transcribed",
    "text": "Currently 9 journals (1871-1880) transcribed\nReading in the data from excel.\n\n\nlibrary(readxl)\njournal_1871_1872 <- read_excel(\"data/journal_1871_1872.xlsx\")\njournal_1873 <- read_excel(\"data/journal_1873.xlsx\")\njournal_1874 <- read_excel(\"data/journal_1874.xlsx\")\njournal_1875 <- read_excel(\"data/journal_1875.xlsx\")\njournal_1876 <- read_excel(\"data/journal_1876.xlsx\")\njournal_1877 <- read_excel(\"data/journal_1877.xlsx\")\njournal_1878 <- read_excel(\"data/journal_1878.xlsx\")\njournal_1879 <- read_excel(\"data/journal_1879.xlsx\")\njournal_1880 <- read_excel(\"data/journal_1880.xlsx\")\n\nI will show you a method for reading in data from a pdf later this week."
  },
  {
    "objectID": "slides/01-fb-tidytext.html#working-with-dates",
    "href": "slides/01-fb-tidytext.html#working-with-dates",
    "title": "Mining Historical Texts",
    "section": "Working with Dates",
    "text": "Working with Dates\n\nlibrary(lubridate)\n(tidy_journal <- journals %>%\n    select(date_mdy, journal_entry, journal) %>%\n    mutate(date_mdy = mdy(date_mdy),\n           year = year(date_mdy),\n           month = month(date_mdy)) %>%\n    unnest_tokens(word, journal_entry))\n#> # A tibble: 65,118 × 5\n#>    date_mdy   journal  year month word   \n#>    <date>       <dbl> <dbl> <dbl> <chr>  \n#>  1 1871-12-23       1  1871    12 was    \n#>  2 1871-12-23       1  1871    12 married\n#>  3 1871-12-23       1  1871    12 at     \n#>  4 1871-12-23       1  1871    12 home   \n#>  5 1871-12-23       1  1871    12 in     \n#>  6 1871-12-23       1  1871    12 evening\n#>  7 1871-12-23       1  1871    12 by     \n#>  8 1871-12-23       1  1871    12 william\n#>  9 1871-12-23       1  1871    12 rand   \n#> 10 1871-12-23       1  1871    12 esqr   \n#> # ℹ 65,108 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#tidying-words-using-case_when",
    "href": "slides/01-fb-tidytext.html#tidying-words-using-case_when",
    "title": "Mining Historical Texts",
    "section": "Tidying words using case_when",
    "text": "Tidying words using case_when\n\njournals <- journals %>%\n    mutate(location = case_when(location %in% c(\"C. Isle\", \"C. Isles\", \"Cranberry Isle\", \"Cranberry Isles\") ~ \"Cranberry Isles\",\n                            TRUE ~ location))"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#creating-meaningful-date-variables-using-lubridate",
    "href": "slides/01-fb-tidytext.html#creating-meaningful-date-variables-using-lubridate",
    "title": "Mining Historical Texts",
    "section": "Creating meaningful date variables using lubridate",
    "text": "Creating meaningful date variables using lubridate\n\nlibrary(lubridate)\njournals <- journals %>%\n    select(date_mdy, journal_entry, journal, location) %>%\n    mutate(date_mdy = mdy(date_mdy),\n           year = year(date_mdy),\n           month = month(date_mdy))"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#what-places-did-freeland-visit",
    "href": "slides/01-fb-tidytext.html#what-places-did-freeland-visit",
    "title": "Mining Historical Texts",
    "section": "What places did Freeland visit?",
    "text": "What places did Freeland visit?\n\n\ntidy_journal %>%\n    distinct(location)\n#> # A tibble: 481 × 1\n#>    location      \n#>    <chr>         \n#>  1 home          \n#>  2 NA            \n#>  3 hall          \n#>  4 shop          \n#>  5 Ellsworth     \n#>  6 up stream     \n#>  7 Whites landing\n#>  8 shed          \n#>  9 camp          \n#> 10 C. Isles      \n#> # ℹ 471 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#where-did-freeland-visit",
    "href": "slides/01-fb-tidytext.html#where-did-freeland-visit",
    "title": "Mining Historical Texts",
    "section": "Where did Freeland visit?",
    "text": "Where did Freeland visit?\n\njournals %>%\n    filter(is.na(location) == FALSE, location != \"NA\") %>%\n    count(location) %>%\n    arrange(desc(n))\n#> # A tibble: 479 × 2\n#>    location                           n\n#>    <chr>                          <int>\n#>  1 Winter Harbor                    770\n#>  2 West Gouldsboro                   50\n#>  3 shop                              42\n#>  4 home                              36\n#>  5 West Gouldsboro, Winter Harbor    32\n#>  6 Ellsworth                         24\n#>  7 Calais                            20\n#>  8 South Gouldsboro                  19\n#>  9 Rockland                          18\n#> 10 Bar Harbor                        17\n#> # ℹ 469 more rows"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#lets-install-some-packages",
    "href": "slides/01-fb-tidydata.html#lets-install-some-packages",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Let’s install some packages",
    "text": "Let’s install some packages\n\ninstall.packages(c(\"tidyverse\", # data wrangling\n                   \"lubridate\", # dates\n                   \"readxl\",\n                   \"DT\")) # reading data"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#the-journals-1870-1906",
    "href": "slides/01-fb-tidydata.html#the-journals-1870-1906",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "The Journals (1870-1906)",
    "text": "The Journals (1870-1906)"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#what-do-we-mean-by-tidy-text",
    "href": "slides/01-fb-tidydata.html#what-do-we-mean-by-tidy-text",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "What do we mean by tidy text?",
    "text": "What do we mean by tidy text?\n\n\njournal_text <- c(\"Was married at home in evening by William Rand Esqr.\",\n          \"Went to meeting.\",\n          \"Shooting match all day in the evening to Christmas Tree at the Hall.\",\n          \"About home at work fobbing.\",\n          \"Work about home.\",\n          \"To work in shop.\",\n          \"To work in shop.\",\n          \"Went to meeting.\")\n\njournal_text\n#> [1] \"Was married at home in evening by William Rand Esqr.\"                \n#> [2] \"Went to meeting.\"                                                    \n#> [3] \"Shooting match all day in the evening to Christmas Tree at the Hall.\"\n#> [4] \"About home at work fobbing.\"                                         \n#> [5] \"Work about home.\"                                                    \n#> [6] \"To work in shop.\"                                                    \n#> [7] \"To work in shop.\"                                                    \n#> [8] \"Went to meeting.\""
  },
  {
    "objectID": "slides/01-fb-tidydata.html#what-do-we-mean-by-tidy-text-1",
    "href": "slides/01-fb-tidydata.html#what-do-we-mean-by-tidy-text-1",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "What do we mean by tidy text?",
    "text": "What do we mean by tidy text?\n\n\nlibrary(tidyverse)\n\njournal_df <- tibble(line = 1:8, text = journal_text)\n\njournal_df\n#> # A tibble: 8 × 2\n#>    line text                                                                \n#>   <int> <chr>                                                               \n#> 1     1 Was married at home in evening by William Rand Esqr.                \n#> 2     2 Went to meeting.                                                    \n#> 3     3 Shooting match all day in the evening to Christmas Tree at the Hall.\n#> 4     4 About home at work fobbing.                                         \n#> 5     5 Work about home.                                                    \n#> 6     6 To work in shop.                                                    \n#> 7     7 To work in shop.                                                    \n#> 8     8 Went to meeting."
  },
  {
    "objectID": "slides/01-fb-tidydata.html#what-do-we-mean-by-tidy-text-2",
    "href": "slides/01-fb-tidydata.html#what-do-we-mean-by-tidy-text-2",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "What do we mean by tidy text?",
    "text": "What do we mean by tidy text?\n\n\nlibrary(tidytext)\n\njournal_df %>%\n    unnest_tokens(word, text)\n#> # A tibble: 45 × 2\n#>     line word   \n#>    <int> <chr>  \n#>  1     1 was    \n#>  2     1 married\n#>  3     1 at     \n#>  4     1 home   \n#>  5     1 in     \n#>  6     1 evening\n#>  7     1 by     \n#>  8     1 william\n#>  9     1 rand   \n#> 10     1 esqr   \n#> # ℹ 35 more rows"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#freeland-wants-to-know",
    "href": "slides/01-fb-tidydata.html#freeland-wants-to-know",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "Freeland wants to know…",
    "text": "Freeland wants to know…\n\nA tidy text dataset typically has\n\nmore\nfewer\n\nrows than the original, non-tidy text dataset."
  },
  {
    "objectID": "slides/01-fb-tidydata.html#currently-9-journals-1871-1880-transcribed",
    "href": "slides/01-fb-tidydata.html#currently-9-journals-1871-1880-transcribed",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "Currently 9 journals (1871-1880) transcribed",
    "text": "Currently 9 journals (1871-1880) transcribed\nReading in the data from excel.\n\n\nlibrary(readxl)\njournal_1871_1872 <- read_excel(\"data/journal_1871_1872.xlsx\")\njournal_1873 <- read_excel(\"data/journal_1873.xlsx\")\njournal_1874 <- read_excel(\"data/journal_1874.xlsx\")\njournal_1875 <- read_excel(\"data/journal_1875.xlsx\")\njournal_1876 <- read_excel(\"data/journal_1876.xlsx\")\njournal_1877 <- read_excel(\"data/journal_1877.xlsx\")\njournal_1878 <- read_excel(\"data/journal_1878.xlsx\")\njournal_1879 <- read_excel(\"data/journal_1879.xlsx\")\njournal_1880 <- read_excel(\"data/journal_1880.xlsx\")"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#keeping-track",
    "href": "slides/01-fb-tidydata.html#keeping-track",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Keeping Track",
    "text": "Keeping Track\n\n\n\n\n# We want to keep track of the journals\n\nlibrary(tidyverse)\n\njournal_1871_1872$journal <- 1\njournal_1873$journal <- 2\njournal_1874$journal <- 3\njournal_1875$journal <- 4\njournal_1876$journal <- 5\njournal_1877$journal <- 6\njournal_1878$journal <- 7\njournal_1879$journal <- 8\njournal_1880$journal <- 9\n\njournals <- dplyr::bind_rows(journal_1871_1872, journal_1873, journal_1874, \n                             journal_1875, journal_1876, journal_1877, \n                             journal_1878, journal_1879, journal_1880)"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#journal-date-and-text",
    "href": "slides/01-fb-tidydata.html#journal-date-and-text",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "Journal Date and Text",
    "text": "Journal Date and Text\n\njournals %>%\n    select(date_mdy, journal_entry, location, journal)\n#> # A tibble: 3,951 × 4\n#>    date_mdy   journal_entry                                     location journal\n#>    <chr>      <chr>                                             <chr>      <dbl>\n#>  1 12/23/1871 Was married at home in evening by William Rand E… home           1\n#>  2 12/24/1871 Went to meeting.                                  NA             1\n#>  3 12/25/1871 Shooting match all day in the evening to Christm… hall           1\n#>  4 12/26/1871 About home at work fobbing.                       home           1\n#>  5 12/27/1871 Work about home reed letter from N. H. Higgins I… home           1\n#>  6 12/28/1871 Work about home.                                  home           1\n#>  7 12/29/1871 To work in shop.                                  shop           1\n#>  8 12/30/1871 To work in shop.                                  shop           1\n#>  9 12/31/1871 Went to meeting.                                  NA             1\n#> 10 1/1/1872   Work in shop.                                     shop           1\n#> # ℹ 3,941 more rows"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#creating-meaningful-date-variables-using-lubridate",
    "href": "slides/01-fb-tidydata.html#creating-meaningful-date-variables-using-lubridate",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "Creating meaningful date variables using lubridate",
    "text": "Creating meaningful date variables using lubridate\n\nlibrary(lubridate)\n(journals_sub <- journals_sub %>%\n    mutate(date_mdy = mdy(date_mdy),\n           year = year(date_mdy),\n           month = month(date_mdy)))\n#> # A tibble: 3,951 × 5\n#>    date_mdy   journal_entry                                 location  year month\n#>    <date>     <chr>                                         <chr>    <dbl> <dbl>\n#>  1 1871-12-23 Was married at home in evening by William Ra… home      1871    12\n#>  2 1871-12-24 Went to meeting.                              NA        1871    12\n#>  3 1871-12-25 Shooting match all day in the evening to Chr… hall      1871    12\n#>  4 1871-12-26 About home at work fobbing.                   home      1871    12\n#>  5 1871-12-27 Work about home reed letter from N. H. Higgi… home      1871    12\n#>  6 1871-12-28 Work about home.                              home      1871    12\n#>  7 1871-12-29 To work in shop.                              shop      1871    12\n#>  8 1871-12-30 To work in shop.                              shop      1871    12\n#>  9 1871-12-31 Went to meeting.                              NA        1871    12\n#> 10 1872-01-01 Work in shop.                                 shop      1872     1\n#> # ℹ 3,941 more rows"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#where-did-freeland-visit",
    "href": "slides/01-fb-tidydata.html#where-did-freeland-visit",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Where did Freeland visit",
    "text": "Where did Freeland visit"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#where-did-freeland-visit-1",
    "href": "slides/01-fb-tidydata.html#where-did-freeland-visit-1",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "Where did Freeland visit",
    "text": "Where did Freeland visit\n\njournals_sub %>%\n    filter(is.na(location) == FALSE, location != \"NA\") %>%\n    separate_rows(location, sep = \", \") %>%\n    count(location) %>%\n    slice_max(n, n = 15) %>%\n    ggplot(aes(x = n, y = fct_reorder(location, n))) +\n    geom_col() +\n    labs(x = \"Number of mentions\", y = \"Location\")"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#what-were-the-less-common-places-he-visited",
    "href": "slides/01-fb-tidydata.html#what-were-the-less-common-places-he-visited",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "What were the less common places he visited?",
    "text": "What were the less common places he visited?\n\njournals_sub %>%\n    filter(is.na(location) == FALSE, location != \"NA\") %>%\n    separate_rows(location, sep = \", \") %>%\n    count(location) %>%\n    slice_min(n, n = 15, with_ties = FALSE) %>%\n    ggplot(aes(x = n, y = fct_reorder(location, n))) +\n    geom_col() +\n    labs(x = \"Number of mentions\", y = \"Location\")"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#fixing-mispellings",
    "href": "slides/01-fb-tidydata.html#fixing-mispellings",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Fixing Mispellings",
    "text": "Fixing Mispellings\n\njournals_sub %>%\n    separate_rows(location, sep = \", \") %>%\n    filter(str_detect(string = location, pattern = \"Cranberry\")) %>%\n    distinct(location)\n#> # A tibble: 4 × 1\n#>   location        \n#>   <chr>           \n#> 1 Cranberry Isles \n#> 2 Cranberry Isle  \n#> 3 Cranberry Island\n#> 4 Cranberry IIsles"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#tidying-words-using-case_when",
    "href": "slides/01-fb-tidydata.html#tidying-words-using-case_when",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Tidying words using case_when",
    "text": "Tidying words using case_when\n\njournals_sub <- journals_sub %>%\n    separate_rows(location, sep = \", \") %>%\n    mutate(location = case_when(location %in% c(\"Cranberry IIsles\", \"Cranberry Isle\", \"Cranberry Island\") ~ \"Cranberry Isles\",\n                            TRUE ~ location))\n\n\njournals_sub %>%\n    separate_rows(location, sep = \", \") %>%\n    filter(str_detect(string = location, pattern = \"Cranberry\")) %>%\n    distinct(location)\n#> # A tibble: 1 × 1\n#>   location       \n#>   <chr>          \n#> 1 Cranberry Isles"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#your-turn-fix-the-mispellings-of-bass-harbor",
    "href": "slides/01-fb-tidydata.html#your-turn-fix-the-mispellings-of-bass-harbor",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "Your Turn: Fix the mispellings of Bass Harbor",
    "text": "Your Turn: Fix the mispellings of Bass Harbor\n\njournals_sub %>%\n    separate_rows(location, sep = \", \") %>%\n    filter(str_detect(string = location, pattern = \"Bass|bass\")) %>%\n    distinct(location)\n#> # A tibble: 4 × 1\n#>   location         \n#>   <chr>            \n#> 1 Bass Harbor      \n#> 2 Bass Harbobr     \n#> 3 Bass Habor       \n#> 4 Outer Bass Harbor\n\n\n\njournals_loc <- journals_loc %>%\n    mutate(location = case_when(location %in% c(__________) ~ _______,\n                            TRUE ~ location))"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#programming-functions",
    "href": "slides/01-fb-tidydata.html#programming-functions",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "Programming Functions",
    "text": "Programming Functions\n\nWe will learn to read in data using read_excel\nHow to select columns using select\nHow to create new variables using mutate\nHow to summarize and arrange data using count and arrange\nHow to group and calculate multiple things\nHow to correct entries using mutate and case_when\nHow to visualize and map the data using ggplot and leaflet"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#journal-date-entry-and-location",
    "href": "slides/01-fb-tidydata.html#journal-date-entry-and-location",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "Journal Date, Entry, and Location",
    "text": "Journal Date, Entry, and Location\n\njournals %>%\n    select(date_mdy, journal_entry, location, journal)\n#> # A tibble: 3,951 × 4\n#>    date_mdy   journal_entry                                     location journal\n#>    <chr>      <chr>                                             <chr>      <dbl>\n#>  1 12/23/1871 Was married at home in evening by William Rand E… home           1\n#>  2 12/24/1871 Went to meeting.                                  NA             1\n#>  3 12/25/1871 Shooting match all day in the evening to Christm… hall           1\n#>  4 12/26/1871 About home at work fobbing.                       home           1\n#>  5 12/27/1871 Work about home reed letter from N. H. Higgins I… home           1\n#>  6 12/28/1871 Work about home.                                  home           1\n#>  7 12/29/1871 To work in shop.                                  shop           1\n#>  8 12/30/1871 To work in shop.                                  shop           1\n#>  9 12/31/1871 Went to meeting.                                  NA             1\n#> 10 1/1/1872   Work in shop.                                     shop           1\n#> # ℹ 3,941 more rows"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#we-have-a-lot-more-variables-recorded",
    "href": "slides/01-fb-tidydata.html#we-have-a-lot-more-variables-recorded",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "We have a lot more variables recorded!",
    "text": "We have a lot more variables recorded!\n\nnames(journals)\n#>  [1] \"date_mdy\"                \"month\"                  \n#>  [3] \"journal_entry\"           \"location\"               \n#>  [5] \"location_accuracy\"       \"latitude\"               \n#>  [7] \"latitude_origin\"         \"longitude\"              \n#>  [9] \"longitude_origin\"        \"transcription\"          \n#> [11] \"quantity\"                \"unit\"                   \n#> [13] \"item\"                    \"letter\"                 \n#> [15] \"letter_from\"             \"letter_to\"              \n#> [17] \"wind_direction_am\"       \"wind_direction_pm\"      \n#> [19] \"wind_direction_night\"    \"wind_speed_am\"          \n#> [21] \"wind_speed_pm\"           \"wind_speed_night\"       \n#> [23] \"weather_condition_am\"    \"weather_condition_pm\"   \n#> [25] \"weather_condition_night\" \"temperature_am\"         \n#> [27] \"temperature_pm\"          \"temperature_night\"      \n#> [29] \"image_path\"              \"image_description\"      \n#> [31] \"recorder\"                \"notes\"                  \n#> [33] \"second_check\"            \"journal\"                \n#> [35] \"transcription_accuracy\""
  },
  {
    "objectID": "slides/01-fb-tidydata.html#exploring-a-subset-using-select",
    "href": "slides/01-fb-tidydata.html#exploring-a-subset-using-select",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Exploring a subset using select",
    "text": "Exploring a subset using select\n\n\n(journals_sub <- journals %>%\n    select(date_mdy, journal_entry, location))\n#> # A tibble: 3,951 × 3\n#>    date_mdy   journal_entry                                             location\n#>    <chr>      <chr>                                                     <chr>   \n#>  1 12/23/1871 Was married at home in evening by William Rand Esqr.      Winter …\n#>  2 12/24/1871 Went to meeting.                                          NA      \n#>  3 12/25/1871 Shooting match all day in the evening to Christmas tree … Winter …\n#>  4 12/26/1871 About home at work fobbing.                               Winter …\n#>  5 12/27/1871 Work about home reed letter from N. H. Higgins Ins agt.   Winter …\n#>  6 12/28/1871 Work about home.                                          Winter …\n#>  7 12/29/1871 To work in shop.                                          Winter …\n#>  8 12/30/1871 To work in shop.                                          Winter …\n#>  9 12/31/1871 Went to meeting.                                          NA      \n#> 10 1/1/1872   Work in shop.                                             Winter …\n#> # ℹ 3,941 more rows"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#where-did-freeland-visit-each-year",
    "href": "slides/01-fb-tidydata.html#where-did-freeland-visit-each-year",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Where did Freeland visit each year?",
    "text": "Where did Freeland visit each year?"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#mapping",
    "href": "slides/01-fb-tidydata.html#mapping",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Mapping",
    "text": "Mapping\n\nlocation_coordinates <- read_excel(path = \"data/location_coordinates.xlsx\")\n\nhead(location_coordinates, n = 2)\n#> # A tibble: 2 × 8\n#>   location n_mentions official_name_check latitude longitude recorder checked_by\n#>   <chr>         <dbl> <lgl>                  <dbl>     <dbl> <chr>    <lgl>     \n#> 1 Winter …       1000 NA                      44.4     -68.1 NH       NA        \n#> 2 West Go…        105 NA                      44.5     -68.1 NH       NA        \n#> # ℹ 1 more variable: notes <lgl>\n\nloc_df <- journals_sub %>%\n    separate_rows(location, sep = \", \")  %>%\n    count(location) %>%\n    left_join(location_coordinates, by = \"location\") %>%\n    drop_na(latitude)\n\nHomework: Add 5 more sets of coordinates to the location excel file"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#where-did-freeland-go",
    "href": "slides/01-fb-tidydata.html#where-did-freeland-go",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Where did Freeland go?",
    "text": "Where did Freeland go?"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#less-common-places-visited",
    "href": "slides/01-fb-tidydata.html#less-common-places-visited",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Less common places visited?",
    "text": "Less common places visited?\n\njournals_sub %>%\n    filter(is.na(location) == FALSE, location != \"NA\") %>%\n    separate_rows(location, sep = \", \") %>%\n    count(location) %>%\n    slice_min(n, n = 15, with_ties = FALSE) \n#> # A tibble: 15 × 2\n#>    location                       n\n#>    <chr>                      <int>\n#>  1 \" Handkerchief Light Ship\"     1\n#>  2 \" North East Harbor\"           1\n#>  3 \"Azores/Western Islands\"       1\n#>  4 \"Baker's Island\"               1\n#>  5 \"Bakers Island\"                1\n#>  6 \"Barbacoa Harbor\"              1\n#>  7 \"Bass Habor\"                   1\n#>  8 \"Bath\"                         1\n#>  9 \"Block Island Channel\"         1\n#> 10 \"Boothbay\"                     1\n#> 11 \"Brooklyn dock\"                1\n#> 12 \"Bucks Ledge\"                  1\n#> 13 \"Camden\"                       1\n#> 14 \"Canary Islands\"               1\n#> 15 \"Cape Cod\"                     1"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#we-have-a-lot-of-variables-recorded",
    "href": "slides/01-fb-tidydata.html#we-have-a-lot-of-variables-recorded",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "We have a lot of variables recorded!",
    "text": "We have a lot of variables recorded!\n\nglimpse(journals)\n#> Rows: 3,951\n#> Columns: 38\n#> $ date_mdy                <chr> \"12/23/1871\", \"12/24/1871\", \"12/25/1871\", \"12/…\n#> $ month                   <chr> \"December\", \"December\", \"December\", \"December\"…\n#> $ journal_entry           <chr> \"Was married at home in evening by William Ran…\n#> $ location                <chr> \"Winter Harbor\", \"NA\", \"Winter Harbor\", \"Winte…\n#> $ location_accuracy       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ local_place             <chr> \"Home\", NA, \"Hall\", \"Home\", \"Home\", \"Home\", \"S…\n#> $ local_place_accuracy    <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ latitude                <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ latitude_origin         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ longitude               <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ longitude_origin        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ transcription           <chr> \"confident\", \"confident\", \"confident\", \"confid…\n#> $ quantity                <chr> \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\"…\n#> $ unit                    <chr> \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\"…\n#> $ item                    <chr> \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\"…\n#> $ letter                  <chr> \"no letter\", \"no letter\", \"no letter\", \"no let…\n#> $ letter_from             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ letter_to               <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ wind_direction_am       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ wind_direction_pm       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ wind_direction_night    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ wind_speed_am           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ wind_speed_pm           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ wind_speed_night        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ weather_condition_am    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ weather_condition_pm    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ weather_condition_night <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ temperature_am          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ temperature_pm          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ temperature_night       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ image_path              <chr> \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\"…\n#> $ image_description       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ recorder                <chr> \"NH\", \"NH\", \"NH\", \"NH\", \"NH\", \"NH\", \"NH\", \"NH\"…\n#> $ notes                   <chr> \"Esqr? Esquire\", \"to?\", \"Christmas tree?\", NA,…\n#> $ second_check            <chr> \"WD\", NA, \"WD\", NA, \"WD\", NA, NA, NA, NA, NA, …\n#> $ journal                 <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n#> $ transcription_accuracy  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ ...1                    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#how-often-did-freeland-write-in-his-journal",
    "href": "slides/01-fb-tidydata.html#how-often-did-freeland-write-in-his-journal",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "How often did Freeland write in his journal?",
    "text": "How often did Freeland write in his journal?"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#how-often-did-freeland-write-his-journal",
    "href": "slides/01-fb-tidydata.html#how-often-did-freeland-write-his-journal",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "How often did Freeland write his journal?",
    "text": "How often did Freeland write his journal?\n::: {.panel-tabset}"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#journals-1871-1880-transcribed",
    "href": "slides/01-fb-tidydata.html#journals-1871-1880-transcribed",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "9 journals (1871-1880) transcribed",
    "text": "9 journals (1871-1880) transcribed\n\n\nlibrary(readxl)\njournal_1871_1872 <- read_excel(\"data/journal_1871_1872.xlsx\")\njournal_1873 <- read_excel(\"data/journal_1873.xlsx\")\njournal_1874 <- read_excel(\"data/journal_1874.xlsx\")\njournal_1875 <- read_excel(\"data/journal_1875.xlsx\")\njournal_1876 <- read_excel(\"data/journal_1876.xlsx\")\njournal_1877 <- read_excel(\"data/journal_1877.xlsx\")\njournal_1878 <- read_excel(\"data/journal_1878.xlsx\")\njournal_1879 <- read_excel(\"data/journal_1879.xlsx\")\njournal_1880 <- read_excel(\"data/journal_1880.xlsx\")"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#plot",
    "href": "slides/01-fb-tidydata.html#plot",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "Plot",
    "text": "Plot"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#code",
    "href": "slides/01-fb-tidydata.html#code",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "Code",
    "text": "Code\n\n\n\njournals_sub %>%\n    filter(is.na(year) == FALSE) %>%\n    group_by(month, year) %>%\n    summarize(days_written = n()) %>%\n    ggplot(aes(x = month, y = days_written)) +\n    geom_line() +\n    geom_point() +\n    facet_wrap(~year) +\n    ylim(0, 36) +\n    scale_x_continuous(breaks = c(0, 3, 6, 9, 12)) +\n    labs(x = \"Month\", y = \"Number of entries\")"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#how-often-did-freeland-write",
    "href": "slides/01-fb-tidydata.html#how-often-did-freeland-write",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "How often did Freeland write?",
    "text": "How often did Freeland write?"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#how-often-did-freeland-write-1",
    "href": "slides/01-fb-tidydata.html#how-often-did-freeland-write-1",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "How often did Freeland write?",
    "text": "How often did Freeland write?\n\n\n\njournals_sub %>%\n    filter(is.na(year) == FALSE) %>%\n    group_by(month, year) %>%\n    summarize(days_written = n()) %>%\n    ggplot(aes(x = month, y = days_written)) +\n    geom_line() +\n    geom_point() +\n    facet_wrap(~year) +\n    ylim(0, 36) +\n    scale_x_continuous(breaks = c(0, 3, 6, 9, 12)) +\n    labs(x = \"Month\", y = \"Number of entries\")"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#how-often-did-freeland-write-code",
    "href": "slides/01-fb-tidydata.html#how-often-did-freeland-write-code",
    "title": "Mining Historical Texts - Tidy Data",
    "section": "How often did Freeland write? Code",
    "text": "How often did Freeland write? Code\n\n\njournals_sub %>%\n    filter(is.na(year) == FALSE) %>%\n    group_by(month, year) %>%\n    summarize(days_written = n()) %>%\n    ggplot(aes(x = month, y = days_written)) +\n    geom_line() +\n    geom_point() +\n    facet_wrap(~year) +\n    ylim(0, 36) +\n    scale_x_continuous(breaks = c(0, 3, 6, 9, 12)) +\n    labs(x = \"Month\", y = \"Number of entries\")"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#plotting-frequency-of-visits",
    "href": "slides/01-fb-tidydata.html#plotting-frequency-of-visits",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Plotting frequency of visits",
    "text": "Plotting frequency of visits\n\njournals_sub %>%\n    filter(is.na(location) == FALSE, location != \"NA\") %>%\n    separate_rows(location, sep = \", \") %>%\n    count(location) %>%\n    slice_max(n, n = 15, with_ties = FALSE) %>%\n    ggplot(aes(x = n, y = fct_reorder(location, n))) +\n    geom_col() +\n    labs(x = \"Number of mentions\", y = \"Location\")"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#creating-date-variables-using-lubridate",
    "href": "slides/01-fb-tidydata.html#creating-date-variables-using-lubridate",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Creating date variables using lubridate",
    "text": "Creating date variables using lubridate\n\nlibrary(lubridate)\n(journals_sub <- journals_sub %>%\n    mutate(date_mdy = mdy(date_mdy),\n           year = year(date_mdy),\n           month = month(date_mdy)))\n#> # A tibble: 3,951 × 5\n#>    date_mdy   journal_entry                                 location  year month\n#>    <date>     <chr>                                         <chr>    <dbl> <dbl>\n#>  1 1871-12-23 Was married at home in evening by William Ra… Winter …  1871    12\n#>  2 1871-12-24 Went to meeting.                              NA        1871    12\n#>  3 1871-12-25 Shooting match all day in the evening to Chr… Winter …  1871    12\n#>  4 1871-12-26 About home at work fobbing.                   Winter …  1871    12\n#>  5 1871-12-27 Work about home reed letter from N. H. Higgi… Winter …  1871    12\n#>  6 1871-12-28 Work about home.                              Winter …  1871    12\n#>  7 1871-12-29 To work in shop.                              Winter …  1871    12\n#>  8 1871-12-30 To work in shop.                              Winter …  1871    12\n#>  9 1871-12-31 Went to meeting.                              NA        1871    12\n#> 10 1872-01-01 Work in shop.                                 Winter …  1872     1\n#> # ℹ 3,941 more rows"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#where-did-freeland-go-1",
    "href": "slides/01-fb-tidydata.html#where-did-freeland-go-1",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Where did Freeland go?",
    "text": "Where did Freeland go?\n\nlibrary(leaflet)\n\nleaflet(data = loc_df) %>%\n     setView(lng = -66, lat = 43.5, zoom = 9) %>%\n     addProviderTiles(providers$OpenStreetMap) %>%\n     addCircleMarkers(lng = ~longitude, lat = ~latitude, label = ~location, radius = ~n/100)"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#your-turn-fix-bass-harbor-misspellings",
    "href": "slides/01-fb-tidydata.html#your-turn-fix-bass-harbor-misspellings",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Your Turn: Fix Bass Harbor misspellings",
    "text": "Your Turn: Fix Bass Harbor misspellings\n\njournals_sub %>%\n    separate_rows(location, sep = \", \") %>%\n    filter(str_detect(string = location, pattern = \"Bass|bass\")) %>%\n    distinct(location)\n#> # A tibble: 3 × 1\n#>   location         \n#>   <chr>            \n#> 1 Bass Harbor      \n#> 2 Bass Habor       \n#> 3 Outer Bass Harbor\n\n\n\njournals_loc <- journals_loc %>%\n    mutate(location = case_when(location %in% c(__________) ~ _______,\n                            TRUE ~ location))"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#where-did-freeland-visit-each-year-code",
    "href": "slides/01-fb-tidydata.html#where-did-freeland-visit-each-year-code",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Where did Freeland visit each year? Code",
    "text": "Where did Freeland visit each year? Code\n\njournals_loc_count <- journals_sub %>%\n    separate_rows(location, sep = \", \") %>%\n    filter(location %in% c(\"West Gouldsboro\", \"Ellsworth\", \"Rockland\", \"Bar Harbor\", \"Sullivan\", \"Calais\", \"Prospect Harbor\", \"East Sullivan\", \"Boston\", \"Bass Harbor\", \"Cranberry Isles\")) %>%\n    group_by(year) %>%\n    count(location)\n\njournals_loc_count %>%\n    ggplot(aes(x = year, y = n, color = location)) +\n    geom_line() +\n    labs(x = \"Year\", y = \"Number of mentions\", color = \"Location\", title = \"Number of times place visited each year by Freeland Bunker\", subtitle = \"Locations don't include home, shop, factor, and Winter Harbor\")"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#journals-1871-1880-transcribed",
    "href": "slides/01-fb-tidytext.html#journals-1871-1880-transcribed",
    "title": "Mining Historical Texts",
    "section": "9 journals (1871-1880) transcribed",
    "text": "9 journals (1871-1880) transcribed\n\n\nlibrary(readxl)\njournal_1871_1872 <- read_excel(\"data/journal_1871_1872.xlsx\")\njournal_1873 <- read_excel(\"data/journal_1873.xlsx\")\njournal_1874 <- read_excel(\"data/journal_1874.xlsx\")\njournal_1875 <- read_excel(\"data/journal_1875.xlsx\")\njournal_1876 <- read_excel(\"data/journal_1876.xlsx\")\njournal_1877 <- read_excel(\"data/journal_1877.xlsx\")\njournal_1878 <- read_excel(\"data/journal_1878.xlsx\")\njournal_1879 <- read_excel(\"data/journal_1879.xlsx\")\njournal_1880 <- read_excel(\"data/journal_1880.xlsx\")\n\n*N.B. excel is just one format"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#journal-date-text-and-location",
    "href": "slides/01-fb-tidytext.html#journal-date-text-and-location",
    "title": "Mining Historical Texts",
    "section": "Journal Date, Text, and Location",
    "text": "Journal Date, Text, and Location\n\njournals %>%\n    select(date_mdy, journal_entry, location)\n#> # A tibble: 3,951 × 3\n#>    date_mdy   journal_entry                                             location\n#>    <chr>      <chr>                                                     <chr>   \n#>  1 12/23/1871 Was married at home in evening by William Rand Esqr.      home    \n#>  2 12/24/1871 Went to meeting.                                          NA      \n#>  3 12/25/1871 Shooting match all day in the evening to Christmas tree … hall    \n#>  4 12/26/1871 About home at work fobbing.                               home    \n#>  5 12/27/1871 Work about home reed letter from N. H. Higgins Ins agt.   home    \n#>  6 12/28/1871 Work about home.                                          home    \n#>  7 12/29/1871 To work in shop.                                          shop    \n#>  8 12/30/1871 To work in shop.                                          shop    \n#>  9 12/31/1871 Went to meeting.                                          NA      \n#> 10 1/1/1872   Work in shop.                                             shop    \n#> # ℹ 3,941 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#making-our-text-data-tidy",
    "href": "slides/01-fb-tidytext.html#making-our-text-data-tidy",
    "title": "Mining Historical Texts",
    "section": "Making our text data tidy",
    "text": "Making our text data tidy\n\n(tidy_journal <- journals %>%\n    unnest_tokens(word, journal_entry))\n#> # A tibble: 65,118 × 6\n#>    date_mdy   journal location  year month word   \n#>    <date>       <dbl> <chr>    <dbl> <dbl> <chr>  \n#>  1 1871-12-23       1 home      1871    12 was    \n#>  2 1871-12-23       1 home      1871    12 married\n#>  3 1871-12-23       1 home      1871    12 at     \n#>  4 1871-12-23       1 home      1871    12 home   \n#>  5 1871-12-23       1 home      1871    12 in     \n#>  6 1871-12-23       1 home      1871    12 evening\n#>  7 1871-12-23       1 home      1871    12 by     \n#>  8 1871-12-23       1 home      1871    12 william\n#>  9 1871-12-23       1 home      1871    12 rand   \n#> 10 1871-12-23       1 home      1871    12 esqr   \n#> # ℹ 65,108 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#creating-date-variables-using-lubridate",
    "href": "slides/01-fb-tidytext.html#creating-date-variables-using-lubridate",
    "title": "Mining Historical Texts",
    "section": "Creating date variables using lubridate",
    "text": "Creating date variables using lubridate\nRecall: What functions can we use to extract the year and month?\n\nlibrary(lubridate)\njournals <- journals %>%\n    select(date_mdy, journal_entry, journal, location) %>%\n    mutate(date_mdy = mdy(date_mdy),\n           year = _____(date_mdy),\n           month = _____(date_mdy))\n\nHint: Check the lubridate cheatsheet"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#creating-date-variables-using-lubridate-1",
    "href": "slides/01-fb-tidytext.html#creating-date-variables-using-lubridate-1",
    "title": "Mining Historical Texts",
    "section": "Creating date variables using lubridate",
    "text": "Creating date variables using lubridate\n\nlibrary(lubridate)\n(journals <- journals %>%\n    select(date_mdy, journal_entry, journal, location) %>%\n    mutate(date_mdy = mdy(date_mdy),\n           year = year(date_mdy),\n           month = month(date_mdy)))\n#> # A tibble: 3,951 × 6\n#>    date_mdy   journal_entry                         journal location  year month\n#>    <date>     <chr>                                   <dbl> <chr>    <dbl> <dbl>\n#>  1 1871-12-23 Was married at home in evening by Wi…       1 home      1871    12\n#>  2 1871-12-24 Went to meeting.                            1 NA        1871    12\n#>  3 1871-12-25 Shooting match all day in the evenin…       1 hall      1871    12\n#>  4 1871-12-26 About home at work fobbing.                 1 home      1871    12\n#>  5 1871-12-27 Work about home reed letter from N. …       1 home      1871    12\n#>  6 1871-12-28 Work about home.                            1 home      1871    12\n#>  7 1871-12-29 To work in shop.                            1 shop      1871    12\n#>  8 1871-12-30 To work in shop.                            1 shop      1871    12\n#>  9 1871-12-31 Went to meeting.                            1 NA        1871    12\n#> 10 1872-01-01 Work in shop.                               1 shop      1872     1\n#> # ℹ 3,941 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#how-did-freeland-refer-to-wind",
    "href": "slides/01-fb-tidytext.html#how-did-freeland-refer-to-wind",
    "title": "Mining Historical Texts",
    "section": "How did Freeland refer to wind?",
    "text": "How did Freeland refer to wind?\n\njournals %>%\n    filter(str_detect(string = journal_entry, pattern = \"wind |Wind \")) %>%\n    mutate(wind_reference = str_extract(string = journal_entry, pattern = \"wind \\\\w+\\\\.\\\\w+\\\\.|wind \\\\w+|wind \\\\w+\\\\b\\\\w+|Wind \\\\w+|Wind \\\\w+\\\\b\\\\w+|Wind \\\\w+\\\\.\\\\w+\\\\.\")) %>%\n    distinct(wind_reference)\n#> # A tibble: 114 × 1\n#>    wind_reference\n#>    <chr>         \n#>  1 wind finished \n#>  2 Wind South    \n#>  3 Wind from     \n#>  4 Wind S        \n#>  5 wind all      \n#>  6 wind E        \n#>  7 wind North    \n#>  8 wind west     \n#>  9 wind West     \n#> 10 wind N.N.     \n#> # ℹ 104 more rows\n\n\nRegular expressions are very powerful!"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#bigram-counts",
    "href": "slides/01-fb-tidytext.html#bigram-counts",
    "title": "Mining Historical Texts",
    "section": "Bigram counts",
    "text": "Bigram counts\n\ntidy_ngram %>%\n    count(word1, word2, sort = TRUE)\n#> # A tibble: 7,116 × 3\n#>    word1    word2           n\n#>    <chr>    <chr>       <int>\n#>  1 wind     south         924\n#>  2 wind     north         737\n#>  3 north    west          402\n#>  4 wrote    letter        329\n#>  5 south    west          277\n#>  6 wind     east          271\n#>  7 wind     west          247\n#>  8 received letter        227\n#>  9 west     thermometer   226\n#> 10 north    east          181\n#> # ℹ 7,106 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#extracting-the-thermometer-data",
    "href": "slides/01-fb-tidytext.html#extracting-the-thermometer-data",
    "title": "Mining Historical Texts",
    "section": "Extracting the thermometer data",
    "text": "Extracting the thermometer data\n\njournals %>%\n  filter(str_detect(string = journal_entry, pattern = \"Thermometer | thermometer\")) %>% # filter rows for mentions of word thermometer\n  mutate(temp = as.numeric(str_extract(journal_entry, pattern = '(?<=thermometer |Thermometer )\\\\d+'))) %>% # extract digits following the word thermometer in a sentence.\n  ggplot(aes(x = date_mdy, y = as.numeric(temp))) +\n  geom_point() +\n  labs(x = \"Date\", y = \"Recorded Temperature\")"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#extracting-the-thermometer-data-1",
    "href": "slides/01-fb-tidytext.html#extracting-the-thermometer-data-1",
    "title": "Mining Historical Texts",
    "section": "Extracting the thermometer data",
    "text": "Extracting the thermometer data"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#how-much-did-bunker-write",
    "href": "slides/01-fb-tidytext.html#how-much-did-bunker-write",
    "title": "Mining Historical Texts",
    "section": "How much did bunker write?",
    "text": "How much did bunker write?\n\ntidy_journal %>%\n  group_by(month, year) %>%\n  filter(is.na(year) == FALSE) %>%\n  summarize(nwords = n()) %>%\n  ggplot(aes(x = month, y = nwords, group = year)) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(~year) +\n  labs(title = \"How much did Freeland write a month?\",\n       y = \"Number of words\",\n       x = \"Month\") +\n  scale_x_continuous(breaks = c(0, 3, 6, 9, 12))"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#recap",
    "href": "slides/01-fb-tidytext.html#recap",
    "title": "Mining Historical Texts",
    "section": "Recap",
    "text": "Recap\n\nWe can put each word on its own row using unnest_tokens\nWe can use anti_join to get rid of stop words\nWe can use filter and summarize to see how word use has changed over time and space"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#extracting-the-thermometer-data-2",
    "href": "slides/01-fb-tidytext.html#extracting-the-thermometer-data-2",
    "title": "Mining Historical Texts",
    "section": "Extracting the thermometer data",
    "text": "Extracting the thermometer data\n\njournals %>%\n  filter(str_detect(string = journal_entry, pattern = \"Thermometer | thermometer\")) %>% # filter rows for mentions of word thermometer\n  mutate(temp = as.numeric(str_extract(journal_entry, pattern = '(?<=thermometer |Thermometer )\\\\d+'))) %>% # extract digits following the word thermometer in a sentence.\n  mutate(temp_below = ifelse(str_detect(string = journal_entry, pattern = \"below zero\"), \"yes\", \"no\")) %>% # if the word below zero is included mark yes or no.\n  filter(is.na(temp) == FALSE) %>% # remove missing values\n  mutate(temp = case_when(temp_below == \"yes\" ~ temp*(-1), \n                          TRUE ~ temp)) %>% # Make below zero values negative\n  ggplot(aes(x = date_mdy, y = as.numeric(temp))) +\n  geom_point() +\n  labs(x = \"Date\", y = \"Recorded Temperature\")"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#extracting-the-thermometer-data-3",
    "href": "slides/01-fb-tidytext.html#extracting-the-thermometer-data-3",
    "title": "Mining Historical Texts",
    "section": "Extracting the thermometer data",
    "text": "Extracting the thermometer data"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#looking-at-word-trends-through-space",
    "href": "slides/01-fb-tidytext.html#looking-at-word-trends-through-space",
    "title": "Mining Historical Texts",
    "section": "Looking at word trends through space",
    "text": "Looking at word trends through space"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#looking-at-word-trends-through-space-1",
    "href": "slides/01-fb-tidytext.html#looking-at-word-trends-through-space-1",
    "title": "Mining Historical Texts",
    "section": "Looking at word trends through space",
    "text": "Looking at word trends through space"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#bigrams-for-winter-harbor",
    "href": "slides/01-fb-tidytext.html#bigrams-for-winter-harbor",
    "title": "Mining Historical Texts",
    "section": "Bigrams for Winter Harbor",
    "text": "Bigrams for Winter Harbor\n\ntidy_ngram %>%\n    filter(!word1 %in% c(\"wind\") & !word2 %in% c(\"north\", \"south\", \"west\", \"east\")) %>%\n    filter(!word1 %in% c(\"south\", \"west\", \"east\", \"north\") & !word2 %in% c(\"thermometer\", \"Thermometer\"))  %>%\n    filter(str_detect(location, \"Winter Harbor|Winter harbor\")) %>%\n    unite(bigram, word1, word2, sep = \" \")  %>%\n    filter(!str_detect(bigram, \"letter|breeze|rain|thermometer|wrote|noon|1|degree|blow|home|harbor|[\\\\d+]\")) %>%\n    count(bigram, sort = TRUE) %>%\n    slice_max(n, n = 15)\n#> # A tibble: 17 × 2\n#>    bigram                n\n#>    <chr>             <int>\n#>  1 wm guptill           37\n#>  2 benj kittridge       30\n#>  3 thomas bunker        23\n#>  4 cutting wood         13\n#>  5 religious meeting    12\n#>  6 american office      11\n#>  7 iron bound           10\n#>  8 sea flower           10\n#>  9 stave island         10\n#> 10 capt thomas           9\n#> 11 cranberry isles       8\n#> 12 eldridge perry        8\n#> 13 thomas smallidge      8\n#> 14 cut wood              7\n#> 15 half day              7\n#> 16 postal card           7\n#> 17 snow storm            7"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#trends-in-space-bigrams-for-winter-harbor",
    "href": "slides/01-fb-tidytext.html#trends-in-space-bigrams-for-winter-harbor",
    "title": "Mining Historical Texts",
    "section": "Trends in Space: Bigrams for Winter Harbor",
    "text": "Trends in Space: Bigrams for Winter Harbor\n\ntidy_ngram %>%\n    filter(!word1 %in% c(\"wind\") & !word2 %in% c(\"north\", \"south\", \"west\", \"east\")) %>%\n    filter(!word1 %in% c(\"south\", \"west\", \"east\", \"north\") & !word2 %in% c(\"thermometer\", \"Thermometer\"))  %>%\n    filter(str_detect(location, \"Winter Harbor|Winter harbor\")) %>%\n    unite(bigram, word1, word2, sep = \" \")  %>%\n    filter(!str_detect(bigram, \"letter|breeze|rain|thermometer|wrote|noon|degree|blow|home|harbor|[\\\\d+]\")) %>%\n    count(bigram, sort = TRUE) %>%\n    slice_max(n, n = 15)\n#> # A tibble: 17 × 2\n#>    bigram                n\n#>    <chr>             <int>\n#>  1 wm guptill           37\n#>  2 benj kittridge       30\n#>  3 thomas bunker        23\n#>  4 cutting wood         13\n#>  5 religious meeting    12\n#>  6 american office      11\n#>  7 iron bound           10\n#>  8 sea flower           10\n#>  9 stave island         10\n#> 10 capt thomas           9\n#> 11 cranberry isles       8\n#> 12 eldridge perry        8\n#> 13 thomas smallidge      8\n#> 14 cut wood              7\n#> 15 half day              7\n#> 16 postal card           7\n#> 17 snow storm            7"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#gathering-context",
    "href": "slides/01-fb-tidytext.html#gathering-context",
    "title": "Mining Historical Texts",
    "section": "Gathering context",
    "text": "Gathering context\n\njournals %>%\n    filter(str_detect(journal_entry, pattern = \"Schr|schr|schooner\")) %>%\n    select(date_mdy, journal_entry)\n#> # A tibble: 74 × 2\n#>    date_mdy   journal_entry                                                     \n#>    <date>     <chr>                                                             \n#>  1 1873-01-06 Fair weather the wind West wrote a letter to C. C. Burrill. Geo. …\n#>  2 1873-01-07 Went to Cranberry Isle in the schr Fremont Capt Elisher Bickford …\n#>  3 1873-01-11 The wind North West pleasant breakfast and dinner at Thomas Bunke…\n#>  4 1873-02-14 The wind N.W very cold in morning more moderate in afternoon turn…\n#>  5 1873-02-19 The wind S.E snow by spells work in shop repairing boat for the s…\n#>  6 1873-02-25 The wind W. quite cold finished the schr Virgins boat. Went to Ha…\n#>  7 1873-03-07 The wind South West went to Augustus Newman's after boat stem and…\n#>  8 1873-04-11 The wind south west breakfast at Enoch Spurlings started for home…\n#>  9 1873-06-30 The wind southerly started in the Schr Banner for Calais got to M…\n#> 10 1873-07-14 The wind southerly and very hot went to Bar Harbor to look at the…\n#> # ℹ 64 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#extracting-names",
    "href": "slides/01-fb-tidytext.html#extracting-names",
    "title": "Mining Historical Texts",
    "section": "Extracting Names",
    "text": "Extracting Names\n\njournals %>%\n    filter(str_detect(journal_entry, pattern = \"Schr|schr|schooner\")) %>%\n    mutate(schooners = str_extract(journal_entry, pattern = \"\\\\b(Schr|Schr.|schr|schr.)(\\\\b\\\\s*([A-Z]\\\\w+|[A-Z]\\\\.\\\\w+\\\\.\\\\w+|[A-Z]\\\\. \\\\w+\\\\. \\\\w+)){0,4}\"))\n#> # A tibble: 74 × 7\n#>    date_mdy   journal_entry               journal location  year month schooners\n#>    <date>     <chr>                         <dbl> <chr>    <dbl> <dbl> <chr>    \n#>  1 1873-01-06 Fair weather the wind West…       2 Winter …  1873     1 Schr A. …\n#>  2 1873-01-07 Went to Cranberry Isle in …       2 Winter …  1873     1 schr Fre…\n#>  3 1873-01-11 The wind North West pleasa…       2 Winter …  1873     1 Schr Sea…\n#>  4 1873-02-14 The wind N.W very cold in …       2 Winter …  1873     2 schr Roa…\n#>  5 1873-02-19 The wind S.E snow by spell…       2 Winter …  1873     2 schr Vir…\n#>  6 1873-02-25 The wind W. quite cold fin…       2 Winter …  1873     2 schr Vir…\n#>  7 1873-03-07 The wind South West went t…       2 Winter …  1873     3 Schr Roa…\n#>  8 1873-04-11 The wind south west breakf…       2 Winter …  1873     4 Schr Nep…\n#>  9 1873-06-30 The wind southerly started…       2 Winter …  1873     6 Schr Ban…\n#> 10 1873-07-14 The wind southerly and ver…       2 Winter …  1873     7 Schr Sig…\n#> # ℹ 64 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#extracting-schooner-name",
    "href": "slides/01-fb-tidytext.html#extracting-schooner-name",
    "title": "Mining Historical Texts",
    "section": "Extracting Schooner name",
    "text": "Extracting Schooner name"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#extracting-names-of-schooners",
    "href": "slides/01-fb-tidytext.html#extracting-names-of-schooners",
    "title": "Mining Historical Texts",
    "section": "Extracting Names of Schooners",
    "text": "Extracting Names of Schooners\n\njournals %>%\n    filter(str_detect(journal_entry, pattern = \"Schr|schr|schooner\")) %>%\n    mutate(schooners = str_extract(journal_entry, pattern = \"\\\\b(Schr|Schr.|schr|schr.)(\\\\b\\\\s*([A-Z]\\\\w+|[A-Z]\\\\.\\\\w+\\\\.\\\\w+|[A-Z]\\\\. \\\\w+\\\\. \\\\w+)){0,4}\")) %>%\n    distinct(schooners)\n#> # A tibble: 38 × 1\n#>    schooners                         \n#>    <chr>                             \n#>  1 Schr A. G. Brooks                 \n#>  2 schr Fremont Capt Elisher Bickford\n#>  3 Schr Sea Flower                   \n#>  4 schr Roamer                       \n#>  5 schr Virgin                       \n#>  6 schr Virgins                      \n#>  7 Schr Roamer                       \n#>  8 Schr Neptune                      \n#>  9 Schr Banner                       \n#> 10 Schr Signal                       \n#> # ℹ 28 more rows"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#how-much-did-freeland-write",
    "href": "slides/01-fb-tidytext.html#how-much-did-freeland-write",
    "title": "Mining Historical Texts",
    "section": "How much did Freeland write?",
    "text": "How much did Freeland write?\n\ntidy_journal %>%\n  group_by(month, year) %>%\n  filter(is.na(year) == FALSE) %>%\n  summarize(nwords = n()) %>%\n  ggplot(aes(x = month, y = nwords, group = year)) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(~year) +\n  labs(title = \"How much did Freeland write a month?\",\n       y = \"Number of words\",\n       x = \"Month\") +\n  scale_x_continuous(breaks = c(0, 3, 6, 9, 12))"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#how-much-did-freeland-write-1",
    "href": "slides/01-fb-tidytext.html#how-much-did-freeland-write-1",
    "title": "Mining Historical Texts",
    "section": "How much did Freeland write?",
    "text": "How much did Freeland write?"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#comparing-multiple-journals",
    "href": "slides/01-fb-tidytext.html#comparing-multiple-journals",
    "title": "Mining Historical Texts",
    "section": "Comparing multiple journals",
    "text": "Comparing multiple journals"
  },
  {
    "objectID": "slides/01-fb-tidytext.html#your-turn-what-were-the-most-common-words-in-journal-5-and-6",
    "href": "slides/01-fb-tidytext.html#your-turn-what-were-the-most-common-words-in-journal-5-and-6",
    "title": "Mining Historical Texts",
    "section": "Your Turn: What were the most common words in Journal 5 and 6?",
    "text": "Your Turn: What were the most common words in Journal 5 and 6?"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#lets-install-some-packages",
    "href": "slides/02-more-eda-fb.html#lets-install-some-packages",
    "title": "Comparing Historical Texts",
    "section": "Let’s install some packages",
    "text": "Let’s install some packages\n\ninstall.packages(c(\"tidyverse\", \n                   \"tidytext\",\n                   \"stopwords\",\n                   \"widyr\",\n                   \"tidygraph\",\n                   \"tidylo\",\n                   \"ggraph\",\n                   \"wordcloud\"))"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#what-is-a-document-about-1",
    "href": "slides/02-more-eda-fb.html#what-is-a-document-about-1",
    "title": "Comparing Historical Texts",
    "section": "What is a document about?",
    "text": "What is a document about?\n\nTerm frequency\nInverse document frequency\n\n\n\\[idf(\\text{term}) = \\ln{\\left(\\frac{n_{\\text{documents}}}{n_{\\text{documents containing term}}}\\right)}\\]\n\n\ntf-idf is about comparing documents within a collection."
  },
  {
    "objectID": "slides/02-more-eda-fb.html#keeping-track",
    "href": "slides/02-more-eda-fb.html#keeping-track",
    "title": "Comparing Historical Texts",
    "section": "Keeping Track",
    "text": "Keeping Track"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#understanding-tf-idf",
    "href": "slides/02-more-eda-fb.html#understanding-tf-idf",
    "title": "Comparing Historical Texts",
    "section": "Understanding tf-idf",
    "text": "Understanding tf-idf\nMake a collection (corpus) for yourself!\n\n\njournal_1871_1872$journal <- 1\njournal_1873$journal <- 2\njournal_1874$journal <- 3\njournal_1875$journal <- 4\njournal_1876$journal <- 5\njournal_1877$journal <- 6\njournal_1878$journal <- 7\njournal_1879$journal <- 8\njournal_1880$journal <- 9\n\njournals <- dplyr::bind_rows(journal_1871_1872, journal_1873, journal_1874, \n                             journal_1875, journal_1876, journal_1877, \n                             journal_1878, journal_1879, journal_1880)"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#understanding-tf-idf-1",
    "href": "slides/02-more-eda-fb.html#understanding-tf-idf-1",
    "title": "Comparing Historical Texts",
    "section": "Understanding tf-idf",
    "text": "Understanding tf-idf\nMake a collection (corpus) for yourself!\n\njournals %>%\n    select(date_mdy, journal_entry, location)\n#> # A tibble: 3,951 × 3\n#>    date_mdy   journal_entry                                             location\n#>    <chr>      <chr>                                                     <chr>   \n#>  1 12/23/1871 Was married at home in evening by William Rand Esqr.      home    \n#>  2 12/24/1871 Went to meeting.                                          NA      \n#>  3 12/25/1871 Shooting match all day in the evening to Christmas tree … hall    \n#>  4 12/26/1871 About home at work fobbing.                               home    \n#>  5 12/27/1871 Work about home reed letter from N. H. Higgins Ins agt.   home    \n#>  6 12/28/1871 Work about home.                                          home    \n#>  7 12/29/1871 To work in shop.                                          shop    \n#>  8 12/30/1871 To work in shop.                                          shop    \n#>  9 12/31/1871 Went to meeting.                                          NA      \n#> 10 1/1/1872   Work in shop.                                             shop    \n#> # ℹ 3,941 more rows"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#counting-word-frequencies",
    "href": "slides/02-more-eda-fb.html#counting-word-frequencies",
    "title": "Comparing Historical Texts",
    "section": "Counting word frequencies",
    "text": "Counting word frequencies\n\nlibrary(tidyverse)\nlibrary(tidytext)\n\n(journal_words <- journals %>%\n    unnest_tokens(word, journal_entry) %>%\n    count(journal, word, sort = TRUE))\n#> # A tibble: 9,200 × 3\n#>    journal word      n\n#>      <dbl> <chr> <int>\n#>  1       8 the     868\n#>  2       7 the     701\n#>  3       4 the     672\n#>  4       6 the     644\n#>  5       7 <NA>    640\n#>  6       9 the     562\n#>  7       2 the     539\n#>  8       3 the     537\n#>  9       5 the     523\n#> 10       4 wind    421\n#> # ℹ 9,190 more rows\n\nWhat do the columns of journal_words tell us?"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#calculating-tf-idf",
    "href": "slides/02-more-eda-fb.html#calculating-tf-idf",
    "title": "Comparing Historical Texts",
    "section": "Calculating tf-idf",
    "text": "Calculating tf-idf\n\njournal_tf_idf <- journal_words %>%\n    bind_tf_idf(word, journal, n)"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#calculating-tf-idf-1",
    "href": "slides/02-more-eda-fb.html#calculating-tf-idf-1",
    "title": "Comparing Historical Texts",
    "section": "Calculating tf-idf",
    "text": "Calculating tf-idf\n\njournal_tf_idf\n#> # A tibble: 9,200 × 6\n#>    journal word      n     tf   idf tf_idf\n#>      <dbl> <chr> <int>  <dbl> <dbl>  <dbl>\n#>  1       8 the     868 0.0895     0      0\n#>  2       7 the     701 0.0741     0      0\n#>  3       4 the     672 0.0881     0      0\n#>  4       6 the     644 0.0907     0      0\n#>  5       7 <NA>    640 0.0677    NA     NA\n#>  6       9 the     562 0.0634     0      0\n#>  7       2 the     539 0.0825     0      0\n#>  8       3 the     537 0.0866     0      0\n#>  9       5 the     523 0.0861     0      0\n#> 10       4 wind    421 0.0552     0      0\n#> # ℹ 9,190 more rows\n\n\nThat’s… super exciting???"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#calculating-tf-idf-2",
    "href": "slides/02-more-eda-fb.html#calculating-tf-idf-2",
    "title": "Comparing Historical Texts",
    "section": "Calculating tf-idf",
    "text": "Calculating tf-idf\nWhat do you predict will happen if we run the following code? 🤔\n\njournal_tf_idf %>%\n    arrange(-tf_idf)"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#calculating-tf-idf-3",
    "href": "slides/02-more-eda-fb.html#calculating-tf-idf-3",
    "title": "Comparing Historical Texts",
    "section": "Calculating tf-idf",
    "text": "Calculating tf-idf\nWhat do you predict will happen if we run the following code? 🤔\n\njournal_tf_idf %>%\n    arrange(-tf_idf)\n#> # A tibble: 9,200 × 6\n#>    journal word            n      tf   idf tf_idf\n#>      <dbl> <chr>       <int>   <dbl> <dbl>  <dbl>\n#>  1       9 thermometer   357 0.0403  0.811 0.0327\n#>  2       7 thermometer   351 0.0371  0.811 0.0301\n#>  3       9 degrees       239 0.0270  1.10  0.0296\n#>  4       8 thermometer   353 0.0364  0.811 0.0295\n#>  5       8 degrees       200 0.0206  1.10  0.0227\n#>  6       7 degrees       166 0.0176  1.10  0.0193\n#>  7       1 lobsters       26 0.00727 2.20  0.0160\n#>  8       1 lbs            36 0.0101  1.50  0.0151\n#>  9       1 factory        32 0.00895 1.50  0.0135\n#> 10       9 troll          46 0.00519 2.20  0.0114\n#> # ℹ 9,190 more rows"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#calculating-tf-idf-4",
    "href": "slides/02-more-eda-fb.html#calculating-tf-idf-4",
    "title": "Comparing Historical Texts",
    "section": "Calculating tf-idf",
    "text": "Calculating tf-idf\nU N S C R A M B L E\ngroup_by(journal) %>%\njournal_tf_idf %>%\nslice_max(tf_idf, n = 10) %>%\nggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = journal)) +\nfacet_wrap(vars(journal), scales = “free”)\ngeom_col(show.legend = FALSE) +"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#calculating-tf-idf-5",
    "href": "slides/02-more-eda-fb.html#calculating-tf-idf-5",
    "title": "Comparing Historical Texts",
    "section": "Calculating tf-idf",
    "text": "Calculating tf-idf\n\njournal_tf_idf %>%\n    group_by(journal) %>%\n    slice_max(tf_idf, n = 10) %>%\n    ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = journal)) +\n    geom_col(show.legend = FALSE) +\n    facet_wrap(vars(journal), scales = \"free\") +\n    scale_x_continuous(expand = c(0,0)) +\n    labs(y = NULL, x = \"tf-idf\", title = \"Highest tf-idf words in Freeland Bunker's Journals\")"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#what-is-a-document-about-3",
    "href": "slides/02-more-eda-fb.html#what-is-a-document-about-3",
    "title": "Comparing Historical Texts",
    "section": "What is a document about?",
    "text": "What is a document about?\n\nTerm frequency\nInverse document frequency\n\n\nWeighted log odds ⚖️\n\nLog odds ratio expresses probabilities\nWeighting helps deal with power law distribution"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#weighted-log-odds-1",
    "href": "slides/02-more-eda-fb.html#weighted-log-odds-1",
    "title": "Comparing Historical Texts",
    "section": "Weighted log odds ⚖️",
    "text": "Weighted log odds ⚖️\n\nlibrary(tidylo)\njournal_words %>%\n    bind_log_odds(journal, word, n) %>%\n    arrange(-log_odds_weighted)\n#> # A tibble: 9,200 × 4\n#>    journal word            n log_odds_weighted\n#>      <dbl> <chr>       <int>             <dbl>\n#>  1       7 <NA>          640              47.8\n#>  2       9 thermometer   357              27.5\n#>  3       9 degrees       239              27.1\n#>  4       8 thermometer   353              26.8\n#>  5       7 thermometer   351              26.8\n#>  6       8 degrees       200              25.1\n#>  7       6 <NA>            2              23.9\n#>  8       7 degrees       166              23.6\n#>  9       6 thermometer    10              17.5\n#> 10       9 troll          46              14.4\n#> # ℹ 9,190 more rows\n\n\nWeighted log odds can distinguish between words that are used in all texts."
  },
  {
    "objectID": "slides/02-more-eda-fb.html#n-grams-and-beyond",
    "href": "slides/02-more-eda-fb.html#n-grams-and-beyond",
    "title": "Comparing Historical Texts",
    "section": "N-grams… and beyond! 🚀",
    "text": "N-grams… and beyond! 🚀\n\ntidy_ngram %>%\n    count(bigram, sort = TRUE)\n#> # A tibble: 19,411 × 2\n#>    bigram             n\n#>    <chr>          <int>\n#>  1 the wind        2760\n#>  2 in the           735\n#>  3 wind north       572\n#>  4 went to          557\n#>  5 wind southerly   543\n#>  6 all day          483\n#>  7 north west       402\n#>  8 wind south       381\n#>  9 the afternoon    292\n#> 10 south west       275\n#> # ℹ 19,401 more rows"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#freeland-wants-to-know",
    "href": "slides/02-more-eda-fb.html#freeland-wants-to-know",
    "title": "Comparing Historical Texts",
    "section": "Freeland wants to know…",
    "text": "Freeland wants to know…\n\nCan we use an anti_join() now to remove stop words?\n\nYes! ✅\nNo ☹️"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#n-grams-and-beyond-1",
    "href": "slides/02-more-eda-fb.html#n-grams-and-beyond-1",
    "title": "Comparing Historical Texts",
    "section": "N-grams… and beyond! 🚀",
    "text": "N-grams… and beyond! 🚀\n\nbigram_counts <- tidy_ngram %>%\n    separate(bigram, c(\"word1\", \"word2\"), sep = \" \") %>%\n    filter(!word1 %in% stop_words$word,\n           !word2 %in% stop_words$word) %>%\n    count(word1, word2, sort = TRUE)"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#so-many-wind-directions",
    "href": "slides/02-more-eda-fb.html#so-many-wind-directions",
    "title": "Comparing Historical Texts",
    "section": "So many wind directions…! 🚀",
    "text": "So many wind directions…! 🚀\n\nbigram_counts\n#> # A tibble: 7,243 × 3\n#>    word1 word2           n\n#>    <chr> <chr>       <int>\n#>  1 wind  north         572\n#>  2 wind  southerly     543\n#>  3 north west          402\n#>  4 wind  south         381\n#>  5 south west          275\n#>  6 wrote letter        263\n#>  7 wind  easterly      243\n#>  8 west  thermometer   186\n#>  9 wind  westerly      182\n#> 10 fresh breeze        175\n#> # ℹ 7,233 more rows"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#how-did-freeland-refer-to-wind",
    "href": "slides/02-more-eda-fb.html#how-did-freeland-refer-to-wind",
    "title": "Comparing Historical Texts",
    "section": "How did Freeland refer to wind?",
    "text": "How did Freeland refer to wind?\n\nlibrary(wordcloud)\nbigram_counts %>%\n    filter(str_detect(string = word1, pattern = \"wind|Wind\")) %>% \n    with(wordcloud::wordcloud(word2, n, random.order = FALSE, max.words = 50, colors = brewer.pal(8,\"Dark2\")))"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#lets-tidy-these-up",
    "href": "slides/02-more-eda-fb.html#lets-tidy-these-up",
    "title": "Comparing Historical Texts",
    "section": "Let’s tidy these up",
    "text": "Let’s tidy these up\n\ntidy_ngram <- tidy_ngram %>%\n    separate(bigram, c(\"word1\", \"word2\"), sep = \" \") %>%\n    filter(!word1 %in% stop_words$word,\n           !word2 %in% stop_words$word) %>%\n    mutate(word1 = case_when(word1 %in% c(\"E\", \"easterly\", \"East\") ~ \"east\",\n                             word1 %in% c(\"S\", \"S.\", \"southerly\", \"South\") ~ \"south\",\n                             word1 %in% c(\"n.w\", \"N.W.\") ~ \"northwest\",\n                             word1 %in% c(\"northerly\", \"N\", \"n\", \"North\") ~ \"north\",\n                             word1 %in% c(\"westerly\", \"w\", \"W\", \"West\") ~ \"west\",\n           TRUE ~ word1)) %>%\n    mutate(word2 = case_when(word2 %in% c(\"E\", \"easterly\") ~ \"east\",\n                             word2 %in% c(\"S\", \"S.\", \"southerly\") ~ \"south\",\n                             word2 %in% \"n.w\" ~ \"northwest\",\n                             word2 %in% c(\"northerly\", \"N\", \"n\") ~ \"north\",\n                             word2 %in% c(\"westerly\", \"w\", \"W\") ~ \"west\",\n           TRUE ~ word2)) %>%\n    mutate(word1 = case_when(word1 %in% c(\"reed\", \"recd\") ~ \"received\",\n           TRUE ~ word1),\n           word2 = case_when(word2 %in% c(\"reed\", \"recd\") ~ \"received\",\n           TRUE ~ word2)) %>%\n    mutate(word1 = case_when(word1 %in% c(\"letters\") ~ \"letter\",\n           TRUE ~ word1),\n           word2 = case_when(word2 %in% c(\"letters\") ~ \"letter\",\n           TRUE ~ word2))\n\nnames(tidy_ngram)\n#> [1] \"journal\"  \"word1\"    \"word2\"    \"date_mdy\" \"location\""
  },
  {
    "objectID": "slides/02-more-eda-fb.html#bigram-counts",
    "href": "slides/02-more-eda-fb.html#bigram-counts",
    "title": "Comparing Historical Texts",
    "section": "Bigram counts",
    "text": "Bigram counts\n\nbigram_counts <- tidy_ngram %>%\n    count(word1, word2, sort = TRUE)"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#what-can-you-do-with-n-grams",
    "href": "slides/02-more-eda-fb.html#what-can-you-do-with-n-grams",
    "title": "Comparing Historical Texts",
    "section": "What can you do with n-grams?",
    "text": "What can you do with n-grams?\n\n\ntf-idf of n-grams\nweighted log odds of n-grams\nnetwork analysis\nnegation"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#section-3",
    "href": "slides/02-more-eda-fb.html#section-3",
    "title": "Comparing Historical Texts",
    "section": "",
    "text": "https://pudding.cool/2017/08/screen-direction/"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#network-analysis",
    "href": "slides/02-more-eda-fb.html#network-analysis",
    "title": "Comparing Historical Texts",
    "section": "Network analysis",
    "text": "Network analysis\n\nlibrary(widyr)\nlibrary(ggraph)\nlibrary(tidygraph)\n\nbigram_graph <- bigram_counts %>%\n    filter(!word1 %in% c(\"Wind\", \"wind\", \"thermometer\", \"degrees\", \"oclock\", \"pm\", \"p.m\"), !word2 %in% c(\"Wind\", \"wind\", \"thermometer\", \"degrees\", \"oclock\", \"pm\", \"p.m\")) %>%\n    mutate(word1 = case_when(word1 %in% c(\"E\", \"easterly\", \"East\") ~ \"east\",\n                             word1 %in% c(\"S\", \"S.\", \"southerly\", \"South\") ~ \"south\",\n                             word1 %in% c(\"n.w\", \"N.W.\") ~ \"northwest\",\n                             word1 %in% c(\"northerly\", \"N\", \"n\", \"North\") ~ \"north\",\n                             word1 %in% c(\"westerly\", \"w\", \"W\", \"West\") ~ \"west\",\n           TRUE ~ word1)) %>%\n    mutate(word2 = case_when(word2 %in% c(\"E\", \"easterly\") ~ \"east\",\n                             word2 %in% c(\"S\", \"S.\", \"southerly\") ~ \"south\",\n                             word2 %in% \"n.w\" ~ \"northwest\",\n                             word2 %in% c(\"northerly\", \"N\", \"n\") ~ \"north\",\n                             word2 %in% c(\"westerly\", \"w\", \"W\") ~ \"west\",\n           TRUE ~ word2)) %>%\n    mutate(word1 = case_when(word1 %in% c(\"reed\", \"recd\") ~ \"received\",\n           TRUE ~ word1),\n           word2 = case_when(word2 %in% c(\"reed\", \"recd\") ~ \"received\",\n           TRUE ~ word2)) %>%\n    mutate(word1 = case_when(word1 %in% c(\"letters\") ~ \"letter\",\n           TRUE ~ word1),\n           word2 = case_when(word2 %in% c(\"letters\") ~ \"letter\",\n           TRUE ~ word2)) %>%\n    mutate(word1 = case_when(word1 %in% c(\"lobster\") ~ \"lobsters\",\n           TRUE ~ word1),\n           word2 = case_when(word2 %in% c(\"lobster\") ~ \"lobsters\",\n           TRUE ~ word2)) %>%\n    filter(n > 15) %>%\n    as_tbl_graph()"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#network-analysis-1",
    "href": "slides/02-more-eda-fb.html#network-analysis-1",
    "title": "Comparing Historical Texts",
    "section": "Network analysis",
    "text": "Network analysis\n\nbigram_graph\n#> # A tbl_graph: 82 nodes and 92 edges\n#> #\n#> # A directed multigraph with 16 components\n#> #\n#> # A tibble: 82 × 1\n#>   name \n#>   <chr>\n#> 1 wind \n#> 2 north\n#> 3 south\n#> 4 wrote\n#> 5 west \n#> 6 fresh\n#> # ℹ 76 more rows\n#> #\n#> # A tibble: 92 × 3\n#>    from    to     n\n#>   <int> <int> <int>\n#> 1     1     2   572\n#> 2     1     3   543\n#> 3     2     5   402\n#> # ℹ 89 more rows"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#jane-wants-to-know",
    "href": "slides/02-more-eda-fb.html#jane-wants-to-know",
    "title": "Comparing Historical Texts",
    "section": "Jane wants to know…",
    "text": "Jane wants to know…\n\nIs bigram_graph a tidy dataset?\n\nYes ☑️\nNo 🚫"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#network-analysis-2",
    "href": "slides/02-more-eda-fb.html#network-analysis-2",
    "title": "Comparing Historical Texts",
    "section": "Network analysis",
    "text": "Network analysis\n\nbigram_graph %>%\n    ggraph(layout = \"kk\") +\n    geom_edge_link(aes(edge_alpha = n)) + \n    geom_node_text(aes(label = name)) +  \n    theme_graph()"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#network-analysis-3",
    "href": "slides/02-more-eda-fb.html#network-analysis-3",
    "title": "Comparing Historical Texts",
    "section": "Network analysis",
    "text": "Network analysis\n\nbigram_graph %>%\n    ggraph(layout = \"kk\") +\n    geom_edge_link(aes(edge_alpha = n), \n                   show.legend = FALSE, \n                   arrow = arrow(length = unit(1.5, 'mm')), \n                   start_cap = circle(3, 'mm'),\n                   end_cap = circle(3, 'mm')) +\n    geom_node_text(aes(label = name)) + \n    theme_graph()"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#trends-in-space-bigrams-for-winter-harbor-your-turn",
    "href": "slides/02-more-eda-fb.html#trends-in-space-bigrams-for-winter-harbor-your-turn",
    "title": "Comparing Historical Texts",
    "section": "Trends in Space: Bigrams for Winter Harbor Your Turn",
    "text": "Trends in Space: Bigrams for Winter Harbor Your Turn\n\ntidy_ngram %>%\n    filter(!word1 %in% c(\"wind\") & !word2 %in% c(\"north\", \"south\", \"west\", \"east\")) %>%\n    filter(!word1 %in% c(\"south\", \"west\", \"east\", \"north\") & !word2 %in% c(\"thermometer\", \"Thermometer\"))  %>%\n    filter(str_detect(location, \"Winter Harbor|Winter harbor\")) %>%\n    unite(bigram, word1, word2, sep = \" \")  %>%\n    filter(!str_detect(bigram, \"letter|breeze|rain|thermometer|wrote|noon|degree|blow|home|harbor|[\\\\d+]\")) %>%\n    count(bigram, sort = TRUE) %>%\n    slice_max(n, n = 15)\n#> # A tibble: 17 × 2\n#>    bigram                n\n#>    <chr>             <int>\n#>  1 wm guptill           37\n#>  2 benj kittridge       30\n#>  3 thomas bunker        23\n#>  4 cutting wood         13\n#>  5 religious meeting    12\n#>  6 american office      11\n#>  7 iron bound           10\n#>  8 sea flower           10\n#>  9 stave island         10\n#> 10 capt thomas           9\n#> 11 cranberry isles       8\n#> 12 eldridge perry        8\n#> 13 thomas smallidge      8\n#> 14 cut wood              7\n#> 15 half day              7\n#> 16 postal card           7\n#> 17 snow storm            7"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#section-2",
    "href": "slides/02-more-eda-fb.html#section-2",
    "title": "Comparing Historical Texts",
    "section": "",
    "text": "https://pudding.cool/2017/08/screen-direction/"
  },
  {
    "objectID": "slides/02-more-eda-fb.html#freeland-wants-to-know-1",
    "href": "slides/02-more-eda-fb.html#freeland-wants-to-know-1",
    "title": "Comparing Historical Texts",
    "section": "Freeland wants to know…",
    "text": "Freeland wants to know…\n\nIs bigram_graph a tidy dataset?\n\nYes ☑️\nNo 🚫"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#learning-objectives",
    "href": "slides/01-fb-tidydata.html#learning-objectives",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Learning Objectives:",
    "text": "Learning Objectives:\nGain familiarity with - How to read in data using read_excel - How to select columns using select - How to create new variables using mutate - How to summarize and arrange data using count and arrange - How to group and calculate multiple things - How to correct entries using mutate and case_when - How to visualize and map the data using ggplot and leaflet"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#where-did-freeland-go-step-by-step",
    "href": "slides/01-fb-tidydata.html#where-did-freeland-go-step-by-step",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Where did Freeland go? Step by Step",
    "text": "Where did Freeland go? Step by Step\nStart with the dataset\n\njournals_sub \n#> # A tibble: 3,951 × 5\n#>    date_mdy   journal_entry                                 location  year month\n#>    <date>     <chr>                                         <chr>    <dbl> <dbl>\n#>  1 1871-12-23 Was married at home in evening by William Ra… Winter …  1871    12\n#>  2 1871-12-24 Went to meeting.                              NA        1871    12\n#>  3 1871-12-25 Shooting match all day in the evening to Chr… Winter …  1871    12\n#>  4 1871-12-26 About home at work fobbing.                   Winter …  1871    12\n#>  5 1871-12-27 Work about home reed letter from N. H. Higgi… Winter …  1871    12\n#>  6 1871-12-28 Work about home.                              Winter …  1871    12\n#>  7 1871-12-29 To work in shop.                              Winter …  1871    12\n#>  8 1871-12-30 To work in shop.                              Winter …  1871    12\n#>  9 1871-12-31 Went to meeting.                              NA        1871    12\n#> 10 1872-01-01 Work in shop.                                 Winter …  1872     1\n#> # ℹ 3,941 more rows"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#where-did-freeland-go-step-by-step-1",
    "href": "slides/01-fb-tidydata.html#where-did-freeland-go-step-by-step-1",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Where did Freeland go? Step by Step",
    "text": "Where did Freeland go? Step by Step\nAnd then filter for only known locations.\n\njournals_sub %>%\n    filter(is.na(location) == FALSE, location != \"NA\")\n#> # A tibble: 1,791 × 5\n#>    date_mdy   journal_entry                                 location  year month\n#>    <date>     <chr>                                         <chr>    <dbl> <dbl>\n#>  1 1871-12-23 Was married at home in evening by William Ra… Winter …  1871    12\n#>  2 1871-12-25 Shooting match all day in the evening to Chr… Winter …  1871    12\n#>  3 1871-12-26 About home at work fobbing.                   Winter …  1871    12\n#>  4 1871-12-27 Work about home reed letter from N. H. Higgi… Winter …  1871    12\n#>  5 1871-12-28 Work about home.                              Winter …  1871    12\n#>  6 1871-12-29 To work in shop.                              Winter …  1871    12\n#>  7 1871-12-30 To work in shop.                              Winter …  1871    12\n#>  8 1872-01-01 Work in shop.                                 Winter …  1872     1\n#>  9 1872-01-02 Work in shop.                                 Winter …  1872     1\n#> 10 1872-01-03 Work in shop.                                 Winter …  1872     1\n#> # ℹ 1,781 more rows"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#where-did-freeland-go-step-by-step-2",
    "href": "slides/01-fb-tidydata.html#where-did-freeland-go-step-by-step-2",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Where did Freeland go? Step by Step",
    "text": "Where did Freeland go? Step by Step\nAnd then separate rows so each location is on its own row.\n\njournals_sub %>%\n    filter(is.na(location) == FALSE, location != \"NA\") %>%\n    separate_rows(location, sep = \", \")\n#> # A tibble: 2,364 × 5\n#>    date_mdy   journal_entry                                 location  year month\n#>    <date>     <chr>                                         <chr>    <dbl> <dbl>\n#>  1 1871-12-23 Was married at home in evening by William Ra… Winter …  1871    12\n#>  2 1871-12-25 Shooting match all day in the evening to Chr… Winter …  1871    12\n#>  3 1871-12-26 About home at work fobbing.                   Winter …  1871    12\n#>  4 1871-12-27 Work about home reed letter from N. H. Higgi… Winter …  1871    12\n#>  5 1871-12-28 Work about home.                              Winter …  1871    12\n#>  6 1871-12-29 To work in shop.                              Winter …  1871    12\n#>  7 1871-12-30 To work in shop.                              Winter …  1871    12\n#>  8 1872-01-01 Work in shop.                                 Winter …  1872     1\n#>  9 1872-01-02 Work in shop.                                 Winter …  1872     1\n#> 10 1872-01-03 Work in shop.                                 Winter …  1872     1\n#> # ℹ 2,354 more rows"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#where-did-freeland-go-step-by-step-3",
    "href": "slides/01-fb-tidydata.html#where-did-freeland-go-step-by-step-3",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Where did Freeland go? Step by Step",
    "text": "Where did Freeland go? Step by Step\nAnd then count the number of times he was at that location\n\njournals_sub %>%\n    filter(is.na(location) == FALSE, location != \"NA\") %>%\n    separate_rows(location, sep = \", \") %>%\n    count(location)\n#> # A tibble: 281 × 2\n#>    location                       n\n#>    <chr>                      <int>\n#>  1 \" Handkerchief Light Ship\"     1\n#>  2 \" North East Harbor\"           1\n#>  3 \"Albany Railroad Wharf\"        9\n#>  4 \"Atlantic wharf\"               2\n#>  5 \"Azores/Western Islands\"       1\n#>  6 \"Baker Island\"                 2\n#>  7 \"Baker's Island\"               1\n#>  8 \"Bakers Island\"                1\n#>  9 \"Bangor\"                       5\n#> 10 \"Bar Habor\"                    3\n#> # ℹ 271 more rows"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#where-did-freeland-go-step-by-step-4",
    "href": "slides/01-fb-tidydata.html#where-did-freeland-go-step-by-step-4",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Where did Freeland go? Step by Step",
    "text": "Where did Freeland go? Step by Step\nAnd then arrange the locations in descending order from most visited to least visited.\n\njournals_sub %>%\n    filter(is.na(location) == FALSE, location != \"NA\") %>%\n    separate_rows(location, sep = \", \") %>%\n    count(location) %>%\n    arrange(desc(n))\n#> # A tibble: 281 × 2\n#>    location            n\n#>    <chr>           <int>\n#>  1 Winter Harbor    1155\n#>  2 West Gouldsboro   107\n#>  3 Ellsworth          53\n#>  4 Rockland           46\n#>  5 Bar Harbor         38\n#>  6 Calais             34\n#>  7 Sullivan           34\n#>  8 Prospect Harbor    28\n#>  9 East Sullivan      27\n#> 10 Bass Harbor        26\n#> # ℹ 271 more rows"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#what-can-you-do-with-r-a-snapshot",
    "href": "slides/01-fb-tidydata.html#what-can-you-do-with-r-a-snapshot",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "What can you do with R? A snapshot",
    "text": "What can you do with R? A snapshot"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#influence-of-target-species-on-fishing-effort",
    "href": "slides/01-fb-tidydata.html#influence-of-target-species-on-fishing-effort",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Influence of target species on fishing effort",
    "text": "Influence of target species on fishing effort\n\nWoman on boat holding a fish and a crab"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#who-is-fishing",
    "href": "slides/01-fb-tidydata.html#who-is-fishing",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Who is fishing?",
    "text": "Who is fishing?\n\nPlot showing the vessel length and width as boats on a scatter plot where the size of the boat is proportional to the carrying capacity of the vessel"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#how-are-vessels-fishing",
    "href": "slides/01-fb-tidydata.html#how-are-vessels-fishing",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "How are vessels fishing?",
    "text": "How are vessels fishing?\n\nPlot showing the distribution of trip length by vessel"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#what-are-vessels-targeting",
    "href": "slides/01-fb-tidydata.html#what-are-vessels-targeting",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "What are vessels targeting?",
    "text": "What are vessels targeting?\n\nPlot showing the distribution of species in the catch by weight by vessel"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#where-are-they-catching-it",
    "href": "slides/01-fb-tidydata.html#where-are-they-catching-it",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Where are they catching it?",
    "text": "Where are they catching it?"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#create-open-source-learning-resources",
    "href": "slides/01-fb-tidydata.html#create-open-source-learning-resources",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Create open source learning resources",
    "text": "Create open source learning resources"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#code-mitten-patterns",
    "href": "slides/01-fb-tidydata.html#code-mitten-patterns",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Code Mitten Patterns",
    "text": "Code Mitten Patterns"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#create-applications-to-help-you-choose-colors-for-mitten-patterns",
    "href": "slides/01-fb-tidydata.html#create-applications-to-help-you-choose-colors-for-mitten-patterns",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Create applications to help you choose colors for mitten patterns",
    "text": "Create applications to help you choose colors for mitten patterns"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#course-websites",
    "href": "slides/01-fb-tidydata.html#course-websites",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Course websites!",
    "text": "Course websites!"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#my-goals-this-week",
    "href": "slides/01-fb-tidydata.html#my-goals-this-week",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "My goals this week",
    "text": "My goals this week\n\nTo get you excited about data and data analysis\nExplore some of the ways we can apply it to this course\nGet you coding and exploring text data!\nTeach you some of the tools to bring your data to life and share it with the world."
  },
  {
    "objectID": "slides/01-fb-tidydata.html#monitor-fish-runs",
    "href": "slides/01-fb-tidydata.html#monitor-fish-runs",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Monitor fish runs",
    "text": "Monitor fish runs"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#section",
    "href": "slides/01-fb-tidydata.html#section",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "",
    "text": "Get you excited about data and analysis\nExplore ways you could use it in projects\nGet you coding and exploring text data\nTeach you tools to set data free and release it into the world."
  },
  {
    "objectID": "slides/01-fb-tidydata.html#where-are-they-fishing",
    "href": "slides/01-fb-tidydata.html#where-are-they-fishing",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Where are they fishing?",
    "text": "Where are they fishing?"
  },
  {
    "objectID": "slides/01-fb-tidydata.html#choose-colors-for-mitten-patterns",
    "href": "slides/01-fb-tidydata.html#choose-colors-for-mitten-patterns",
    "title": "Wrangling and Visualizing Historical Texts",
    "section": "Choose colors for mitten patterns",
    "text": "Choose colors for mitten patterns"
  }
]