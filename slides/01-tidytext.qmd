---
title: "Text Mining"
subtitle: "USING TIDY DATA PRINCIPLES"
author: "by Julia Silge adapted with a COA twist by Laurie Baker"
format:
  revealjs: 
    footer: <https://juliasilge.github.io/tidytext-tutorial/>
    theme: [dark, custom.scss]
    width: 1280
    height: 720
    title-slide-attributes: 
      data-background-image: figs/p_and_p_cover.png
      data-background-opacity: "0.7"
highlight-style: "arrow-light"      
knitr:
  opts_chunk: 
    echo: true
    collapse: true
    comment: "#>"    
---

```{r}
#| include: false
#| file: setup.R
```

# Acknowledgements {background-image="figs/p_and_p_cover.png" background-size="cover" background-opacity="0.7"}

<center>

<img src="figs/blue_jane.png" width="150px"/>

[{{< fa brands mastodon >}} \@juliasilge](https://fosstodon.org/@juliasilge)

[{{< fa brands github >}} \@juliasilge](https://github.com/juliasilge)

[{{< fa brands youtube >}} youtube.com/juliasilge](https://www.youtube.com/juliasilge)

[{{< fa link >}} juliasilge.com](https://juliasilge.com/)

[{{< fa book >}} tidytextmining.com](https://tidytextmining.com)

</center>

## Let's install some packages {background-color="white"}

```{r}
#| eval: false
install.packages(c("tidyverse", 
                   "tidytext",
                   "stopwords",
                   "gutenbergr"))
```

## What do we mean by tidy text? {background-color="white"}

![](figs/purple_emily.png){.absolute top="-30" right="0" width="100"}

```{r}
text <- c("Tell all the truth but tell it slant ‚Äî",
          "Success in Circuit lies",
          "Too bright for our infirm Delight",
          "The Truth's superb surprise",
          "As Lightning to the Children eased",
          "With explanation kind",
          "The Truth must dazzle gradually",
          "Or every man be blind ‚Äî")

text
```

## What do we mean by tidy text? {background-color="white"}

![](figs/purple_emily.png){.absolute top="-30" right="0" width="100"}

```{r}
library(tidyverse)

text_df <- tibble(line = 1:8, text = text)

text_df
```

## What do we mean by tidy text? {background-color="white"}

![](figs/purple_emily.png){.absolute top="-30" right="0" width="100"}

```{r}
#| code-line-numbers: "|4"
library(tidytext)

text_df %>%
    unnest_tokens(word, text)
```

## Jane wants to know... {transition="slide-in"}

![](figs/blue_jane.png){.absolute top="0" right="0" width="150" height="150"}

A tidy text dataset typically has

-   [more]{.lavender}
-   [fewer]{.lavender}

rows than the original, non-tidy text dataset.

## Gathering more data {background-color="white"}

You can access the full text of many public domain works from Project Gutenberg using the gutenbergr package.

```{r}
library(gutenbergr)

full_text <- gutenberg_download(1342, mirror = my_mirror)
```

<!-- What book do *you* want to analyze today? üìñü•≥üìñ -->

::: aside
[https://docs.ropensci.org/gutenbergr/]{.blue}
:::

## Time to tidy your text! {background-color="white"}

```{r}
#| code-line-numbers: "|3"
tidy_book <- full_text %>%
    mutate(line = row_number()) %>%
    unnest_tokens(word, text)         

glimpse(tidy_book)
```

## What are the most common words? {background-color="white"}

What do you predict will happen if we run the following code? ü§î

```{r}
#| eval: false
tidy_book %>%
    count(word, sort = TRUE)
```

## What are the most common words? {background-color="white"}

What do you predict will happen if we run the following code? ü§î

```{r}
tidy_book %>%
    count(word, sort = TRUE)
```

## Stop words {background-color="white"}

```{r}
get_stopwords()
```

## Stop words {background-color="white"}

```{r}
get_stopwords(language = "es")
```

## Stop words {background-color="white"}

```{r}
get_stopwords(language = "fr")
```

## Stop words {background-color="white"}

```{r}
get_stopwords(source = "smart")
```

## What are the most common words?

[U N S C R A M B L E]{.lavender}

anti_join(get_stopwords(source = "smart")) %>%

tidy_book %>%

count(word, sort = TRUE) %>%

geom_col() +

slice_max(n, n = 20) %>%

ggplot(aes(n, fct_reorder(word, n))) + 

## What are the most common words? {background-color="white"}

```{r, eval = FALSE}
#| eval: false
#| code-line-numbers: "|5"
tidy_book %>%
    anti_join(get_stopwords(source = "smart")) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 20) %>%
    ggplot(aes(n, fct_reorder(word, n))) +  
    geom_col()
```

## {background-color="white"}

```{r}
#| echo: false
#| fig-width: 7
#| fig-align: center
tidy_book %>%
    anti_join(get_stopwords(source = "smart")) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 20) %>%
    ggplot(aes(n, fct_reorder(word, n))) +
    geom_col(fill = "midnightblue", alpha = 0.9) +
    scale_x_continuous(expand = c(0,0)) +
    labs(y = NULL, x = "Number of occurrences")
```

##  {background-image="figs/tilecounts-1.png" background-size="60%" background-color="white"}

::: footer
:::

##  {background-image="figs/tilerate-1.png" background-size="60%" background-color="white"}

::: footer
:::

# The Freeland Bunker Diaries {background-image="figs/water.jpg" background-size="cover" background-opacity="0.5"}


##  {background-image="figs/freeland_bunker.jpg" background-size="40%" background-color="white"}

::: footer
:::

##  {background-image="figs/freeland_timeline.jpg" background-size="40%" background-color="white"}

::: footer
:::


##  {background-image="figs/freeland_bunker_journal.jpg" background-size="85%" background-color="white"}

::: footer
:::

## Currently 9 journals transcribed from 1871-1880

```{r}

library(readxl)
journal_1871_1872 <- read_excel("data/journal_1871_1872.xlsx")
journal_1871_1872 %>%
    select(date_mdy, month, journal_entry) %>%
    head()
```
## All Journals

```{r}

journal_1873 <- read_excel("data/journal_1873.xlsx")
journal_1874 <- read_excel("data/journal_1874.xlsx")
journal_1875 <- read_excel("data/journal_1875.xlsx")
journal_1876 <- read_excel("data/journal_1876.xlsx")
journal_1877 <- read_excel("data/journal_1877.xlsx")
journal_1878 <- read_excel("data/journal_1878.xlsx")
journal_1879 <- read_excel("data/journal_1879.xlsx")
journal_1880 <- read_excel("data/journal_1880.xlsx")

```

## Keeping Track

```{r echo = FALSE, message = FALSE, warning = FALSE}
# We need to make sure the journals are the same type

journal_1871_1872$temperature_night <- as.numeric(journal_1871_1872$temperature_night)
journal_1873$temperature_night <- as.numeric(journal_1873$temperature_night)
journal_1874$temperature_night <- as.numeric(journal_1874$temperature_night)
journal_1875$temperature_night <- as.numeric(journal_1875$temperature_night)
journal_1876$temperature_night <- as.numeric(journal_1876$temperature_night)
journal_1877$temperature_night <- as.numeric(journal_1877$temperature_night)
journal_1878$temperature_night <- as.numeric(journal_1878$temperature_night)
journal_1879$temperature_night <- as.numeric(journal_1879$temperature_night)
journal_1880$temperature_night <- as.numeric(journal_1880$temperature_night)
```


```{r}
# We want to keep track of the journals

journal_1871_1872$journal <- 1
journal_1873$journal <- 2
journal_1874$journal <- 3
journal_1875$journal <- 4
journal_1876$journal <- 5
journal_1877$journal <- 6
journal_1878$journal <- 7
journal_1879$journal <- 8
journal_1880$journal <- 9

journals <- dplyr::bind_rows(journal_1871_1872, journal_1873, journal_1874, 
                             journal_1875, journal_1876, journal_1877, 
                             journal_1878, journal_1879, journal_1880)
```


## Tidy Journals

```{r}
library(lubridate)
(tidy_journal <- journals %>%
    select(date_mdy, month, journal_entry, journal) %>%
    mutate(date_mdy = mdy(date_mdy)) %>%
    mutate(year = year(date_mdy)) %>%
    unnest_tokens(word, journal_entry)  %>%
    mutate(word = case_when(word %in% c("reed", "read") ~ "received",
                            TRUE ~ word)))
```

## Most common words

```{r}
tidy_journal %>%
    count(word, sort = TRUE)
```

## Removing stop words


```{r}
#| eval: false
tidy_journal %>%
    anti_join(get_stopwords(source = "smart")) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 20) %>%
    ggplot(aes(n, fct_reorder(word, n))) +  
    geom_col()
```

## Journal 1: Boats, Meals, Goods üç≥ ‚õµü¶û ü™µ


```{r}
#| echo: false
tidy_journal %>%
    anti_join(get_stopwords(source = "smart")) %>%
    filter(journal == 1) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 25) %>%
    mutate(color = case_when(word %in% c("breakfast", "dinner", "supper", "tea") ~ "meal", TRUE ~ "other")) %>%
    ggplot(aes(n, fct_reorder(word, n))) +  
    geom_col(aes(fill = color)) +
    labs(fill = "Word Type", y = "word")
```
## Journal 2: Wind and Weather ‚òÅÔ∏é NESW

```{r}
#| echo: false
tidy_journal %>%
    anti_join(get_stopwords(source = "smart")) %>%
    filter(journal == 2) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 25) %>%
    mutate(color = case_when(word %in% c("wind", "n.w", "north", "east", "west", "south", "rainy", "heavy", "snow", "breeze", "easterly", "southerly", "moderate", "cold", "rain") ~ "wind and weather", TRUE ~ "other")) %>%
    ggplot(aes(n, fct_reorder(word, n))) +  
    geom_col(aes(fill = color)) +
    labs(fill = "Word Type", y = "word")
```

## Your Turn: What were the most common words in Journal 3 and 4?


# SENTIMENT ANALYSIS </br>üòÑüò¢üò† {background-image="figs/p_and_p_cover.png" background-size="cover" background-opacity="0.5"}

## Sentiment lexicons {background-color="white"}

```{r echo = FALSE}

tns <- getNamespace("textdata")
assignInNamespace(x = "printer", value = function(...) 1, ns = tns)

```


```{r}
get_sentiments("afinn")
```

## Sentiment lexicons {background-color="white"}

```{r}
get_sentiments("bing")
```

## Sentiment lexicons {background-color="white"}

```{r}
get_sentiments("nrc")
```

## Sentiment lexicons {background-color="white"}

```{r}
get_sentiments("loughran")
```

## Implementing sentiment analysis {background-color="white"}

```{r}
#| code-line-numbers: "|2"
tidy_book %>%
    inner_join(get_sentiments("bing")) %>% 
    count(sentiment, sort = TRUE)
```

## Jane wants to know... {transition="slide-in"}

![](figs/blue_jane.png){.absolute top="0" right="0" width="150" height="150"}

What kind of join is appropriate for sentiment analysis?

-   [anti_join()]{.codedarkbg}
-   [full_join()]{.codedarkbg}
-   [outer_join()]{.codedarkbg}
-   [inner_join()]{.codedarkbg}

## Implementing sentiment analysis {background-color="white"}

What do you predict will happen if we run the following code? ü§î

```{r}
#| eval: false
#| code-line-numbers: "|3"
tidy_book %>%
    inner_join(get_sentiments("bing")) %>%            
    count(sentiment, word, sort = TRUE) 
```

## Implementing sentiment analysis {background-color="white"}

What do you predict will happen if we run the following code? ü§î

```{r}
#| code-line-numbers: "3"
tidy_book %>%
    inner_join(get_sentiments("bing")) %>%            
    count(sentiment, word, sort = TRUE)   
```

## Implementing sentiment analysis {background-color="white"}

```{r, eval = FALSE}
#| eval: false
#| code-line-numbers: "|7"
tidy_book %>%
    inner_join(get_sentiments("bing")) %>%
    count(sentiment, word, sort = TRUE) %>%
    group_by(sentiment) %>%
    slice_max(n, n = 10) %>%
    ungroup() %>%
    ggplot(aes(n, fct_reorder(word, n), fill = sentiment)) +
    geom_col() +
    facet_wrap(vars(sentiment), scales = "free") 
```

## {background-color="white"}

```{r}
#| echo: false
#| fig-align: center
tidy_book %>%
    inner_join(get_sentiments("bing")) %>%
    count(sentiment, word, sort = TRUE) %>%
    group_by(sentiment) %>%
    slice_max(n, n = 10) %>%
    ungroup %>%
    ggplot(aes(n, fct_reorder(word, n), fill = sentiment)) +
    geom_col(alpha = 0.9, show.legend = FALSE) +
    facet_wrap(vars(sentiment), scales = "free") +
    scale_x_continuous(expand = c(0,0)) +
    labs(y = NULL, x = "Number of occurrences")
```

# Was Freeland Sentimental? {background-image="figs/water.jpg" background-size="cover" background-opacity="0.5"}

![](figs/freeland_headshot.jpg){top="0" right="" width="180" height="200"}


## Implementing sentiment analysis {background-color="white"}

```{r}
#| code-line-numbers: "3"
tidy_journal %>%
    inner_join(get_sentiments("bing")) %>%            
    count(sentiment, word, sort = TRUE)   
```

## Implementing sentiment analysis {background-color="white"}

```{r, eval = FALSE}
#| eval: false
#| code-line-numbers: "|7"
tidy_journal %>%
    inner_join(get_sentiments("bing")) %>%
    count(sentiment, word, sort = TRUE) %>%
    group_by(sentiment) %>%
    slice_max(n, n = 10) %>%
    ungroup() %>%
    ggplot(aes(n, fct_reorder(word, n), fill = sentiment)) +
    geom_col() +
    facet_wrap(vars(sentiment), scales = "free") 
```

## {background-color="white"}

```{r}
#| echo: false
#| fig-align: center
tidy_journal %>%
    inner_join(get_sentiments("bing")) %>%
    count(sentiment, word, sort = TRUE) %>%
    group_by(sentiment) %>%
    slice_max(n, n = 10) %>%
    ungroup %>%
    ggplot(aes(n, fct_reorder(word, n), fill = sentiment)) +
    geom_col(alpha = 0.9, show.legend = FALSE) +
    facet_wrap(vars(sentiment), scales = "free") +
    scale_x_continuous(expand = c(0,0)) +
    labs(y = NULL, x = "Number of occurrences")
```

# What was the weather like? {background-image="figs/water.jpg" background-size="cover" background-opacity="0.5"}


## {background-color="white"}

```{r}
#| echo: false
#| fig-align: center
tidy_journal %>%
    inner_join(get_sentiments("bing")) %>%
    mutate(month = as.factor(month)) %>%
    drop_na(month) %>%
    filter(word %in% c("cold", "dark", "stormy", "rainy", "cloudy", "calm", "warm", "pleasant", "clear")) %>%
    count(month, sentiment, word, sort = TRUE) %>%
    mutate(word = as.factor(word)) %>%
    mutate(word = fct_relevel(word, c("calm", "clear", "pleasant", "warm", "cloudy", "cold", "dark", "stormy"))) %>%
    mutate(sentiment = fct_relevel(as.factor(sentiment), "positive", "negative")) %>%
    ggplot(aes(x = fct_relevel(month, c("January", "February", "March", "April", "May", "June", "July", "August", "September")), y = n, fill = word)) +
    geom_col(position = "stack") +
    #facet_wrap(~sentiment, ncol = 1) +
    labs(y = "Number of occurrences", x = "Month") +
    scale_fill_brewer(palette = "Spectral") +
    labs(title = "Whatever the weather") +
    coord_polar()
```
# More insight from bigrams! {background-image="figs/water.jpg" background-size="cover" background-opacity="0.5"}

```{r}
(tidy_ngram <- journals %>%
    mutate(journal_entry = str_replace_all(journal_entry, "south west", "southwest")) %>%
    mutate(journal_entry = str_replace_all(journal_entry, "north west", "northwest")) %>%
    mutate(journal_entry = str_replace_all(journal_entry, "south east", "southeast")) %>%
    mutate(journal_entry = str_replace_all(journal_entry, "north east", "northeast")) %>%
    unnest_tokens(bigram, journal_entry, token = "ngrams", n = 2) %>% 
    drop_na(bigram) %>%
    select(journal, bigram, date_mdy))
```

## N-grams... and beyond! üöÄ {background-color="white"}

```{r}
tidy_ngram %>%
    count(bigram, sort = TRUE)
```

## Jane wants to know... {transition="slide-in"}

![](figs/blue_jane.png){.absolute top="0" right="0" width="150"
height="150"}

Can we use an [anti_join()]{.codedarkbg} now to remove stop words?

-   Yes! ‚úÖ
-   No ‚òπÔ∏è

## N-grams... and beyond! üöÄ {background-color="white"}

```{r}
#| code-line-numbers: "|2"
bigram_counts <- tidy_ngram %>%
    separate(bigram, c("word1", "word2"), sep = " ") %>%
    filter(!word1 %in% stop_words$word,
           !word2 %in% stop_words$word) %>%
    count(word1, word2, sort = TRUE)
```

## So many wind directions...! üöÄ {background-color="white"}

```{r}
bigram_counts
```

## Let's tidy these up 

```{r}
#| eval: true
bigram_counts <- tidy_ngram %>%
    separate(bigram, c("word1", "word2"), sep = " ") %>%
    filter(!word1 %in% stop_words$word,
           !word2 %in% stop_words$word) %>%
    mutate(word1 = case_when(word1 == "easterly" ~ "east",
                             word1 == "southerly" ~ "south",
                             word1 == "n.w" ~ "northwest",
                             word1 == "northerly" ~ "north",
                             word1 == "westerly" ~ "west",
           TRUE ~ word1)) %>%
    mutate(word2 = case_when(word2 == "easterly" ~ "east",
                             word2 == "southerly" ~ "south",
                             word2 == "n.w" ~ "northwest",
                             word2 == "northerly" ~ "north",
                             word2 == "westerly" ~ "west",
           TRUE ~ word2)) %>%
    count(word1, word2, sort = TRUE)
```

## Removing wind

```{r}
bigram_counts %>%
    filter(word1 != "wind" & word1 != "north" & word1 != "south")
```



# Thanks! {background-image="figs/p_and_p_cover.png" background-size="cover" background-opacity="0.5"}

<center>

<img src="figs/blue_jane.png" width="150px"/>

[{{< fa brands mastodon >}} \@juliasilge](https://fosstodon.org/@juliasilge)

[{{< fa brands github >}} \@juliasilge](https://github.com/juliasilge)

[{{< fa brands youtube >}} youtube.com/juliasilge](https://www.youtube.com/juliasilge)

[{{< fa link >}} juliasilge.com](https://juliasilge.com/)

[{{< fa book >}} tidytextmining.com](https://tidytextmining.com)

</center>

::: footer
Slides created with [Quarto](https://quarto.org/)
:::
