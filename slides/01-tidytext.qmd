---
title: "Text Mining"
subtitle: "USING TIDY DATA PRINCIPLES"
author: "by Julia Silge adapted with a COA twist by Laurie Baker"
format:
  revealjs: 
    footer: <https://juliasilge.github.io/tidytext-tutorial/>
    theme: [dark, custom.scss]
    width: 1280
    height: 720
    title-slide-attributes: 
      data-background-image: figs/p_and_p_cover.png
      data-background-opacity: "0.7"
highlight-style: "arrow-light"      
knitr:
  opts_chunk: 
    echo: true
    collapse: true
    comment: "#>"    
---

```{r}
#| include: false
#| file: setup.R
```

# Acknowledgements {background-image="figs/p_and_p_cover.png" background-size="cover" background-opacity="0.7"}

<center>

<img src="figs/blue_jane.png" width="150px"/>

[{{< fa brands mastodon >}} \@juliasilge](https://fosstodon.org/@juliasilge)

[{{< fa brands github >}} \@juliasilge](https://github.com/juliasilge)

[{{< fa brands youtube >}} youtube.com/juliasilge](https://www.youtube.com/juliasilge)

[{{< fa link >}} juliasilge.com](https://juliasilge.com/)

[{{< fa book >}} tidytextmining.com](https://tidytextmining.com)

</center>

## Let's install some packages {background-color="white"}

```{r}
#| eval: false
install.packages(c("tidyverse", 
                   "tidytext",
                   "stopwords",
                   "gutenbergr"))
```

## What do we mean by tidy text? {background-color="white"}

![](figs/purple_emily.png){.absolute top="-30" right="0" width="100"}

```{r}
text <- c("Tell all the truth but tell it slant â€”",
          "Success in Circuit lies",
          "Too bright for our infirm Delight",
          "The Truth's superb surprise",
          "As Lightning to the Children eased",
          "With explanation kind",
          "The Truth must dazzle gradually",
          "Or every man be blind â€”")

text
```

## What do we mean by tidy text? {background-color="white"}

![](figs/purple_emily.png){.absolute top="-30" right="0" width="100"}

```{r}
library(tidyverse)

text_df <- tibble(line = 1:8, text = text)

text_df
```

## What do we mean by tidy text? {background-color="white"}

![](figs/purple_emily.png){.absolute top="-30" right="0" width="100"}

```{r}
#| code-line-numbers: "|4"
library(tidytext)

text_df %>%
    unnest_tokens(word, text)
```

## Jane wants to know... {transition="slide-in"}

![](figs/blue_jane.png){.absolute top="0" right="0" width="150" height="150"}

A tidy text dataset typically has

-   [more]{.lavender}
-   [fewer]{.lavender}

rows than the original, non-tidy text dataset.

## Gathering more data {background-color="white"}

You can access the full text of many public domain works from Project Gutenberg using the gutenbergr package.

```{r}
library(gutenbergr)

full_text <- gutenberg_download(1342, mirror = my_mirror)
```

What book do *you* want to analyze today? ðŸ“–ðŸ¥³ðŸ“–

::: aside
[https://docs.ropensci.org/gutenbergr/]{.blue}
:::

## Time to tidy your text! {background-color="white"}

```{r}
#| code-line-numbers: "|3"
tidy_book <- full_text %>%
    mutate(line = row_number()) %>%
    unnest_tokens(word, text)         

glimpse(tidy_book)
```

## What are the most common words? {background-color="white"}

What do you predict will happen if we run the following code? ðŸ¤”

```{r}
#| eval: false
tidy_book %>%
    count(word, sort = TRUE)
```

## What are the most common words? {background-color="white"}

What do you predict will happen if we run the following code? ðŸ¤”

```{r}
tidy_book %>%
    count(word, sort = TRUE)
```

## Stop words {background-color="white"}

```{r}
get_stopwords()
```

## Stop words {background-color="white"}

```{r}
get_stopwords(language = "es")
```

## Stop words {background-color="white"}

```{r}
get_stopwords(language = "fr")
```

## Stop words {background-color="white"}

```{r}
get_stopwords(source = "smart")
```

## What are the most common words?

[U N S C R A M B L E]{.lavender}

anti_join(get_stopwords(source = "smart")) %>%

tidy_book %>%

count(word, sort = TRUE) %>%

geom_col() +

slice_max(n, n = 20) %>%

ggplot(aes(n, fct_reorder(word, n))) + 

## What are the most common words? {background-color="white"}

```{r, eval = FALSE}
#| eval: false
#| code-line-numbers: "|5"
tidy_book %>%
    anti_join(get_stopwords(source = "smart")) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 20) %>%
    ggplot(aes(n, fct_reorder(word, n))) +  
    geom_col()
```

## {background-color="white"}

```{r}
#| echo: false
#| fig-width: 7
#| fig-align: center
tidy_book %>%
    anti_join(get_stopwords(source = "smart")) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 20) %>%
    ggplot(aes(n, fct_reorder(word, n))) +
    geom_col(fill = "midnightblue", alpha = 0.9) +
    scale_x_continuous(expand = c(0,0)) +
    labs(y = NULL, x = "Number of occurrences")
```

##  {background-image="figs/tilecounts-1.png" background-size="60%" background-color="white"}

::: footer
:::

##  {background-image="figs/tilerate-1.png" background-size="60%" background-color="white"}

::: footer
:::

# The Freeland Bunker Diaries {background-image="figs/water.jpg" background-size="cover" background-opacity="0.5"}


##  {background-image="figs/freeland_bunker.jpg" background-size="60%" background-color="white"}

::: footer
:::

##  {background-image="figs/freeland_timeline.jpg" background-size="60%" background-color="white"}

::: footer
:::


##  {background-image="figs/freeland_bunker_journal.jpg" background-size="85%" background-color="white"}

::: footer
:::

## Currently 2.5 journals transcribed from 1871-1874

```{r}

library(readxl)
journal_1871_1872 <- read_excel("data/journal_year_1871_1872.xlsx")

journal_1871_1872 %>%
    select(date_mdy, month, journal_entry) %>%
    head()
```
## All Journals

```{r}

journal_1873 <- read_excel("data/journal_1873.xlsx")
journal_1874 <- read_excel("data/journal_year_1874.xlsx")
journal_1875 <- read_excel("data/journal_1875.xlsx")

# We want to keep track of the journals

journal_1871_1872$journal <- 1
journal_1873$journal <- 2
journal_1874$journal <- 3
journal_1875$journal <- 4


journals <- rbind(journal_1871_1872, journal_1873, journal_1874, journal_1875)

```


## Tidy Journals

```{r}
library(lubridate)
(tidy_journal <- journals %>%
    select(date_mdy, month, journal_entry, journal) %>%
    unnest_tokens(word, journal_entry))
```

## Most common words

```{r}
tidy_journal %>%
    count(word, sort = TRUE)
```

## Removing stop words


```{r}
#| eval: false
tidy_journal %>%
    anti_join(get_stopwords(source = "smart")) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 20) %>%
    ggplot(aes(n, fct_reorder(word, n))) +  
    geom_col()
```

## Journal 1: Boats, Meals, Goods ðŸ³ â›µðŸ¦ž ðŸªµ


```{r}
#| echo: false
tidy_journal %>%
    anti_join(get_stopwords(source = "smart")) %>%
    filter(journal == 1) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 25) %>%
    mutate(color = case_when(word %in% c("breakfast", "dinner", "supper", "tea") ~ "meal", TRUE ~ "other")) %>%
    ggplot(aes(n, fct_reorder(word, n))) +  
    geom_col(aes(fill = color)) +
    labs(fill = "Word Type", y = "word")
```
## Journal 2: Wind and Weather â˜ï¸Ž NESW

```{r}
#| echo: false
tidy_journal %>%
    anti_join(get_stopwords(source = "smart")) %>%
    filter(journal == 2) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 25) %>%
    mutate(color = case_when(word %in% c("wind", "n.w", "north", "east", "west", "south", "rainy", "heavy", "snow", "breeze", "easterly", "southerly", "moderate") ~ "wind and weather", TRUE ~ "other")) %>%
    ggplot(aes(n, fct_reorder(word, n))) +  
    geom_col(aes(fill = color)) +
    labs(fill = "Word Type", y = "word")
```

## Your Turn: What were the most common words in Journal 3 and 4?


# SENTIMENT ANALYSIS </br>ðŸ˜„ðŸ˜¢ðŸ˜  {background-image="figs/p_and_p_cover.png" background-size="cover" background-opacity="0.5"}

## Sentiment lexicons {background-color="white"}

```{r echo = FALSE}

tns <- getNamespace("textdata")
assignInNamespace(x = "printer", value = function(...) 1, ns = tns)

```


```{r}
get_sentiments("afinn")
```

## Sentiment lexicons {background-color="white"}

```{r}
get_sentiments("bing")
```

## Sentiment lexicons {background-color="white"}

```{r}
get_sentiments("nrc")
```

## Sentiment lexicons {background-color="white"}

```{r}
get_sentiments("loughran")
```

## Implementing sentiment analysis {background-color="white"}

```{r}
#| code-line-numbers: "|2"
tidy_book %>%
    inner_join(get_sentiments("bing")) %>% 
    count(sentiment, sort = TRUE)
```

## Jane wants to know... {transition="slide-in"}

![](figs/blue_jane.png){.absolute top="0" right="0" width="150" height="150"}

What kind of join is appropriate for sentiment analysis?

-   [anti_join()]{.codedarkbg}
-   [full_join()]{.codedarkbg}
-   [outer_join()]{.codedarkbg}
-   [inner_join()]{.codedarkbg}

## Implementing sentiment analysis {background-color="white"}

What do you predict will happen if we run the following code? ðŸ¤”

```{r}
#| eval: false
#| code-line-numbers: "|3"
tidy_book %>%
    inner_join(get_sentiments("bing")) %>%            
    count(sentiment, word, sort = TRUE) 
```

## Implementing sentiment analysis {background-color="white"}

What do you predict will happen if we run the following code? ðŸ¤”

```{r}
#| code-line-numbers: "3"
tidy_book %>%
    inner_join(get_sentiments("bing")) %>%            
    count(sentiment, word, sort = TRUE)   
```

## Implementing sentiment analysis {background-color="white"}

```{r, eval = FALSE}
#| eval: false
#| code-line-numbers: "|7"
tidy_book %>%
    inner_join(get_sentiments("bing")) %>%
    count(sentiment, word, sort = TRUE) %>%
    group_by(sentiment) %>%
    slice_max(n, n = 10) %>%
    ungroup() %>%
    ggplot(aes(n, fct_reorder(word, n), fill = sentiment)) +
    geom_col() +
    facet_wrap(vars(sentiment), scales = "free") 
```

## {background-color="white"}

```{r}
#| echo: false
#| fig-align: center
tidy_book %>%
    inner_join(get_sentiments("bing")) %>%
    count(sentiment, word, sort = TRUE) %>%
    group_by(sentiment) %>%
    slice_max(n, n = 10) %>%
    ungroup %>%
    ggplot(aes(n, fct_reorder(word, n), fill = sentiment)) +
    geom_col(alpha = 0.9, show.legend = FALSE) +
    facet_wrap(vars(sentiment), scales = "free") +
    scale_x_continuous(expand = c(0,0)) +
    labs(y = NULL, x = "Number of occurrences")
```

# Thanks! {background-image="figs/p_and_p_cover.png" background-size="cover" background-opacity="0.5"}

<center>

<img src="figs/blue_jane.png" width="150px"/>

[{{< fa brands mastodon >}} \@juliasilge](https://fosstodon.org/@juliasilge)

[{{< fa brands github >}} \@juliasilge](https://github.com/juliasilge)

[{{< fa brands youtube >}} youtube.com/juliasilge](https://www.youtube.com/juliasilge)

[{{< fa link >}} juliasilge.com](https://juliasilge.com/)

[{{< fa book >}} tidytextmining.com](https://tidytextmining.com)

</center>

::: footer
Slides created with [Quarto](https://quarto.org/)
:::
