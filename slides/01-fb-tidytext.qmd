---
title: "Mining Historical Texts"
subtitle: "USING TIDY DATA PRINCIPLES"
author: "By Laurie Baker"
format:
  revealjs: 
    footer: <https:coa-navigating-change.netlify.app>
    theme: [dark, fbcustom.scss]
    width: 1280
    height: 720
highlight-style: "arrow-light"      
knitr:
  opts_chunk: 
    echo: true
    collapse: true
    comment: "#>"
---

```{r}
#| include: false
#| file: setup.R
```

# Acknowledgements

<center>

<img src="figs/blue_jane.png" width="150px"/>

Slide Structure, Content, and Design adapted from Julia Silge 

[{{< fa brands github >}} \@juliasilge](https://github.com/juliasilge)

[{{< fa link >}} juliasilge.com](https://juliasilge.com/)

[{{< fa book >}} tidytextmining.com](https://tidytextmining.com)

</center>

## Let's install some packages {background-color="white"}

```{r}
#| eval: false
install.packages(c("tidyverse", # data wrangling
                   "tidytext", # text analysis
                   "stopwords", # stop words
                   "lubridate", # dates
                   "readxl")) # reading data
```

##  The Journals (1870-1906) {background-image="figs/freeland_bunker_journal.jpg" background-size="45%" background-color="white"}

## What do we mean by tidy text? {background-color="white"}

![](figs/freeland_headshot.jpg){.absolute top="-35" right="0" width="92"}

```{r}
journal_text <- c("Was married at home in evening by William Rand Esqr.",
          "Went to meeting.",
          "Shooting match all day in the evening to Christmas Tree at the Hall.",
          "About home at work fobbing.",
          "Work about home.",
          "To work in shop.",
          "To work in shop.",
          "Went to meeting.")

journal_text
```

## What do we mean by tidy text? {background-color="white"}

![](figs/freeland_headshot.jpg){.absolute top="-35" right="0" width="92"}

```{r}
library(tidyverse)

journal_df <- tibble(line = 1:8, text = journal_text)

journal_df
```

## What do we mean by tidy text? {background-color="white"}

![](figs/freeland_headshot.jpg){.absolute top="-35" right="0" width="92"}

```{r}
#| code-line-numbers: "|4"
library(tidytext)

journal_df %>%
    unnest_tokens(word, text)
```

## Freeland wants to know... {transition="slide-in"}

![](figs/freeland_headshot.jpg){.absolute top="0" right="0" width="150" height="150"}

A tidy text dataset typically has

-   [more]{.lavender}
-   [fewer]{.lavender}

rows than the original, non-tidy text dataset.


## 9 journals (1871-1880) transcribed


```{r warning = FALSE, message = FALSE}

journals <- read_csv(file = "data/journals.csv")

journals %>%
    distinct(journal)

```

## Journal Date, Text, and Location

```{r}
journals %>%
    select(date_mdy, journal_entry, location)
```


## Creating date variables using `lubridate`

Recall: What functions can we use to extract the year and month?

```{r, eval=FALSE, warning=FALSE}
library(lubridate)
journals <- journals %>%
    select(date_mdy, journal_entry, journal, location) %>%
    mutate(date_mdy = mdy(date_mdy),
           year = _____(date_mdy),
           month = _____(date_mdy))
```

Hint: Check the [lubridate cheatsheet](https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_lubridate.pdf)

## Creating date variables using `lubridate`

```{r, warning=FALSE}
library(lubridate)
(journals <- journals %>%
    select(date_mdy, journal_entry, journal, location) %>%
    mutate(date_mdy = mdy(date_mdy),
           year = year(date_mdy),
           month = month(date_mdy)))
```

## Making our text data tidy

```{r}
#| code-line-numbers: "|2"
(tidy_journal <- journals %>%
    unnest_tokens(word, journal_entry))
```

## How much did Freeland write?

```{r}
(monthly_word_count <- tidy_journal %>%
  group_by(month, year) %>%
  filter(is.na(year) == FALSE) %>%
  summarize(nwords = n()))
```

## Plotting monthly word count through time

What plot do you expect to see?

```{r}
#| eval: false
monthly_word_count %>%
  ggplot(aes(x = month, y = nwords, group = year)) +
  geom_line() +
  geom_point() +
  facet_wrap(~year) +
  labs(title = "How much did Freeland write a month?",
       y = "Number of words",
       x = "Month") +
  scale_x_continuous(breaks = c(0, 3, 6, 9, 12))
```
## How much did Freeland write?

```{r}
#| echo: false
monthly_word_count %>%
  ggplot(aes(x = month, y = nwords, group = year)) +
  geom_line() +
  geom_point() +
  facet_wrap(~year) +
  labs(title = "How much did Freeland write a month?",
       y = "Number of words",
       x = "Month") +
  scale_x_continuous(breaks = c(0, 3, 6, 9, 12))
```


```{r echo=FALSE}
tidy_journal <- journals %>%
    unnest_tokens(word, journal_entry) %>%
    filter(word != "NA") %>%
    mutate(word = case_when(word %in% c("reed", "recd") ~ "received",
           TRUE ~ word)) %>%
    drop_na(word)
```

## What are the most common words? {background-color="white"}

What do you predict will happen if we run the following code? ðŸ¤”

```{r}
#| eval: false
tidy_journal %>%
    count(word, sort = TRUE)
```

## What are the most common words? {background-color="white"}

What do you predict will happen if we run the following code? ðŸ¤”

```{r}
tidy_journal %>%
    count(word, sort = TRUE)
```

## Stop words {background-color="white"}

```{r}
get_stopwords()
```

## Stop words {background-color="white"}

```{r}
get_stopwords(language = "es")
```

## Stop words {background-color="white"}

```{r}
get_stopwords(language = "de")
```

## Stop words {background-color="white"}

```{r}
get_stopwords(source = "smart")
```

## What are the most common words?

[U N S C R A M B L E]{.lavender}

anti_join(get_stopwords(source = "smart")) %>%

tidy_journal %>%

count(word, sort = TRUE) %>%

geom_col() +

slice_max(n, n = 20) %>%

ggplot(aes(n, fct_reorder(word, n))) + 

## What are the most common words? {background-color="white"}

```{r, eval = FALSE}
#| eval: false
#| code-line-numbers: "|2|5"
tidy_journal %>%
    anti_join(get_stopwords(source = "smart")) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 20) %>%
    ggplot(aes(n, fct_reorder(word, n))) +  
    geom_col()
```

## {background-color="white"}

```{r}
#| echo: false
#| fig-width: 7
#| fig-align: center
tidy_journal %>%
    anti_join(get_stopwords(source = "smart")) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 20) %>%
    ggplot(aes(n, fct_reorder(word, n))) +
    geom_col(fill = "midnightblue", alpha = 0.9) +
    scale_x_continuous(expand = c(0,0)) +
    labs(y = NULL, x = "Number of occurrences")
```

## Journal 1: Boats, Meals, Goods ðŸ³ â›µðŸ¦ž ðŸªµ  {background-color="white"}


```{r}
#| echo: false
tidy_journal %>%
    anti_join(get_stopwords(source = "smart")) %>%
    filter(journal == 1) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 25) %>%
    mutate(color = case_when(word %in% c("breakfast", "dinner", "supper", "tea") ~ "meal", 
                             word %in% c("wood", "lobster", "lobsters") ~ "goods", 
                             word %in% c("boat", "boats") ~ "boats",
                             TRUE ~ "other")) %>%
    ggplot(aes(n, fct_reorder(word, n))) +  
    geom_col(aes(fill = color)) +
    labs(fill = "Word Type", y = "word") +
    scale_fill_viridis_d(direction = -1)
```

## Journal 2: Wind and Weatherï¸Ž NESW{background-color="white"}

```{r}
#| echo: false
tidy_journal %>%
    anti_join(get_stopwords(source = "smart")) %>%
    filter(journal == 2) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 25) %>%
    mutate(word = case_when(word %in% c("n.w.") ~ "northwest",
                            TRUE ~ word)) %>%
    mutate(color = case_when(word %in% c("wind", "northwest", "north", "east", "west", "south", "rainy", "heavy", "snow", "breeze", "easterly", "southerly", "moderate", "cold", "rain") ~ "wind and weather", TRUE ~ "other")) %>%
    ggplot(aes(n, fct_reorder(word, n))) +  
    geom_col(aes(fill = color)) +
    labs(fill = "Word Type", y = "word") +
    scale_fill_viridis_d(direction = -1)
```
## Comparing multiple journals

```{r}
#| echo: false
tidy_journal %>%
    anti_join(get_stopwords(source = "smart")) %>%
    filter(journal %in% c(3, 4)) %>%
    count(word, journal, sort = TRUE) %>%
    slice_max(n, n = 25) %>%
    mutate(word = case_when(word %in% c("n.w.") ~ "northwest",
                            TRUE ~ word)) %>%
    mutate(color = case_when(word %in% c("wind", "northwest", "north", "east", "west", "westerly", "south", "rainy", "heavy", "snow", "breeze", "easterly", "southerly", "moderate", "cold", "rain") ~ "wind and weather", TRUE ~ "other")) %>%
    ggplot(aes(n, fct_reorder(word, n))) +  
    geom_col(aes(fill = color)) +
    labs(fill = "Word Type", y = "word") +
    scale_fill_viridis_d(direction = -1) +
    facet_wrap(~journal)
```

## Your Turn: What were the most common words in Journal 5 and 6? 

```{r}
#| eval: false
tidy_journal %>%
    anti_join(get_stopwords(source = "smart")) %>%
    filter(journal %in% c(____, ____)) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 25) %>%
    ggplot(aes(n, fct_reorder(word, n))) +  
    geom_col(aes(fill = color)) +
    labs(fill = "Word Type", y = "word") +
    scale_fill_viridis_d(direction = -1)
```


## Your Turn: What were the most common words in your journal period?

```{r}
#| eval: false
tidy_journal %>%
    anti_join(get_stopwords(source = "smart")) %>%
    filter(year _______,
           month %in% c(_________)) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 25) %>%
    ggplot(aes(n, fct_reorder(word, n))) +  
    geom_col(aes(fill = color)) +
    labs(fill = "Word Type", y = "word") +
    scale_fill_viridis_d(direction = -1)
```

## Looking at word trends through space

```{r}
#| eval: false
tidy_journal %>%
    anti_join(get_stopwords(source = "smart")) %>%
    filter(str_detect(location, pattern = "Matinicus")) %>%
    count(word, sort = TRUE) %>%
    filter(word != "home") %>%
    slice_max(n, n = 10, with_ties = FALSE) %>%
    ggplot(aes(n, fct_reorder(word, n))) +  
    geom_col() +
    labs(fill = "Word Type", y = "word", title = "Matinicus") +
    scale_fill_viridis_d(direction = -1)
```

## Looking at word trends through space

```{r}
#| echo: false
tidy_journal %>%
    anti_join(get_stopwords(source = "smart")) %>%
    filter(str_detect(location, pattern = "Matinicus")) %>%
    count(word, sort = TRUE) %>%
    filter(word != "home") %>%
    slice_max(n, n = 10, with_ties = FALSE) %>%
    ggplot(aes(n, fct_reorder(word, n))) +  
    geom_col() +
    labs(fill = "Word Type", y = "word", title = "Matinicus") +
    scale_fill_viridis_d(direction = -1)
```
## Your Turn: Looking at word trends through space

```{r}
#| eval: false
tidy_journal %>%
    anti_join(get_stopwords(source = "smart")) %>%
    filter(str_detect(location, "__________")) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 10, with_ties = FALSE) %>%
    ggplot(aes(n, fct_reorder(word, n))) +  
    geom_col() +
    labs(fill = "Word Type", y = "word", title = "_______") +
    scale_fill_viridis_d(direction = -1)
```

# We can also look for specific things

## Extracting thermometer readings

```{r extract journal entries with the word thermometer ignore below plot}
#| echo: false
journals %>%
  filter(str_detect(string = journal_entry, pattern = "Thermometer | thermometer")) %>% # filter rows for mentions of word thermometer
  mutate(temp = as.numeric(str_extract(journal_entry, pattern = '(?<=thermometer |Thermometer )\\d+'))) %>% # extract digits following the word thermometer in a sentence.
  ggplot(aes(x = date_mdy, y = as.numeric(temp))) +
  geom_point() +
  labs(x = "Date", y = "Recorded Temperature")
  
```


## Extracting thermometer readings

```{r extract journal entries with the word thermometer ignore below}
#| eval: false
journals %>%
  filter(str_detect(string = journal_entry, pattern = "Thermometer | thermometer")) %>% # filter rows for mentions of word thermometer
  mutate(temp = as.numeric(str_extract(journal_entry, pattern = '(?<=thermometer |Thermometer )\\d+'))) %>% # extract digits following the word thermometer in a sentence.
  ggplot(aes(x = date_mdy, y = as.numeric(temp))) +
  geom_point() +
  labs(x = "Date", y = "Recorded Temperature")
  
```

## Looking for Schooners

```{r}
journals %>%
    filter(str_detect(journal_entry, pattern = "Schr|schr|schooner")) %>%
    select(date_mdy, journal_entry) %>%
    DT::datatable()
```

## Extracting names of schooners

```{r}
journals %>%
    filter(str_detect(journal_entry, pattern = "Schr|schr|schooner")) %>%
    mutate(schooners = str_extract(journal_entry, pattern = "\\b(Schr|Schr.|schr|schr.)(\\b\\s*([A-Z]\\w+|[A-Z]\\.\\w+\\.\\w+|[A-Z]\\. \\w+\\. \\w+)){0,4}")) %>%
    distinct(schooners)
```

## Recap

-   We can put each word on its own row using `unnest_tokens`
-   We can use `anti_join` to get rid of stop words
-   We can use `filter` and `summarize` to see how word use has changed over time and space
-   We can use `str_detect` to find patterns in our text
-   We can use `regular expressions` to extract more complicated patterns

## Your Turn

What is something you are curious about in Freeland's journals that you'd like to investigate? Be creative with the time period, place, and what you're looking for.


```{r eval = FALSE}
journals %>%
    filter(str_detect(journal_entry, pattern = "What are you looking for?")) %>%
    select(date_mdy, journal_entry)
```



# Thanks! {background-image="figs/water2.jpg" background-size="cover" background-opacity="0.5"}

<center>

<img src="figs/freeland_headshot.jpg" width="150px"/>

[{{< fa brands github >}} \@LaurieLBaker](https://github.com/laurielbaker)

[{{< fa link >}} lauriebaker@rbind.io](https://lauriebaker.rbind.io)

</center>

::: footer
Slides created with [Quarto](https://quarto.org/)
:::

# Additional Slides

# What was the weather like? {background-image="figs/water2.jpg" background-size="cover" background-opacity="1"}


## {background-color="white"}

```{r}
#| echo: false
#| fig-align: center
tidy_journal %>%
    mutate(month = as.factor(month)) %>%
    drop_na(month) %>%
    filter(word %in% c("cold", "dark", "stormy", "rainy", "cloudy", "calm", "warm", "pleasant", "clear")) %>%
    count(month, word, sort = TRUE) %>%
    mutate(word = as.factor(word)) %>%
    mutate(word = fct_relevel(word, c("calm", "clear", "pleasant", "warm", "cloudy", "cold", "dark", "stormy"))) %>%
    ggplot(aes(x = fct_relevel(month, c("January", "February", "March", "April", "May", "June", "July", "August", "September")), y = n, fill = word)) +
    geom_col(position = "stack") +
    labs(y = "Number of occurrences", x = "Month") +
    scale_fill_brewer(palette = "Spectral") +
    labs(title = "Whatever the weather") +
    coord_polar()
```

